{"pages":[{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz1234@163.com","link":"/about/index.html"},{"title":"","text":"","link":"/tags/index.html"},{"title":"","text":"","link":"/categories/index.html"}],"posts":[{"title":"Cache Lab","text":"介绍本实验有两个部分，Part A 要求我们模拟一个 cache 行为，正确地模拟每次操作（如 load、store、modify） cache 的响应（hit、miss、eviction）。Part B 要求我们用尽可能少的 cache 的 miss 实现矩阵的转置，充分利用 cache。 实验说明：地址 Part A在本实验中，需要完成 csim.c 文件，使之编译后实现类似功能： Usage: ./csim-ref [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;• -h: Optional help flag that prints usage info• -v: Optional verbose flag that displays trace info• -s &lt;s&gt;: Number of set index bits (S = 2sis the number of sets)• -E &lt;E&gt;: Associativity (number of lines per set)• -b &lt;b&gt;: Number of block bits (B = 2bis the block size)• -t &lt;tracefile&gt;: Name of the valgrind trace to replay 要求我们的程序可以手动设置 cache 的 set 数、line 数、block 大小，读取指定的文件内容进行操作，指令类似如下： I 0400d7d4,8M 0421c7f0,4L 04f6b868,8S 7ff0005c8,8 每行代表一个操作，格式: [space]operation address,size I 代表 instruction load, L 代表 data load, S 代表 data store, M 代表 data modify (i.e., a data load followed by a data store) 回顾一下 cahce 具体结构： 具体如下： #include &quot;cachelab.h&quot;#include &lt;getopt.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;math.h&gt;typedef unsigned long int uint64_t;typedef struct { int valid; int lru; uint64_t tag;}cacheLine;typedef cacheLine* cacheSet;typedef cacheSet* Cache;const char* usage = &quot;Usage: %s [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;\\n&quot;;int verbose = 0; //verbose flag int s; //number of set index bits int E; //number of lines per setint b; //number of block bitsFILE* fp = NULL;Cache cache;int hits = 0;int misses = 0;int evictions = 0;void parseArgument(int argc, char* argv[]);int visitCache(uint64_t address);int simulate();int main(int argc, char* argv[]){ parseArgument(argc, argv); simulate(); printSummary(hits, misses, evictions); return 0;}void parseArgument(int argc, char* argv[]){ int opt; while ((opt = getopt(argc, argv, &quot;hvs:E:b:t:&quot;)) != -1) { switch(opt) { case 'h': fprintf(stdout, usage, argv[0]); exit(1); case 'v': verbose = 1; break; case 's': s = atoi(optarg); break; case 'E': E = atoi(optarg); break; case 'b': b = atoi(optarg); break; case 't': fp = fopen(optarg, &quot;r&quot;); break; default: fprintf(stdout, usage, argv[0]); exit(1); } }}int simulate(){ int S = pow(2, s); cache = (Cache)malloc(sizeof(cacheSet) * S); if (cache == NULL) return -1; for (int i = 0; i &lt; S; i++) { cache[i] = (cacheSet)calloc(E, sizeof(cacheLine)); if (cache[i] == NULL) return -1; } char buf[20]; char operation; uint64_t address; int size; while (fgets(buf, sizeof(buf), fp) != NULL) { int ret; if (buf[0] == 'I') //ignore instruction cache accesses { continue; } else { sscanf(buf, &quot; %c %lx,%d&quot;, &amp;operation, &amp;address, &amp;size); switch (operation) { case 'S': ret = visitCache(address); break; case 'L': ret = visitCache(address); break; case 'M': ret = visitCache(address); hits++; break; } if (verbose) { switch(ret) { case 0: printf(&quot;%c %lx,%d hit\\n&quot;, operation, address, size); break; case 1: printf(&quot;%c %lx,%d miss\\n&quot;, operation, address, size); break; case 2: printf(&quot;%c %lx,%d miss eviction\\n&quot;, operation, address, size); break; } } } } for (int i = 0; i &lt; S; i++) free(cache[i]); free(cache); fclose(fp); return 0;}/*return value 0 cache hit 1 cache miss 2 cache miss, eviction*/int visitCache(uint64_t address){ uint64_t tag = address &gt;&gt; (s + b); unsigned int setIndex = address &gt;&gt; b &amp; ((1 &lt;&lt; s) - 1); int evict = 0; int empty = -1; cacheSet cacheset = cache[setIndex]; for (int i = 0; i &lt; E; i++) { if (cacheset[i].valid) { if (cacheset[i].tag == tag) { hits++; cacheset[i].lru = 1; return 0; } cacheset[i].lru++; if (cacheset[evict].lru &lt;= cacheset[i].lru) // =是必须的,why? { evict = i; } } else { empty = i; } } //cache miss misses++; if (empty != -1) { cacheset[empty].valid = 1; cacheset[empty].tag = tag; cacheset[empty].lru = 1; return 1; } else { cacheset[evict].tag = tag; cacheset[evict].lru = 1; evictions++; return 2; }} Part B参考总结","link":"/2000/12/13/CSAPP_Cache_Lab/"},{"title":"Go项目笔记","text":"前言最近在公司有开始接触 Go 的项目，想系统的学习一下。相对来说 Go 的语法还是比较简单，很容易上手。快速看完两本入门书，想找一些偏项目的书来看，发现目前国内还是比较少。然后翻了一下培训机构的教程，感觉也不是很好，偶然在油管上看到这个教程 Backend master class，感觉讲的不错，就把这个教程整理出来。 介绍这是一个从设计、开发到部署的完整的 Go 项目，使用 PostgreSQL、Golang 和 Docker，这个项目主要来构建一个简单的银行系统，主要提供一下功能： 创建和管理帐户：所有者、余额、货币 记录所有余额变化：为每次更改创建一个帐户条目 转账交易：在一笔交易中，在两个账户之间进行一致的转账 数据库设计设计数据库架构使用 dbdiagram.io 设计表结构，采用的 DSL 语言来定义： Table accounts as A { id bigint [pk, increment, note: '主键'] owner varchar [not null, note: '账户所有者'] balance bigint [not null, note: '账户余额'] currency varchar [not null, note: '货币类型，比如：人民币'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { owner } note: '账户'}Table entries { id bigint [pk, increment, note: '主键'] account_id bigint [not null, ref: &gt; A.id, note:'账户id，关联account的id'] amount bigint [not null, note:'变化金额，可正可负'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { account_id } note: '记录所有余额变化'}Table transfers { id bigint [pk, increment, note: '主键'] from_account_id bigint [not null, ref: &gt; A.id, note: '转账id'] to_account_id bigint [not null, ref: &gt; A.id, note: '被转账id'] amount bigint [not null, note: '必须为正'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { from_account_id to_account_id (from_account_id, to_account_id) } note: '转账交易记录'} 可以生成响应的关系图： 可以导出 PostgreSQL，MySQL等等 还可以创建分享链接，这个表的链接为： https://dbdiagram.io/d/5fcc5ee49a6c525a03b9f27d 使用 Docker 安装 Postgers先安装 docker，可参考网上 先登入 docker 官方，查找可用的镜像，找到一个为 12-alpine，使用 docker pull &lt;image&gt;:&lt;tag&gt; 方式拉去这个镜像 docker pull postgres:12-alpine 输入 docker images 就可看到我们拉去的镜像了 ~ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpostgres 12-alpine b5a8143fc58d 3 weeks ago 158MB 通过以下格式来运行，我们知道一个镜像（image）可用运行多个容器（container） docker run --name&lt;container_name&gt; // 容器名称 -e &lt;environment_variable&gt; // 环境变量 -p &lt;host_port:containter_ports&gt; // 端口映射 -d &lt;image&gt;:&lt;tag&gt; // 后台运行 运行镜像： docker run --name postgres12 \\ -e POSTGRES_USER=root -e POSTGRES_PASSWORD=12356 \\ -p 5432:5432 \\ -d postgres:12-alpine \\ 使用 docker ps 查看运行的镜像 ~ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5c337d6516a6 postgres:12-alpine &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 0.0.0.0:5432-&gt;5432/tcp postgres12 在运行的容器中执行命令： docker exec -it &lt;container_name_or_id&gt; &lt;commend&gt; [args] 进入 postgres 命令终端 docker exec -it postgres12 psql -U rootpsql (12.5)Type &quot;help&quot; for help.root=# 使用 DataGrip 连接数据库，并且把生成的 SQL 导入 DataGrip 中，生成相应的表。 SQL/GORM/SQLX/SQLC生成CRUD的比较SQL 快、直接 手动映射 容易写错 GORM CRUD 已经实现了 需要学习一些 gorm 语法 比较慢 SQLX 快，容易使用 通过查询语句和结构体tag映射 SQLC 快，容易使用 自动代码生成 最终我们选择 SQLC，https://github.com/kyleconroy/sqlc 在 mac 上安装 brew install kyleconroy/sqlc/sqlc","link":"/2020/12/06/Go%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/"},{"title":"Markdown绘制UML图","text":"makedown 用户 -&gt; 认证中心: 登录操作认证中心 -&gt; 缓存: 存放(key=token+ip,value=token)token认证中心 -&gt; 用户: 认证成功返回token用户 -&gt; 认证中心: 下次访问头部携带token认证缓存 -&gt; 认证中心: key=token+ip获取token认证中心-&gt;其他服务: 存在且校验成功则跳转到用户请求的其他服务其他服务 -&gt; 用户: 信息 测试 @startuml用户 -&gt; 认证中心: 登录操作认证中心 -&gt; 缓存: 存放(key=token+ip,value=token)token 用户 &lt;- 认证中心 : 认证成功返回token用户 -&gt; 认证中心: 下次访问头部携带token认证认证中心 &lt;- 缓存: key=token+ip获取token其他服务 &lt;- 认证中心: 存在且校验成功则跳转到用户请求的其他服务其他服务 -&gt; 用户: 信息@enduml @startuml用户 -&gt; 认证中心: 登录操作认证中心 -&gt; 缓存: 存放(key=token+ip,value=token)token用户 &lt;- 认证中心 : 认证成功返回token用户 -&gt; 认证中心: 下次访问头部携带token认证认证中心 &lt;- 缓存: key=token+ip获取token其他服务 &lt;- 认证中心: 存在且校验成功则跳转到用户请求的其他服务其他服务 -&gt; 用户: 信息@enduml","link":"/2000/05/10/Markdown%E7%BB%98%E5%88%B6UML%E5%9B%BE/"},{"title":"深入理解高速缓存工作原理","text":"为什么需要高速缓存早期 CPU 相比现在的 CPU 比较简单，没有 Cache 的计算机系统的简化模型，CPU在执行时需要的指令和数据通过内存总线和系统总线由内存传送到寄存器，再由寄存器送入ALU）。 那时候，CPU 内核的频率与内存总线的频率相当。内存访问只比寄存器访问慢一点。随着 CPU 内核频率不断增加，内存总线的频率和 RAM 芯片的性能并没有成比例增加。 下图展示了CPU和主存（DRAM）、磁盘速度上的差距。可以看到，CPU的速度大概是主存的几十倍，如果没有Cache（SRAM），这就出现了 CPU 等待 I/O 访存的现象，致使CPU空等一段时间，甚至可能等待几个主存周期，从而降低了CPU 的工作效率。 在 CUP 和 DRAM 之间引入高速 SRAM，来弥补这种差距，当 CPU 需要数据时，先查 SRAM（Cache）中，如果在 Cache 中可以查询到，叫作缓存命中，则就不需要访问 DRAM 了，节约时间。 程序局部性原理为了充分发挥 Cache 的能力，使得机器的速度能够切实的得到提高，必须要保障 CPU 访问的指令或数据大多情况下都能够在 Cache 中找到，这样依靠程序访问的局部性原理。 时间局部性：最近访问的数据可能在不久的将来会再次访问 空间局部性：位置相近的数据常常在相近的时间内被访问 存储山由于不同的存储技术在存储速度和造价上相差巨大，为了高效的访问数据，现代计算机的存储系统会把最常用的数据放在读存速度快的存储设备上，而把不常用的数据放在读存速度慢的存储设备上。 存储器系统是一个具有不同容量、成本和访问时间的存储设备的层级结构。从上往下容量越来越大，但访问速度越来越慢。上一层做为下一层的缓存来存储访问频率更高的数据， 比如，CPU 寄存器保存着最常用的数据。靠近 CPU 的小的、快速的高速缓存存储器是内存上一部分数据和指令的缓冲区域。主存缓存磁盘上的数据，而这些磁盘又常常作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。存储层次如下： 高速缓存原理假设计算机储存地址为 m 位，形成 M = 2^m 个不同的地址，就会形成 S = 2^s 个缓存组（cache set），每组包含 E 个高速缓存行（cache line），每行包含一个有效位（valid bit）指明这个行是否有效，t 个标记位（tag bit）和 B = 2^b 个缓存数据块。 Cache由硬件管理，硬件在得到内存地址后会将地址划分为三个部分 首先根据组下标选择一个组，然后将地址中的标签与被选中组的每个行中的标签进行比较，如果标签相等，且有效位为1，则 Cache 命中，再根据块偏移从行中选出相应的数据。 假设计算机储存地址为 m 位，形成 M = 2^m 个不同的地址，就会形成 S = 2^s 个缓存组（cache set），每组包含 E 个高速缓存行（cache line），每行包含一个有效位（valid bit）指明这个行是否有效，t 个标记位（tag bit）和 B = 2^b 个缓存数据块 假设 m = 4，t = 2，s = 1，b = 1，E = 2 可知： M = 2^m = 2^4 = 16 S = 2^s = 2^1 = 2 B = 2^b = 2^1 = 2 分别读取地址为 0、1、7、8、0 这几个地址，看看缓存能命中哪些？ 具体过程如图： 高速缓存不命中替换 如果 CPU 请求的数据不在任何一行中，那么缓存不命中，如果有空行的话就把数据缓存到空行中，如果没有空行，那我们必须选择一个非空行替换。可以使用 LRU 算法来替换。 为什么使用中间位来做索引？假设我们有一个缓存组可以缓存四块，如果我们去 0000 这块数据，并且把 0001、0002 和 0003 这三块数据加入缓存中，就会发现，使用高位缓存只能缓存一块数据，而使用中间位来索引可以缓存四块数据。所以使用高位做缓存缓存的使用效率很低。 高速缓存读与写高速缓存读 首先，在高速缓存中查找所需字 w 的副本。如果命中，立即返回字 w 给CPU。如果不命中，从存储器层次结构中较低层中取出包含字 w 的块，将这个块存储到某个高速缓存行中，然后返回字 w。 高速缓存写 写命中 直写（write-through），写一个已经缓存了的字w（写命中，write hit），立即将w的高速缓存块写回到紧接着的低一层中。 写回（write-back），尽可能的推迟更新，只有当替换算法要驱逐这个更新过的块时，才把写到紧接着的低一层中。高速缓存必须为每一个高速缓存行维护一个额外的修改位（dirty bit），表明这个高速缓存块是否被修改过。 写不命中 写分配（write-allocate），加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。 非写分配（not-write-allocate），避开高速缓存，直接把这个字写到低一层中。 Cache 失效的三种原因 Cold miss：刚刚使用Cache时Cache为空，此时必然发生Cache miss。 Capacity miss：程序最经常使用的那些数据(工作集,working set)超过了Cache的大小 Conflict miss：Cache容量足够大，但是不同的数据映射到了同一组，从而造成Cache line反复被替换的现象。 高速缓存结构我们看看 Intel Core i7 处理器的高速缓存层次结构。每个 CPU 芯片有四个核。每个核有自己的 L1 i-cache（指令高速缓存）、L1 d-cache（数据高速缓存）、和 L2 统一高速缓存。以及 L3 为所有核共享高速缓存。所有的缓存都是集成在 CPU 芯片上。 下面指标高速缓存类型（Cache Type）、访问周期（Access time）、缓存大小（Cache size）、一组有多少行（Assoc）、块大小（Block size）以及组数（Set）。 编写高速缓存友好代码假设我们需要来计算一个二维数组的和，有两种方式分别是按行计算和按列计算。 假设我们高速缓存为 4 字，可以缓存 4 和 int 的值。 按行计算 int sumarrrayrows(int a[M][N]) { int i, j, sum = 0; for (i = 0; i &lt; M; i++) { for (j = 0; i &lt; N; j++) { sum += a[i][j]; } } return sum;} 当我们加载地址为1的数，会把 2、3和4地址的数据加载到高速缓存中，如果是按行，后面这几个就会缓存命中。 具体缓存命中情况如图： 按列计算 int sumarrraycols(int a[M][N]) { int i, j, sum = 0; for (j = 0; i &lt; N; j++) { for (i = 0; i &lt; M; i++) { sum += a[i][j]; } } return sum;} 当我们加载地址为1的数，会把 2、3和4地址的数据加载到高速缓存中，然而我们下个取得是 5 所以缓存不命中，同时会把 6、7和8地址加到缓存中。接着下个取地址为9的值，缓存又不命中。 具体缓存情况如图： 我们看上去只是调换了一下顺序，缓存命中相差很大，所以编写高速缓存友好代码。 总结学习到了高速缓存原理，以及编写高速缓存友好代码。 参考 深入理解计算机系统 深入理解处理器高速缓存的工作机制 Linux内存系列2 - CPU Cache 计算机组成原理（2）-cache高速缓存存储器","link":"/2020/11/28/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/tags/PostgreSQL/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"UML","slug":"UML","link":"/tags/UML/"}],"categories":[{"name":"CSAPP","slug":"CSAPP","link":"/categories/CSAPP/"},{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"}]}