{"pages":[{"title":"","text":"","link":"/tags/index.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz1234@163.com","link":"/about/index.html"},{"title":"","text":"","link":"/categories/index.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"}],"posts":[{"title":"Let&#39;s build a Full-Text Search engine","text":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。 Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search. Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text. Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word cat“ and we’ll extend the engine to support more sophisticated boolean queries. Note Most well-known FTS engine is Lucene (as well as Elasticsearch and Solr built on top of it). Why FTSBefore we start writing code, you may ask “can’t we just use grep or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea. CorpusWe are going to search a part of the abstract of English Wikipedia. The latest dump is available at dumps.wikimedia.org. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents. Document example: &lt;title&gt;Wikipedia: Kit-Cat Klock&lt;/title&gt;&lt;url&gt;https://en.wikipedia.org/wiki/Kit-Cat_Klock&lt;/url&gt;&lt;abstract&gt;The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.&lt;/abstract&gt; Loading documentsFirst, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy: import ( &quot;encoding/xml&quot; &quot;os&quot;)type document struct { Title string `xml:&quot;title&quot;` URL string `xml:&quot;url&quot;` Text string `xml:&quot;abstract&quot;` ID int}func loadDocuments(path string) ([]document, error) { f, err := os.Open(path) if err != nil { return nil, err } defer f.Close() dec := xml.NewDecoder(f) dump := struct { Documents []document `xml:&quot;doc&quot;` }{} if err := dec.Decode(&amp;dump); err != nil { return nil, err } docs := dump.Documents for i := range docs { docs[i].ID = i } return docs, nil} Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on. First attemptSearching the contentNow that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring cat: func search(docs []document, term string) []document { var r []document for _, doc := range docs { if strings.Contains(doc.Text, term) { r = append(r, doc) } } return r} On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches caterpillar and category, but doesn’t match Cat with the capital C. That’s not quite what I was looking for. We need to fix two things before moving forward: Make the search case-insensitive (so Cat matches as well). Match on a word boundary rather than on a substring (so caterpillar and communication don’t match). Searching with regular expressionsOne solution that quickly comes to mind and allows implementing both requirements is regular expressions. Here it is - (?i)\\bcat\\b: (?i) makes the regex case-insensitive \\b matches a word boundary (position where one side is a word character and another side is not a word character) func search(docs []document, term string) []document { re := regexp.MustCompile(`(?i)\\b` + term + `\\b`) // Don't do this in production, it's a security risk. term needs to be sanitized. var r []document for _, doc := range docs { if re.MatchString(doc.Text) { r = append(r, doc) } } return r} Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that. Inverted IndexTo make search queries faster, we’ll preprocess the text and build an index in advance. The core of FTS is a data structure called Inverted Index. The Inverted Index associates every word in documents with documents that contain the word. Example: documents = { 1: &quot;a donut on a glass plate&quot;, 2: &quot;only the donut&quot;, 3: &quot;listen to the drum machine&quot;,}index = { &quot;a&quot;: [1], &quot;donut&quot;: [1, 2], &quot;on&quot;: [1], &quot;glass&quot;: [1], &quot;plate&quot;: [1], &quot;only&quot;: [2], &quot;the&quot;: [2, 3], &quot;listen&quot;: [3], &quot;to&quot;: [3], &quot;drum&quot;: [3], &quot;machine&quot;: [3],} Below is a real-world example of the Inverted Index. An index in a book where a term references a page number: Text analysisBefore we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching. The text analyzer consists of a tokenizer and multiple filters. TokenizerThe tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks: func tokenize(text string) []string { return strings.FieldsFunc(text, func(r rune) bool { // Split on any character that is not a letter or a number. return !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r) })} &gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;] FiltersIn most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization. LowercaseIn order to make the search case-insensitive, the lowercase filter converts tokens to lower case. cAt, Cat and caT are normalized to cat. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term cAt match the text Cat. func lowercaseFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = strings.ToLower(token) } return r} &gt; lowercaseFilter([]string{&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;] Dropping common wordsAlmost any English text contains commonly used words like a, I, the or be. Such words are called stop words. We are going to remove them since almost any document would match the stop words. There is no “official” list of stop words. Let’s exclude the top 10 by the OEC rank. Feel free to add more: var stopwords = map[string]struct{}{ // I wish Go had built-in sets. &quot;a&quot;: {}, &quot;and&quot;: {}, &quot;be&quot;: {}, &quot;have&quot;: {}, &quot;i&quot;: {}, &quot;in&quot;: {}, &quot;of&quot;: {}, &quot;that&quot;: {}, &quot;the&quot;: {}, &quot;to&quot;: {},}func stopwordFilter(tokens []string) []string { r := make([]string, 0, len(tokens)) for _, token := range tokens { if _, ok := stopwords[token]; !ok { r = append(r, token) } } return r} &gt; stopwordFilter([]string{&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;] StemmingBecause of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, fishing, fished and fisher may be reduced to the base form (stem) fish. Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the existing modules: import snowballeng &quot;github.com/kljensen/snowball/english&quot;func stemmerFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = snowballeng.Stem(token, false) } return r} &gt; stemmerFilter([]string{&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] Note A stem is not always a valid word. For example, some stemmers may reduce airline to airlin. Putting the analyzer togetherfunc analyze(text string) []string { tokens := tokenize(text) tokens = lowercaseFilter(tokens) tokens = stopwordFilter(tokens) tokens = stemmerFilter(tokens) return tokens} The tokenizer and filters convert sentences into a list of tokens: &gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] The tokens are ready for indexing. Building the indexBack to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs: type index map[string][]int Building the index consists of analyzing the documents and adding their IDs to the map: func (idx index) add(docs []document) { for _, doc := range docs { for _, token := range analyze(doc.Text) { ids := idx[token] if ids != nil &amp;&amp; ids[len(ids)-1] == doc.ID { // Don't add same ID twice. continue } idx[token] = append(ids, doc.ID) } }}func main() { idx := make(index) idx.add([]document{{ID: 1, Text: &quot;A donut on a glass plate. Only the donuts.&quot;}}) idx.add([]document{{ID: 2, Text: &quot;donut is a donut&quot;}}) fmt.Println(idx)} It works! Each token in the map refers to IDs of the documents that contain the token: map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]] QueryingTo query the index, we are going to apply the same tokenizer and filters we used for indexing: func (idx index) search(text string) [][]int { var r [][]int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { r = append(r, ids) } } return r} &gt; idx.search(&quot;Small wild cat&quot;)[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]] And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)! With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups. Boolean queriesThe query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type small wild cat in a search box is a list of results that contain small, wild and cat at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens. Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both: func intersection(a []int, b []int) []int { maxLen := len(a) if len(b) &gt; maxLen { maxLen = len(b) } r := make([]int, 0, maxLen) var i, j int for i &lt; len(a) &amp;&amp; j &lt; len(b) { if a[i] &lt; b[j] { i++ } else if a[i] &gt; b[j] { j++ } else { r = append(r, a[i]) i++ j++ } } return r} Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs: func (idx index) search(text string) []int { var r []int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { if r == nil { r = ids } else { r = intersection(r, ids) } } else { // Token doesn't exist. return nil } } return r} The Wikipedia dump contains only two documents that match small, wild and cat at the same time: &gt; idx.search(&quot;Small wild cat&quot;)130764 The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).131692 Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat. The search is working as expected! By the way, this is the first time I hear about catopuma, here is one of them: ConclusionsWe just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects. I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements: Extend boolean queries to support OR and NOT. Store the index on disk: Rebuilding the index on every application restart may take a while. Large indexes may not fit in memory. Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at Roaring Bitmaps. Support indexing multiple document fields. Sort results by relevance. The full source code is available on GitHub. I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!","link":"/2020/08/17/Let's%20build%20a%20Full-Text%20Search%20engine/"},{"title":"Shell入门","text":"Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell Shell编程之Hello World编写一个hello world shell一般使用.sh作为后缀 #!/bin/bash # 使用/bin/sh来解释执行 # auto echo hello world! # 解释这个脚本是干什么的# by authors cuzz # 作者和时间一些信息echo &quot;hello world!&quot; 给脚本添加执行权限 &gt; chmod +x hello.sh Shell编程之变量Shell变量可以分为两类：局部变量和环境变量 #!/bin/bash# define path variables# by authors cuzzname=cuzz # 等号两边不能有空格echo &quot;my name is $name&quot; # 使用$引用 基本变量 echo $PWD # 当前路径echo $0 # 脚本名echo $1 # 第一个参数echo $2 # 第二个参数echo $? # 判断上一个命令是否正确echo $* # 所有参数echo $# # 参数的个数 Shell编程之if条件语句比较大小 #!/bin/bash# if test# by authors cuzznum=100# 计算使用两个小括号if (($num &gt; 10)); then echo &quot;this num greater than 10.&quot;else echo &quot;this num littler than 10.&quot;fi 逻辑运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 目录 操作符 说明 举例 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 创建文件 #!/bin/bash# if test# by authors cuzzDIR=cuzzif [ ! -d $DIR ]; then # 都有空格 mkdir $DIR echo &quot;this $DIR create success.&quot;else echo &quot;this dir is exit.&quot;fi 测试文件是否存在 #!/bin/bash# if test# by authors cuzzfile=test.txtif [ ! -e $file ]; then echo &quot;OK&quot; &gt;&gt; $file # &gt;&gt;是追加内容 &gt;是覆盖内容else cat $filefi mysql备份 #!/bin/bash# auto backup mysql db# by authors cuzz# define backup pathBAK_DIR=/data/backup/`date +%Y%m%d` # 反引号可以把里面当作命令来解析 # mysqlMYSQLDB=testMYSQLUSER=rootMYSQLPW=123456MYSQLCMD=/usr/bin/mysqldump # 备份命令# 判断是否是rootif [ $UID -ne 0 ]; then echo &quot;Only root can execute Shell.&quot; exitfiif [ ! -d $BAK_DIR ]; then mkdir -p $BAK_DIR # -p 父目录不存在就创建 echo &quot;The $BAK_DIR create success.&quot;else echo &quot;This $BAK_DIR is exist.&quot;fi# mysql backup command$MYSQLCMD -u$MYSQLUSER -p$MYSQLPW -d $MYSQLDB &gt;$BAK_DIR/$MYSQLDB.sqlif [ $? -eq 0 ]; then echo &quot;backup success.&quot;else echo &quot;backup fail.&quot;fi Shell编程之for循环基本语句 #!/bin/bashfor i in `seq 1 15`do echo &quot;the number is $i.&quot;done 求和 #!/bin/bashsum=0for ((i=1; i&lt;=100; i++)) # 双括号用于运算相当与其他语言的单括号do sum=`expr $sum + $i` # expr用于计算doneecho &quot;$sum&quot; 打包，只能打包到最后一个，后面的会把前面的覆盖了 #!/bin/bashfor file in `find ./ -name &quot;*.sh&quot;`do tar -czf all.tgz $filedone Shell编程之while循环使用 #!/bin/bashi=0while [[ $i -lt 10 ]] # (( $i &lt; 10))是一样的do echo &quot;$i&quot; ((i++))done 结合read使用 #!/bin/bashwhile read line # 把读取的东西赋值给linedo echo $linedone &lt;/etc/hosts # 从哪里读取 Shell编程之数组Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： my_array=(A B &quot;C&quot; D) # 定义数组array_name[0]=value0 # 使用下标来定义array_name[1]=value1array_name[2]=value2${array_name[0]} # 读取第一个元素${my_array[*]} # 读取所有元素 ${my_array[@]} # 读取所有元素${#my_array[*]} # 读取数组长度${#my_array[@]} # 读取数组长度 Shell编程之函数无返回值得函数 sayHello(){ # 定义函数一 echo &quot;hello&quot;}function sayHelloWorld(){ # 定义函数二 echo &quot;hello world&quot;}sayhell # 使用函数 有返回值得，使用return只能返回0-255 function sum(){ returnValue=$(( $1 + $2 )) return $returnValue}sum 22 4echo $? 可以使用echo来传递参数 function length(){ str=$1 result=0 if [ &quot;$str&quot; != &quot;&quot; ] ; then result=${#str} fi echo &quot;$result&quot;}len=$(length &quot;abc123&quot;) # 调用echo &quot;The string's length is $len &quot; Shell编程之sed命令把test.txt中的old修改为new，要使用-i才能插入 &gt; sed -i 's/old/new/s' test.txt 在每行行前面添加一个cuzz &gt; sed -i sed 's/^/&amp;cuzz/g' test.txt 在每行的末尾添加一个cuzz &gt; sed -i 's/$/&amp; cuzz/g' test.txt 匹配某一行，在下方插入一行，找到cuzz这行在下方插入#### &gt; sed '/cuzz/a #######' test.txt 在之前添加一行，只要把a改成i &gt; sed '/cuzz/i #######' test.txt 打印 &gt; sed -n '/cuzz/p' test.txt # 打印含有cuzz这一行&gt; sed -n '1p' test.txt # 打印第一行&gt; sed -n '1,5p' text.txt # 打印1到5行 查找最大和最小值 number.txt 12 324 56 0034 -23 345345 349- 245 345 345 0989 0459 -25 命令 cat number.txt | sed 's/ /\\n/g' | grep -v &quot;^$&quot; | sort -nr | sed -n '1p;$p'sed 's/ /\\n/g' # 把所有空格换成换行grep -v &quot;^$&quot; # 去掉所有空格sort -nr # 降序排列sed -n '1p;$p # 找出第1行和最后一行 Shell编程之grep命令 -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’ 的次数 -i ：忽略大小写的不同，所以大小写视为相同 -n ：顺便输出行号 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行 –color=auto ：可以将找到的关键词部分加上颜色的显示 egrep 和grep -E 相同，可以使用正则表达式 Shell编程之awk命令# 每行按空格或TAB分割cat test.txt | awk '{print $1}' # 行匹配语句 awk '' 只能用单引号# 指定分割awk -F #-F相当于内置变量FS, 指定分割字符cat test.txt | awk -F: '{print $1}' # 以分号分割# 指定添加某些内容cat test.txt | awk -F: '{print &quot;haha&quot; $1}' # 提前出来再添加haha Shell编程之find命令基本命令 find /dir -name &quot;test.txt&quot; # 在/dir目录下查找find . -name &quot;test.txt&quot; # 在当前目录下找 find . -maxdepth 1 -name &quot;text.txt&quot; # 只遍历一层find . -type f -name &quot;text&quot; # 指定类型find . -name &quot;text&quot; -mtime -1 # 指定时间find . -size +20M # 指定大小 查找并执行其他命令 find . -name &quot;text.txt&quot; -exec rm -rf {} \\; # 后面{} \\是固定格式","link":"/2018/10/04/Shell%E5%85%A5%E9%97%A8/"},{"title":"Spring注解驱动开发（二）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 声明周期@Bean指定初始化和销毁方法Bean的生命周期Bean的创建、初始化和销毁是由容器帮我们管理的 我们可以自定义初始化和销毁方法，容器在进行到当前生命周期的时候来调用我买自定义的初始化和销毁方法 构造（对象创建） ​ 单实例： 在容器启动的时候创建 ​ 多实例： 在每次获取的时候创建对象 指定初始化方法初始化：对象创建完成后，并赋值化，调用初始化方法 销毁：单实例是在容器关闭的时候销毁，多实例容器不会管理这个Bean，容器不会调用销毁方法 编写一个Car类 /** * @Author: cuzz * @Date: 2018/9/23 21:20 * @Description: */public class Car { public Car () { System.out.println(&quot;car constructor...&quot;); } public void init() { System.out.println(&quot;car...init...&quot;); } public void destroy() { System.out.println(&quot;car...destroy...&quot;); }} 在xml中我们可以指定init-method和destroy-method方法，如 &lt;bean id=&quot;car&quot; class=&quot;com.cuzz.bean.Car&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt; 使用注解我们可以 /** * @Author: cuzz * @Date: 2018/9/24 12:49 * @Description: 配置类 */@Configurationpublic class MainConfigOfLifecycle { @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;) public Car car() { return new Car(); }} 测试 /** * @Author: cuzz * @Date: 2018/9/24 13:00 * @Description: */public class IOCTestLifeCycle { @Test public void test01() { // 创建ioc容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifecycle.class); System.out.println(&quot;容器创建完成...&quot;); // 关闭容器 System.out.println(&quot;---&gt;开始关闭容器&quot;); applicationContext.close(); System.out.println(&quot;---&gt;已经关闭容器&quot;); }} 可以看出先创建car，再调用init方法，在容器关闭时销毁实例 car constructor...car...init...容器创建完成...---&gt;开始关闭容器car...destroy...---&gt;已经关闭容器 在配置数据源的时候，有很多属性赋值，销毁的时候要把连接给断开 生命周期InitializingBean和DisposableBeanInitializingBean可以通过Bean实现InitializingBean来定义初始化逻辑，是设置好所有属性会调用afterPropertiesSet()方法 public interface InitializingBean { /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;} DisposableBean可以通过Bean实现DisposableBean来定义销毁逻辑，会调用destroy()方法 public interface DisposableBean { /** * Invoked by a BeanFactory on destruction of a singleton. * @throws Exception in case of shutdown errors. * Exceptions will get logged but not rethrown to allow * other beans to release their resources too. */ void destroy() throws Exception;} 例子编写一个Cat类 /** * @Author: cuzz * @Date: 2018/9/24 13:36 * @Description: */public class Cat implements InitializingBean, DisposableBean{ public Cat() { System.out.println(&quot;cat constructor...&quot;); } @Override public void afterPropertiesSet() throws Exception { System.out.println(&quot;cat...init...&quot;); } @Override public void destroy() throws Exception { System.out.println(&quot;cat...destroy...&quot;); }} 测试 cat constructor...cat...init...容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 生命周期@PostContruct和@PreDestroy注解@PostContruct在Bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy在容器销毁Bean之前通知我们进行清理工作 编写一个Dog类，并把他注入到配置类中 /** * @Author: cuzz * @Date: 2018/9/24 14:03 * @Description: */public class Dog { public Dog() { System.out.println(&quot;dog constructor...&quot;); } @PostConstruct public void postConstruct() { System.out.println(&quot;post construct...&quot;); } @PreDestroy public void preDestroy() { System.out.println(&quot;pre destroy...&quot;); }} 测试结果 dog constructor...post construct...容器创建完成...---&gt;开始关闭容器pre destroy...---&gt;已经关闭容器 生命周期BeanPostProscessor后置处理器我们先看看源码，解释的很清楚，BeanPostProscessor 中postProcessBeforeInitialization方法会在每一个bean对象的初始化方法调用之前回调；postProcessAfterInitialization方法会在每个bean对象的初始化方法调用之后被回调 。 /** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement {@link #postProcessBeforeInitialization}, * while post-processors that wrap beans with proxies will normally * implement {@link #postProcessAfterInitialization}. */public interface BeanPostProcessor { /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding {@code bean instanceof FactoryBean} checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * {@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation} method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;} 编写一个MyBeanPostProcessor实现BeanPostProcessor接口 /** * @Author: cuzz * @Date: 2018/9/24 14:21 * @Description: 后置处理器，初始化前后进行处理工作 */public class MyBeanPostProcessor implements BeanPostProcessor{ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessBeforeInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessAfterInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; }} 添加到配置中 @Configurationpublic class MainConfigOfLifecycle { @Bean public Cat cat() { return new Cat(); } @Bean public MyBeanPostProcessor myBeanPostProcessor() { return new MyBeanPostProcessor(); }} 测试 ---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765cat constructor...---&gt;postProcessBeforeInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207cat...init...---&gt;postProcessAfterInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 在实例创建之前后创建之后会被执行 生命周期BeanPostProcessor原理通过debug到populateBean，先给属性赋值在执行initializeBean方法 try { populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) { exposedObject = initializeBean(beanName, exposedObject, mbd); }} initializeBean方法时， protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) { Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 执行before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } ... try { // 执行初始化 invokeInitMethods(beanName, wrappedBean, mbd); } if (mbd == null || !mbd.isSynthetic()) { // 执行after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;} Spring底层对BeanPostProcessor的使用： Bean赋值、注入其他组件、@Autowired、生命周期注解功能、@Async等等都使用到了BeanPostProcessor这个接口的实现类，很重要 总结Bean 的初始化顺序 首先执行 bean 的构造方法 BeanPostProcessor 的 postProcessBeforeInitialization 方法 InitializingBean 的 afterPropertiesSet 方法 @Bean 注解的 initMethod方法 BeanPostProcesso r的 postProcessAfterInitialization 方法 DisposableBean 的 destroy 方法 @Bean注解的 destroyMethod 方法","link":"/2018/09/24/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Spring注解驱动开发（三）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 属性赋值@value赋值使用@Value赋值 基本数值 可以写SPEL表达式 #{} 可以${}获取配置文件信息（在运行的环境变量中的值） 使用xml时候导入配置文件是 &lt;context:property-placeholder location=&quot;classpath:person.properties&quot;/&gt; 使用注解可以在配置类添加一个@PropertySource注解把配置文件中k/v保存到运行的环境中 使用${key}来获取 /** * @Author: cuzz * @Date: 2018/9/24 18:43 * @Description: */@PropertySource(value = {&quot;classpath:/person.properties&quot;})@Configurationpublic class MainConfigOfPropertyValue { @Bean public Person person() { return new Person(); }} Person 类 @Datapublic class Person { @Value(&quot;vhuj&quot;) private String name; @Value(&quot;#{20-2}&quot;) private Integer age; @Value(&quot;${person.nickName}&quot;) private String nickName;} 测试 @Testpublic void test01() { printBean(applicationContext); System.out.println(&quot;---------------------------&quot;); Person person = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(person); System.out.println(&quot;---------------------------&quot;);} 输出 ---------------------------Person(name=vhuj, age=18, nickName=三三)--------------------------- 自动装配@Autowired@Qualifier@Primary自动转配： Spring利用依赖注入（DI），完成对IOC容器中各个组件的依赖关系赋值 @Autowired自动注入: a. 默认优先按照类型去容器中寻找对应的组件，如果找到去赋值 b. 如果找到到相同类型的组件，再将属性名（BookDao bookdao）作为组件的id去容器中查找 c. 接下来还可以使用@Qualifier(&quot;bookdao&quot;)明确指定需要装配的id d. 默认是必须的，我们可以指定 @Autowired(required=false)，指定非必须 @Primary让Spring自动装配时首先装配 自动装配@Resource和@InjectSpring还支持使用@Resource (JSR250) 和@Inject (JSR330) 注解，这两个是java规范 @Resource和@Autowired一样实现自动装配功能，默认是按组件名称进行装配的 没有支持@Primary和@Autowird(required=false)的功能 自动装配其他地方的自动装配@Autowired：构造器、参数、方法属性等 标注到方法位子上@Bean+方法参数，参数从容器中获取 /** * @Author: cuzz * @Date: 2018/9/24 20:57 * @Description: */public class Boss { // 属性 @Autowired private Car car; // 构造器 如果构造器只有一个有参构造器可以省略 @Autowired public Boss(@Autowired Car car) { } public Car getCar() { return car; } // set方法 @Autowired // 参数 public void setCar(@Autowired Car car) { this.car = car; }} 自动装配Aware注入Spring底层注解自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory 等等），自定义组件实现xxxAware，在创建对象的时候会调用接口规定的方法注入相关的组件 /** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. */public interface Aware {} 我们实现几个常见的Aware接口 /** * @Author: cuzz * @Date: 2018/9/25 10:18 * @Description: */@Componentpublic class Red implements BeanNameAware ,BeanFactoryAware, ApplicationContextAware { private ApplicationContext applicationContext; @Override public void setBeanName(String name) { System.out.println(&quot;当前Bean的名字: &quot; + name); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;当前的BeanFactory: &quot; + beanFactory); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; System.out.println(&quot;传入的ioc: &quot; + applicationContext); }} 注入到配置中测试 /** * @Author: cuzz * @Date: 2018/9/25 10:28 * @Description: */public class IOCTestAware { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAware.class); }} 测试结果 当前Bean的名字: red当前的BeanFactory: org.springframework.beans.factory.support.DefaultListableBeanFactory@159c4b8: defining beans [org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,mainConfigOfAware,red]; root of factory hierarchy传入的ioc: org.springframework.context.annotation.AnnotationConfigApplicationContext@1e89d68: startup date [Tue Sep 25 10:29:17 CST 2018]; root of context hierarchy 把Spring自定义组件注入到容器中 原理： public interface ApplicationContextAware extends Aware {} 通过 Debug 方式，定位到 org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization @Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { invokeAwareInterfaces(bean); return null; } }, acc); } else { invokeAwareInterfaces(bean); // 调用 } 调用下面方法进行判断，每种 xxxAware 接口中只有一种方法，并调用相应的方法 private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } }} xxxAware都是通过xxxProcessor来处理的 比如：ApplicationContextAware 对应 ApplicationContextAwareProcessor 自动装配@Profile环境搭建Profile是Spring为我们提供可以根据当前环境，动态的激活和切换一系组件的功能 a. 使用命令动态参数激活：虚拟机参数位子加载 -Dspring.profiles.active=test b. 使用代码激活环境 我们想配置类 /** * @Author: cuzz * @Date: 2018/9/25 10:47 * @Description: */@Configurationpublic class MainConfigOfProfile { @Profile(value = &quot;test&quot;) @Bean(value = &quot;testDataSource&quot;) public DataSource testDataSource() { System.out.println(&quot;testDataSource&quot;); return null; } @Profile(value = &quot;dev&quot;) @Bean(value = &quot;devDataSource&quot;) public DataSource devDataSource() { System.out.println(&quot;devDataSource&quot;); return null; }} 测试 /** * @Author: cuzz * @Date: 2018/9/25 10:59 * @Description: */public class IOCTestProfile { @Test public void test01() { // 1. 使用无参构造器创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置要激活的环境 applicationContext.getEnvironment().setActiveProfiles(&quot;test&quot;); // 3. 注册主配置类 applicationContext.register(MainConfigOfProfile.class); // 4. 启动刷新容器 applicationContext.refresh(); }} 输出 testDataSource","link":"/2018/09/25/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Understanding Object Oriented Programming","text":"这是一篇很早的文章，讲的关于面向对象，原文地址：Understanding Object Oriented Programming。这里有关于这篇文章的评论如此理解面向对象编程，很有有趣。我觉得这篇作为一篇入门讲面向对象的例子还是很不错的，通过不同的例子讲述了不同人的实现想法。最后用策略模式+工厂模式来实现，来达到消除if-else。 The code on this page grew out of a discussion on the Object Technology in Computer Science Education list server. The discussion had been going on for about 36 hours in late March and early April 2000 centered on the question of “What is OO really; is it a real paradigm, different from procedural programming or is it just a packaging mechanism for procedural programming?” Both of the authors believe that it is a real paradigm shift, requiring a change in mental model in the practitioners. Winder produced the first three of the following code fragments to show the difference in styles between hackers, procedural programmers, and (naive) object oriented programmers. Bergin then added the more sophisticated OO version that appears last. TheProblemThe problem to be solved is to output a value judgment about operating systems. The assumptions being (of course) that UNIX is good and Windows is bad. Hacker Solutionpublic class PrintOS { public static void main(final String[] args) { String osName = System.getProperty(&quot;os.name&quot;); if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { System.out.println(&quot;This is a UNIX box and therefore good.&quot;); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { System.out.println(&quot;This is a Windows box and therefore bad.&quot;); } else { System.out.println(&quot;This is not a box.&quot;); } }} Their claim: It works doesn’t it what more do you want? Also I got mine implemented and working faster than any of the others, so there. Evaluation: While this solves the problem, it would not be easy to modify in the future if the problem changes. In particular, if we need to add new operating systems, we need to extend the if structure. If we want to add additional functionality for each operating system, we would likely see this expand to nested if statements. This would get unwieldy over time. Thus, the hacker has solved the immediate problem, but made little progress on future evolution of the program. Procedural Solutionpublic class PrintOS { private static String unixBox() { return &quot;This is a UNIX box and therefore good.&quot;; } private static String windowsBox() { return &quot;This is a Windows box and therefore bad.&quot;; } private static String defaultBox() { return &quot;This is not a box.&quot;; } private static String getTheString(final String osName) { if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { return unixBox(); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { return windowsBox(); } else { return defaultBox(); } } public static void main(final String[] args) { System.out.println(getTheString(System.getProperty(&quot;os.name&quot;))); }} Their claim: Java is a wonderful procedural programming language; it naturally supports top-down decomposition which is clearly the only way of analyzing and designing quality solutions to problems – as exemplified by this example. Evaluation: The procedural programmer has made some progress on the larger problem. If an operating system needs to be added, we extend the if statement in the getTheString function and add a new function for that OS. However, if the functionality of each OS needs to be extended, what we are likely to see is that the if statement will most likely be replicated elsewhere in the program each time we need to make the distinction between operating systems. Once that happens, whenever we add a new OS or change or add functionality we will need to find ALL of these if statements and update them compatibly*. This is very error prone and results in entropy setting into such programs over time. In effect the programmer is using ad-hoc polymorphism. We want different things to happen, but the programmer must specifically make the choice of what is to happen in each instance. Naive Object Oriented SolutionThis solution requires several classes in several files. // PrintOS.javapublic class PrintOS { public static void main(final String[] args) { System.out.println(OSDiscriminator.getBoxSpecifier().getStatement()); }}// ---------------// OSDiscriminator.javapublic class OSDiscriminator { // Factory Pattern private static BoxSpecifier theBoxSpecifier = null; public static BoxSpecifier getBoxSpecifier() { if (theBoxSpecifier == null) { String osName = System.getProperty(&quot;os.name&quot;); if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { theBoxSpecifier = new UNIXBox(); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { theBoxSpecifier = new WindowsBox(); } else { theBoxSpecifier = new DefaultBox(); } } return theBoxSpecifier; }}// ---------------// BoxSpecifier.javapublic interface BoxSpecifier { String getStatement();}// ---------------// DefaultBox.javapublic class DefaultBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is not a box.&quot;; }}// ---------------// UNIXBox.javapublic class UNIXBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is a UNIX box and therefore good.&quot;; }}// ---------------// WindowsBox.javapublic class WindowsBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is a Windows box and therefore bad.&quot;; }} Their claim: Well I managed to get both Singleton and Factory Method into the implementation so according to all the hype about object-oriented programming and patterns it must be good. Note: The factory here is a kind of naive singleton. Evaluation This programmer has made quite a lot more progress toward the goal of writing a maintainable program. In particular, if we need to add an OS, we extend the if statement as before, and write a new class for that OS. This is similar to what the procedural programmer had to do. However, if we need to add functionality for each OS, we only need to change the classes that deal with that OS. The if statement in OSDiscriminator is still a “logic bottleneck” but it is the only one in the program. This means that the location of change is easy to find (the classes that implement the functionality). Also, if we add functionality by changing the interface BoxSpecifier, then the compiler will tell us if some class fails to implement the new required functionality. We won’t have to search the program for the locus of each change with no help from the tools. However, this solution still does ad-hoc polymorphism in the if statement. Object oriented programming attempts to remove all such ad-hoc decision making. Every if and every switch should be viewed as a lost opportunity for dynamic polymorphism. If we can replace this with dynamic polymorphism then the program will be much easier to maintain. Sophisticated Object Oriented + Patterns SolutionIn the following, PrintOS.java and BoxSpecifier.java are unchanged from the above. // PrintOS.javapublic class PrintOS { public static void main(final String[] args) { System.out.println(OSDiscriminator.getBoxSpecifier().getStatement()); }}// ----------// OSDiscriminator.javapublic class OSDiscriminator {// Factory Pattern private static java.util.HashMap storage = new java.util.HashMap(); public static BoxSpecifier getBoxSpecifier() { BoxSpecifier value = (BoxSpecifier) storage.get(System.getProperty(&quot;os.name&quot;)); if (value == null) return DefaultBox.value; return value; } public static void register(final String key, final BoxSpecifier value) { storage.put(key, value); // Should guard against null keys, actually. } static { WindowsBox.register(); UNIXBox.register(); MacBox.register(); }}// ----------// BoxSpecifier.javapublic interface BoxSpecifier { String getStatement();}// ----------// DefaultBox.javapublic class DefaultBox implements BoxSpecifier {// Singleton Pattern public static final DefaultBox value = new DefaultBox(); private DefaultBox() { } @Override public String getStatement() { return &quot;This is not a box.&quot;; }}// ----------// UNIXBox.javapublic class UNIXBox implements BoxSpecifier {// Singleton Pattern public static final UNIXBox value = new UNIXBox(); private UNIXBox() { } @Override public String getStatement() { return &quot;This is a UNIX box and therefore good.&quot;; } public static final void register() { OSDiscriminator.register(&quot;SunOS&quot;, value); OSDiscriminator.register(&quot;Linux&quot;, value); }}// ----------// WindowsBox.javapublic class WindowsBox implements BoxSpecifier {// Singleton Pattern public static final WindowsBox value = new WindowsBox(); private WindowsBox() { } @Override public String getStatement() { return &quot;This is a Windows box and therefore bad.&quot;; } public static final void register() { OSDiscriminator.register(&quot;Windows NT&quot;, value); OSDiscriminator.register(&quot;Windows 95&quot;, value); }}// ----------// MacBox.javapublic class MacBox implements BoxSpecifier { // Singleton Pattern public static final MacBox value = new MacBox(); private MacBox() { } @Override public String getStatement() { return &quot;This is a Macintosh box and therefore far superior.&quot;; } public static final void register() { OSDiscriminator.register(&quot;Mac OS&quot;, value); }} Their claim: Aaaaahhhhh. And besides, I added important functionality – Mac OS. Evaluation Here we have turned the OS objects into singletons, so there can be only one such object in each of these classes. This may be desirable or not. If it is not, then the factory wouldn’t return the objects in the hash table, but would return clones of them instead. Here we have maintainable code. To add a new OS, like the Mac OS, we just add a new class and add its registration to the factory. To change the functionality we change the OS classes. To add new functionality, we either modify the OS classes, or extend them. Note that there is NO ad-hoc polymorphism here except the single test for null in the factory. DeconstructionWhether it is clear or not, the mental processes of the programmers who wrote these different versions was quite different. The hacker wanted to get the immediate job done at all cost. The procedural programmer views the nature of computation as a decomposition of a function into sub-functions (helper functions) that solve sub-problems. The object-oriented programmers see the nature of computation as a swarm of interacting agents that provide services for other objects. Further, the sophisticated OO programmer lets the system take care of all polymorphic tasks possible. This programmer sees the essence of object oriented programming as the naive object-oriented programmer may not. NotesSingleton and Factory are discussed in Design Patterns by Gamma, Helm, Johnson, and Vlissides (Addison-Wesley, 1995). This is the now famous “Gang of Four” or GOF book. The DefaultBox is a kind of Null Object. This pattern is by Bobby Wolfe and can be found in Pattern Languages of Program Design 3, edited by Martin, Riehle, and Buschmann (Addison-Wesley, 1998) While object oriented programmers try to avoid ad-hoc polymorphism it isn’t always possible. The hard-to-impossible cases are when dealing with primitive (non-object) data in hybrid languages like Java, parsing input, and when creating new objects. Here, however, we have solved the creational problem with a simple factory containing singletons. The creational problem can be solved in general through the use of reflection, such as the Java Reflection API. The other situations are less tractable. For more on ad-hoc polymorphism, see Bergin’s Selection Patterns.For more on dynamic polymorphism, see Bergin’s Polymorphism Patterns.For more on how the object oriented programmer thinks, see Bergin’s Object Patterns. MoreHere is another perspective on the same ideas from out friend and colleague Dung X. Nguyen of Rice University. By the way, Dung has done a lot with using patterns to enhance object-oriented code seen by students. He often works with Stephen Wong of Oberlin College. They have some nice papers on this in the last few SIGCSE conference proceedings. Note: For a discussion on why replicated code, such as that in the if structure of the procedural solution, is bad see Kent Beck’s discussion on OnceAndOnlyOnce on the Wiki Wiki Web. Last Updated: July 30, 2000","link":"/2020/08/25/Understanding%20Object%20Oriented%20Programming/"},{"title":"关于null的思考","text":"写代码的时候有个地方需要把 Integer 类型强转为 String Integer firstEventType = eventTask.getEventType1();String firstEventTypeName = eventTypeService.queryDescByCode(String.valueOf(firstEventType)); 当我点开 String#valueof 这个静态方式时 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();} 当我们没有获取到 firstEventType 这个值时，为 null，此时它返回给我们的是字符串 “null” ，有时候就不符合我们的业务场景，最好是提前做空值判断。 看下面一个例子 Integer i = null;System.out.println(String.valueOf(i)); // 输出 nullSystem.out.println(String.valueOf(null)); // 空指针 感觉很奇怪，竟然输出结果不一样。 看看这两个重载方法 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();}public static String valueOf(char data[]) { return new String(data);} 凭直觉来看以为String.valueOf(null) 会选择第一做为 valueOf(Object obj) 这个从载方法，然而选择的是valueOf(char data[]) 所以会报空指针异常。 下面是查到官方文档 https://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.12.2.5 如果第一个方法处理的任何调用都可以传递给另一个没有编译时类型错误的调用，那么一个方法比另一个方法更具体。 从意思来看 valueOf(char data[]) 比 valueOf(Object obj) 更具体。 我们非常痛恨的 null 到底是什么 Java 语言定义 There is also a special null type, the type of the expression null, which has no name. Because the null type has no name, it is impossible to declare a variable of the null type or to cast to the null type. The null reference is the only possible value of an expression of null type. The null reference can always be cast to any reference type. In practice, the programmer can ignore the null type and just pretend that null is merely a special literal that can be of any reference type.","link":"/2019/06/03/%E5%85%B3%E4%BA%8Enull%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"Spring注解驱动开发（四）","text":"AOP面向切面编程AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 底层实现Spring 的 AOP 的底层用到两种代理机制： JDK 的动态代理 ：类必须实现接口，所以是针对实现了接口的类产生代理. Cglib 的动态代理：针对没有实现接口的类产生代理，应用的是底层的字节码增强的技术生成当前类的子类对象 JDK 的动态代理 UserService接口，实现增删改查的功能 package com.cuzz.service;public interface UserService { void add(); void delete(); void update(); void get();} UserService接口的实现的类 public class UserServiceImpl implements UserService { @Override public void add() { System.out.println(&quot;添加一个user&quot;); } @Override public void delete() { System.out.println(&quot;删除一个user&quot;); } @Override public void update() { System.out.println(&quot;更新一个user&quot;); } @Override public void get() { System.out.println(&quot;查询一个user&quot;); }} 实现动态代理 package com.cuzz.service;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class UserServiceProxyFactory implements InvocationHandler{ private UserService us; public UserServiceProxyFactory(UserService us) { super(); this.us = us; } // 获得动态代理 public UserService getUserServiceProxy() { // 生成动态代理 UserService usProxy = (UserService) Proxy.newProxyInstance(UserServiceProxyFactory.class.getClassLoader(), UserServiceImpl.class.getInterfaces(), this); // 这个 this 就是实现 InvocationHandler 的对象 return usProxy; } @Override public Object invoke(Object arg0, Method method, Object[] arg2) throws Throwable { System.out.println(&quot;打开事务!&quot;); Object invoke = method.invoke(us, arg2); System.out.println(&quot;提交事务!&quot;); return invoke; }} 测试 public class TestDemo { @Test public void test01(){ UserService us = new UserServiceImpl(); UserServiceProxyFactory factory = new UserServiceProxyFactory(us); UserService usProxy = factory.getUserServiceProxy(); usProxy.add(); }} 输出 打开事务!添加一个user提交事务! Cglib 的动态代理 Cglib 的动态代理的代码实现 package com.cuzz.service;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class UserServiceProxyFactory2 implements MethodInterceptor { public UserService getUserServiceProxy(){ // 帮我们生成代理对象 Enhancer en = new Enhancer(); // 设置对谁进行代理 en.setSuperclass(UserServiceImpl.class); // 代理要做什么 en.setCallback(this); // 创建代理对象 UserService us = (UserService) en.create(); return us; } @Override public Object intercept(Object prxoyobj, Method method, Object[] arg, MethodProxy methodProxy) throws Throwable { // 打开事务 System.out.println(&quot;打开事务!&quot;); // 调用原有方法 Object returnValue = methodProxy.invokeSuper(prxoyobj, arg); // 提交事务 System.out.println(&quot;提交事务!&quot;); return returnValue; }} 测试 @Testpublic void test02() { UserServiceProxyFactory2 factory = new UserServiceProxyFactory2(); UserService usProxy = factory.getUserServiceProxy(); usProxy.add();} Spring的AOP开发(基于AspectJ)AOP的开发中的相关术语： Joinpoint(连接点)：所谓连接点是指那些被拦截到的点，在 spring 中这些点指的是方法，因为 spring 只支持方法类型的连接点 Pointcut(切入点)：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义 Advice(通知/增强)：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介)：引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target(目标对象)：代理的目标对象 Weaving(织入)：是指把增强应用到目标对象来创建新的代理对象的过程，spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装在期织入 Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类 Aspect(切面)：是切入点和通知（引介）的结合 通知类型 前置通知 ：在目标方法执行之前执行 后置通知 ：在目标方法执行之后执行 环绕通知 ：在目标方法执行前和执行后执行 异常抛出通知：在目标方法执行出现异常的时候执行 最终通知 ：无论目标方法是否出现异常 最终通知都会执行 代码演示通知类，给切面的目标方法标注何时地运行，必须告诉 Spring 哪个类是切面类，添加注解 @Aspect @Aspect // 表示该类是一个通知类public class MyAdvice { // 前置通知 @Before(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void before(){ System.out.println(&quot;这是前置通知!!&quot;); } // 后置通知 @AfterReturning(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterReturning(){ System.out.println(&quot;这是后置通知(如果出现异常不会调用)!!&quot;); } // 环绕通知 @Around(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(&quot;这是环绕通知之前的部分!!&quot;); // 调用目标方法 Object proceed = pjp.proceed(); System.out.println(&quot;这是环绕通知之后的部分!!&quot;); return proceed; } // 异常通知 @AfterThrowing(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterException(){ System.out.println(&quot;出事啦!出现异常了!!&quot;); } // 后置通知 @After(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void after(){ System.out.println(&quot;这是后置通知(出现异常也会调用)!!&quot;); }} 配置类，将切面类和业务逻辑类都加入到容器中，给配置类加 @EnableAspectJAutoProxy 注解 /** * @Author: cuzz * @Date: 2019/2/10 20:43 * @Description: */@Configuration@EnableAspectJAutoProxypublic class MainConfigOfAOP { @Bean public UserService userService() { return new UserServiceImpl(); } @Bean public MyAdvice myAdvice() { return new MyAdvice(); }} 测试 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); UserService userService = (UserService) applicationContext.getBean(&quot;userService&quot;); userService.add(); userService.delete(); userService.update(); userService.get();} 如果报错添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt;","link":"/2019/02/10/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"分布式事务框架Seata","text":"分布式基础CAP 定理CAP 定理指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得。在分布式系统中，分区容错性是必须需要实现的。所以只能在一致性和可用性之间进行权衡（AP 或者 CP）。 BASE 理论BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的缩写。是对 CAP 中 AP 的一个扩展 BA 基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 S 软状态：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。 E 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。 BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 分布式事务实现方式 XA 方案(两阶段提交) TCC 方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 Seata简介Seata (Simple Extensible Autonomous Transaction Architecture) 是阿里巴巴开源的分布式事务中间件，，解决微服务场景下面临的分布式事务问题。 具体看 Seata 官网： Seata主要由三个重要组件组成： Transaction Coordinator(TC)：管理全局的分支事务的状态，用于全局性事务的提交和回滚。 Transaction Manager(TM)：事务管理器，用于开启全局事务、提交或者回滚全局事务，是全局事务的开启者。 Resource Manager(RM)：资源管理器，用于分支事务上的资源管理，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务。 Seata 两种模式Seata 关注的就是微服务架构下的数据一致性问题，是一整套的分布式事务解决方案。Seata 框架包含两种模式，一种是 AT 模式。AT 模式主要从数据分片的角度，关注多 DB 访问的数据一致性，当然也包括多服务下的多 DB 数据访问一致性问题。 另外一个就是 TCC 模式，TCC 模式主要关注业务拆分，在按照业务横向扩展资源时，解决微服务间调用的一致性问题，保证读资源访问的事务属性。 AT 模式AT 模式是通过两段提交的方式实现，AT 模式下，把每个数据库被当做是一个 Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。 这就是我们的 AT 模式。简单总结一下，就是把每个数据库当做一个 Resource，在本地事务提交时会去注册一个分支事务。 这种模式是对业务零入侵，并发没那么高。 TCC 模式TCC 模型是把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm / Cancel 接口。 TCC 模式本质也是 2PC ，只是 TCC 在应用层控制。 Try: 尝试执行业务 完成所有业务检查（一致性） 预留必须业务资源（准隔离性） Confirm: 确认执行业务； 真正执行业务，不作任何业务检查 只使用Try阶段预留的业务资源 Confirm 操作满足幂等性 Cancel: 取消执行业务 释放Try阶段预留的业务资源 Cancel操作满足幂等性 这三个阶段，都会按本地事务的方式执行。不同于 XA 的 prepare ，TCC 无需将 XA 的投票期间的所有资源挂起，因此极大的提高了吞吐量。 那么对应到 TCC 模式里，也是一样的，Seata 框架把每组 TCC 接口当做一个 Resource，称为 TCC Resource。这套 TCC 接口可以是 RPC，也以是服务内 JVM 调用。在业务启动时，Seata 框架会自动扫描识别到 TCC 接口的调用方和发布方。如果是 RPC 的话，就是 sofa:reference、sofa:service、dubbo:reference、dubbo:service 等。 扫描到 TCC 接口的调用方和发布方之后。如果是发布方，会在业务启动时向 TC 注册 TCC Resource，与 DataSource Resource 一样，每个资源也会带有一个资源 ID。 如果是调用方，Seata 框架会给调用方加上切面，与 AT 模式一样，在运行时，该切面会拦截所有对 TCC 接口的调用。每调用一次 Try 接口，切面会先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。当请求链路调用完成后，TC 通过分支事务的资源 ID 回调到正确的参与者去执行对应 TCC 资源的 Confirm 或 Cancel 方法。 在讲完了整个框架模型以后，大家可能会问 TCC 三个接口怎么实现。因为框架本身很简单，主要是扫描 TCC 接口，注册资源，拦截接口调用，注册分支事务，最后回调二阶段接口。最核心的实际上是 TCC 接口的实现逻辑。下面我将根据蚂蚁金服内部多年的实践来为大家分析怎么实现一个完备的 TCC 接口。 运行 Demo官方Demo 下面是 dubbo 的例子，运行后报错可以看到回滚信息： INFO [rpcDispatch_RMROLE_4_8] - onMessage:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchType=AT,resourceId=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC,applicationData=null INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacking: 10.116.22.63:8091:2016481020 2016481022 jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC INFO [rpcDispatch_RMROLE_4_8] - xid 10.116.22.63:8091:2016481020 branch 2016481022, undo_log deleted with GlobalFinished INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacked result: PhaseTwo_RollbackedDEBUG [rpcDispatch_RMROLE_4_8] - branch rollback result:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null INFO [rpcDispatch_RMROLE_4_8] - RmRpcClient sendResponse xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =nullDEBUG [rpcDispatch_RMROLE_4_8] - send response:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null,channel:[id: 0xc8027ef7, L:/127.0.0.1:62873 - R:/127.0.0.1:8091] 注意： 数据库驱动与 Mysql 版本一致 数据库 rul 添加时区 jdbc.account.url=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC 参考链接Seata AT 模式分布式事务源码分析 分布式事务 Seata TCC 模式深度解析","link":"/2019/07/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6Seata/"},{"title":"Java 反射","text":"Reflection is a feature in the Java programming language. It allows an executing Java program to examine or “introspect” upon itself, and manipulate internal properties of the program. For example, it’s possible for a Java class to obtain the names of all its members and display them. The ability to examine and manipulate a Java class from within itself may not sound like very much, but in other programming languages this feature simply doesn’t exist. For example, there is no way in a Pascal, C, or C++ program to obtain information about the functions defined within that program. One tangible use of reflection is in JavaBeans, where software components can be manipulated visually via a builder tool. The tool uses reflection to obtain the properties of Java components (classes) as they are dynamically loaded. 类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载 就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接 验证：是否有正确的内部结构，并和其他类协调一致 准备：负责为类的静态成员分配内存，并设置默认初始化值 解析：将类的二进制数据中的符号引用替换为直接引用 初始化 对类的静态变量，静态代码块执行初始化操作 类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类 类加载器作用 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行 类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader 扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader 系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法 Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单） Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可） Class c3 = Class.forName(&quot;cn.cuzz.Person&quot;); 注意：第三种和前两种的区别 前两种你必须明确Person类型。 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了。 Person类public class Person { // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() { System.out.println(&quot;空参数构造方法&quot;); } public Person(String name) { this.name = name; System.out.println(&quot;带有String的构造方法&quot;); } // 私有的构造方法 private Person(String name, int age){ this.name = name; this.age = age; System.out.println(&quot;带有String，int的构造方法&quot;); } public Person(String name, int age, String address){ this.name = name; this.age = age; this.address = address; System.out.println(&quot;带有String, int, String的构造方法&quot;); } // 成员方法 // 没有返回值没有参数的方法 public void method1(){ System.out.println(&quot;没有返回值没有参数的方法&quot;); } // 没有返回值，有参数的方法 public void method2(String name){ System.out.println(&quot;没有返回值，有参数的方法 name= &quot;+ name); } // 有返回值，没有参数 public int method3(){ System.out.println(&quot;有返回值，没有参数的方法&quot;); return 123; } // 有返回值，有参数的方法 public String method4(String name){ System.out.println(&quot;有返回值，有参数的方法&quot;); return &quot;哈哈&quot; + name; } // 私有方法 private void method5(){ System.out.println(&quot;私有方法&quot;); } @Override public String toString() { return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;, address=&quot; + address+ &quot;]&quot;; }} 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的) package cn.cuzz;import java.lang.reflect.Constructor;public class Test { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException { // 获取Class对象 包名.类 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); }} 通过反射方式，获取构造方法，创建对象获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] }} 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有) package cn.cuzz;import java.lang.reflect.Field;public class Test3 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField(&quot;age&quot;); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField(&quot;address&quot;); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address }} 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 { public static void main(String[] args) throws IllegalAccessException, Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;); // 获取指定成员变量 // public String name Field nameField = c.getField(&quot;name&quot;); // public int age Field ageField = c.getField(&quot;age&quot;); // 赋值 nameField.set(obj, &quot;Cuzz&quot;); ageField.set(obj, 23); System.out.println(&quot;name = &quot;+ nameField.get(obj)); // name = Cuzz System.out.println(&quot;age = &quot;+ ageField.get(obj)); // age = 23 }} 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的) package cn.cuzz;import java.lang.reflect.Method;public class Test5 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod(&quot;method1&quot;, null); System.out.println(method); // public String method4(String name){ method = c.getMethod(&quot;method4&quot;, String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod(&quot;method5&quot;, null); System.out.println(method); }} 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true)) public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); // 获取指定的方法 Method m4 = c.getMethod(&quot;method4&quot;, String.class); // 执行找到的方法 Object result = m4.invoke(obj, &quot;2018/03/19&quot;); System.out.println(&quot;result = &quot; + result); // result = 哈哈2018/03/19 }} 反射练习下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素。 package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 { public static void main(String[] args) throws Exception, SecurityException { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(&quot;cuzz&quot;); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName(&quot;java.util.ArrayList&quot;); // 找到add()方法 Method addMethod = c.getMethod(&quot;add&quot;, Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] }} 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法 public class Test8 { public static void main(String[] args) throws Exception{ // IO流读取配置文件 FileReader r = new FileReader(&quot;config.properties&quot;); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty(&quot;className&quot;); String methodName = pro.getProperty(&quot;methodName&quot;); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); }} 配置文件 # className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work","link":"/2019/02/11/Java%20%E5%8F%8D%E5%B0%84/"},{"title":"JVM 面试","text":"JVM 垃圾回收的时候如何确定垃圾？知道什么是 GC Roots ? 什么是垃圾 简单来说就是内存中已经不在被使用到的空间就是垃圾 要进行垃圾回收，如何判断一个对象是否可以被回收？ 引用计数法 枚举根节点做可达性分析 为了解决引用计数法的循环引用问题，Java 使用了可达性算法。 跟踪收集器采用的为集中式的管理方式，全局记录对象之间的引用状态，执行时从一些列GC Roots的对象做为起点，从这些节点向下开始进行搜索所有的引用链，当一个对象到GC Roots 没有任何引用链时，则证明此对象是不可用的。 图中，对象Object6、Object7、Object8虽然互相引用，但他们的GC Roots是不可到达的，所以它们将会被判定为是可回收的对象。 哪些对象可以作为 GC Roots 的对象： 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法去常量引用的对象 本地方法栈中 JNI (Native方法)引用的对象 你说你做过 JVM 调优和参数配置，请问如果盘点查看 JVM 系统默认值？JVM 的参数类型: 标配参数 -version -help X 参数（了解） -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 XX 参数 Boolean 类型：-XX：+ 或者 - 某个属性值（+ 表示开启，- 表示关闭） -XX:+PrintGCDetails：打印 GC 收集细节 -XX:-PrintGCDetails：不打印 GC 收集细节 -XX:+UseSerialGC：使用了串行收集器 -XX:-UseSerialGC：不使用了串行收集器 KV 设置类型：-XX:key=value -XX:MetaspaceSize=128m -XX:MaxTenuringThreshold=15 jinfo 举例，如何查看当前运行程序的配置 public class HelloGC { public static void main(String[] args) { System.out.println(&quot;hello GC...&quot;); try { Thread.sleep(Integer.MAX_VALUE); } catch (InterruptedException e) { e.printStackTrace(); } }} 我们可以使用 jps -l 命令，查出进程 id 1923 org.jetbrains.jps.cmdline.Launcher1988 sun.tools.jps.Jps1173 org.jetbrains.kotlin.daemon.KotlinCompileDaemon32077 com.intellij.idea.Main1933 com.cuzz.jvm.HelloGC32382 org.jetbrains.idea.maven.server.RemoteMavenServer 在使用 jinfo -flag PrintGCDetails 1933 命令查看 -XX:-PrintGCDetails 可以看出默认是不打印 GC 收集细节也可是使用jinfo -flags 1933 查看所以的参数 两个经典参数：-Xms 和 - Xmx（如 -Xms1024m） -Xms 等价于 -XX:InitialHeapSize -Xmx 等价于 -XX:MaxHeapSize 盘点家底查看 JVM 默认值 查看初始默认值：-XX:+PrintFlagsInitialcuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintFlagsInitial[Global flags] intx ActiveProcessorCount = -1 {product} uintx AdaptiveSizeDecrementScaleFactor = 4 {product} uintx AdaptiveSizeMajorGCDecayTimeScale = 10 {product} uintx AdaptiveSizePausePolicy = 0 {product} uintx AdaptiveSizePolicyCollectionCostMargin = 50 {product} uintx AdaptiveSizePolicyInitializingSteps = 20 {product} uintx AdaptiveSizePolicyOutputInterval = 0 {product} uintx AdaptiveSizePolicyWeight = 10 {product} ... 查看修改更新：-XX:+PrintFlagsFinalbool UsePSAdaptiveSurvivorSizePolicy = true {product}bool UseParNewGC = false {product}bool UseParallelGC := true {product}bool UseParallelOldGC = true {product}bool UsePerfData = true {product}bool UsePopCountInstruction = true {product}bool UseRDPCForConstantTableBase = false {C2 product} = 与 := 的区别是，一个是默认，一个是人物改变或者 jvm 加载时改变的参数 打印命令行参数(可以看默认垃圾回收器)：-XX:+PrintCommandLineFlagscuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintCommandLineFlags-XX:InitialHeapSize=128789376 -XX:MaxHeapSize=2060630016 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 你平时工作用过的 JVM 常用的基本配置参数有哪些？ -Xms 初始大小内存，默认为物理内存 1/64 等价于 -XX:InitialHeapSize -Xmx 最大分配内存，默认为物理内存的 1/4 等价于 -XX:MaxHeapSize -Xss 设置单个线程栈的大小，一般默认为 512-1024k 等价于 -XX:ThreadStackSize -Xmn 设置年轻代的大小 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小，持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:MetaspaceSize 设置元空间大小（元空间的本质和永久代类似，都是对 JVM 规范中的方法区的实现，不过元空间于永久代之间最大区别在于，元空间并不在虚拟中，而是使用本地内存，因此默认情况下，元空间的大小仅受本地内存限制） 元空间默认比较小，我们可以调大一点 -XX:+PrintGCDetails 输出详细 GC 收集日志信息 设置 JVM 参数为： -Xms10m -Xmx10m -XX:+PrintGCDetails -XX:SurvivorRatio 设置新生代中 eden 和 S0/S1 空间比例 默认 -XX:SurvivorRatio=8，Eden : S0 : S1 = 8 : 1 : 1 -XX:NewRatio 配置年轻代和老年代在堆结构的占比 默认 -XX:NewRatio=2 新生代占1，老年代占2，年轻代占整个堆的 1/3 -XX:MaxTenuringThreshold 设置垃圾最大年龄 强引用、软引用、弱引用和虚引用分别是什么？在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 强引用 我们平常典型编码Object obj = new Object()中的 obj 就是强引用，通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出 OutOfMemoryError 运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应强引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 软引用 软引用通过SoftReference类实现， 软引用的生命周期比强引用短一些。 只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即 JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null，否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 代码验证，我设置 JVM 参数为 -Xms10m -Xmx10m -XX:+PrintGCDetails public class SoftReferenceDemo { public static void main(String[] args) { Object obj = new Object(); SoftReference&lt;Object&gt; softReference = new SoftReference&lt;&gt;(obj); obj = null; try { // 分配 20 M byte[] bytes = new byte[20 * 1024 * 1024]; } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(&quot;软引用：&quot; + softReference.get()); } }} 发现当内存不够的时候就会被回收。 [GC (Allocation Failure) [PSYoungGen: 1234K-&gt;448K(2560K)] 1234K-&gt;456K(9728K), 0.0016748 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 448K-&gt;384K(2560K)] 456K-&gt;392K(9728K), 0.0018398 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 384K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;358K(7168K)] 392K-&gt;358K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0057246 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 358K-&gt;358K(9728K), 0.0006038 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;340K(7168K)] 358K-&gt;340K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0115080 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 软引用：nullException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.cuzz.jvm.SoftReferenceDemo.main(SoftReferenceDemo.java:21)Heap PSYoungGen total 2560K, used 98K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 4% used [0x00000000ffd00000,0x00000000ffd18978,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 340K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 4% used [0x00000000ff600000,0x00000000ff6552f8,0x00000000ffd00000) Metaspace used 3067K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K 弱引用 弱引用通过 WeakReference 类实现， 弱引用的生命周期比软引用短。 在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。 代码验证 public class WeakReferenceDemo { public static void main(String[] args) { Object obj = new Object(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj); System.out.println(obj); System.out.println(weakReference.get()); obj = null; System.gc(); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); }} 输出 java.lang.Object@1540e19djava.lang.Object@1540e19dGC之后....nullnull 引用队列 public class ReferenceQueueDemo { public static void main(String[] args) throws InterruptedException { Object obj = new Object(); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj, referenceQueue); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); obj = null; System.gc(); Thread.sleep(500); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); }} 会把该对象的包装类即weakReference放入到ReferenceQueue里面，我们可以从queue中获取到相应的对象信息，同时进行额外的处理。比如反向操作，数据清理等。 java.lang.Object@1540e19djava.lang.Object@1540e19djava.lang.ref.WeakReference@677327b6GC之后....nullnulljava.lang.ref.WeakReference@677327b6 虚引用 虚引用也叫幻象引用，通过PhantomReference类来实现，无法通过虚引用访问对象的任何属性或函数。 幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 请谈谈你对 OOM 的认识？ java.lang.StackOverflowError 在一个函数中调用自己就会产生这个错误 java.lang.OutOfMemoryError : Java heap space new 一个很大对象 java.lang.OutOfMemoryError : GC overhead limit exceeded 执行垃圾收集的时间比例太大， 有效的运算量太小，默认情况下,，如果GC花费的时间超过 **98%**， 并且GC回收的内存少于 **2%**， JVM就会抛出这个错误。 java.lang.OutOfMemoryError : Direct buffer memory配置参数：-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m public class DirectBufferDemo { public static void main(String[] args) { System.out.println(&quot;maxDirectMemory : &quot; + sun.misc.VM.maxDirectMemory() / (1024 * 1024) + &quot;MB&quot;); ByteBuffer byteBuffer = ByteBuffer.allocateDirect(6 * 1024 * 1024); }} 输出 maxDirectMemory : 5MB[GC (System.gc()) [PSYoungGen: 1315K-&gt;464K(2560K)] 1315K-&gt;472K(9728K), 0.0008907 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 464K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;359K(7168K)] 472K-&gt;359K(9728K), [Metaspace: 3037K-&gt;3037K(1056768K)], 0.0060466 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:694) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.cuzz.jvm.DirectBufferDemo.main(DirectBufferDemo.java:17)Heap PSYoungGen total 2560K, used 56K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0e170,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 359K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 5% used [0x00000000ff600000,0x00000000ff659e28,0x00000000ffd00000) Metaspace used 3068K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K java.lang.OutOfMemoryError : unable to create new native thread 创建线程数太多了 java.lang.OutOfMemoryError : Metaspace Java 8 之后的版本使用元空间（Metaspace）代替了永久代，元空间是方法区在 HotSpot 中的实现，它与持久代最大的区别是：元空间并不在虚拟机中的内存中而是使用本地内存。 元空间存放的信息： 虚拟机加载的类信息 常量池 静态变量 即时编译后的代码 具体的实现可以看看这个帖子：几种手动OOM的方式 GC 垃圾回收算法和垃圾收集器的关系？谈谈你的理解？ 四种 GC 垃圾回收算法 引用计数 复制回收 标记清除 标记整理 GC 算法是内存回收的方法论，垃圾收集其就是算法的落实的实现。 目前为止还没有完美的收集器的出现，更加没有万能的收集器，只是针对具体应用最适合的收集器，进行分代收集。 串行垃圾回收器（Serial） 它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，所以不适合服务环境。 并行垃圾回收器（Parallel） 多个垃圾收集线程并行工作，此时用户线程是暂停的，用于科学计算、大数据处理等弱交互场景。 并发垃圾回收器（CMS） 用户线程和垃圾收集线程同时执行（不一定是并行，可能是交替执行），不需要停顿用户线程，互联网公司多用它，适用对相应时间有要求的场景。 G1 垃圾回收器 G1 垃圾回收器将堆内存分割成不同的区域然后并发的对其进行垃圾回收。 怎么查看服务器默认垃圾收集器是哪个？生产是如何配置垃圾收集器？谈谈你对垃圾收集器的理解？ 怎么查看服务器默认垃圾收集器是哪个？ Java -XX:+PrintCommandLineFlags Java 的 GC 回收的类型主要有： UseSerialGC，UseParallelGC，UseConcMarkSweepGC，UseParNewGC，UseParallelOldGC，UseG1GC Java 8 以后基本不使用 Serial Old 垃圾收集器 参数说明 DefNew : Default New Generation Tenured : Old ParNew : Parallel New Generation PSYoungGen : Parallel Scavenge ParOldGen : Parallel Old Generation Server/Client 模式分别是什么意思 最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。 当虚拟机运行在-client模式的时候，使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级，代号为C2的编译器，C2比C1编译器编译的相对彻底，服务起来之后,性能更高。 所以通常用于做服务器的时候我们用服务端模式，如果你的电脑只是运行一下java程序，就客户端模式就可以了。当然这些都是我们做程序优化程序才需要这些东西的，普通人并不关注这些专业的东西了。其实服务器模式即使编译更彻底，然后垃圾回收优化更好，这当然吃的内存要多点相对于客户端模式。 新生代 串行 GC (Serial/ Serital Copying) 并行 GC (ParNew) 并行回收 GC (Parallel/ Parallel Scanvenge) 老年代 串行 GC (Serial Old/ Serial MSC) 并行 GC (Parallel Old/ Parallel MSC) 并发标记清除 GC (CMS) 是一种以获取最短回收停顿时间为目标的收集器，适合应用在互联网站或者 B/S 系统的服务器上，这个类应用尤其重视服务器的响应速度，希望系统停顿时间最短。 CMS 非常适合堆内存大、CPU 核数多的服务器端应用，也是 G1 出现之前大型应用首选收集器。 并发停顿比较少，并发指的是与用户线程一起执行。 过程 初始标记（initail mark）：只是标记一下 GC Roots 能直接关联的对象，速度很快，需要暂停所有的工作线程 并发标记（concurrent mark 和用户线程一起）：进行 GC Roots 的跟踪过程，和用户线程一起工作，不需要暂停工作线程。 重新标记（remark）：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 并发清除（concurrent sweep 和用户线程一起）：清除 GC 不可达对象，和用户线程一起工作，不需要暂停工作线程，基于标记结果，直接清除。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程和用户线程可以一起并发工作，所以总体来看 CMS 收集器的内存回收和用户线程是一起并发地执行。 优缺点 优点：并发收集停顿低 缺点：并发执行对 CPU 资源压力大，采用的标记清除算法会导致大量碎片 由于并发进行， CMS 在收集与应用线程会同时增加对堆内存的占用，也就是说，CMS 必须要在老年代堆用尽之前完成垃圾回收，否者 CMS 回收失败，将触发担保机制，串行老年代收集器将会以 STW 的方式进行一次 GC，从而造成较大的停顿时间。 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐渐耗尽，最后将不得不通过担保机制对堆内存进行压缩。CMS 也提供了参数 -XX:CMSFullGCsBeForeCompaction (默认0，即每次都进行内存整理) 来指定多少次 CMS 收集之后，进行一次压 垃圾收集器配置代码总结，配置新生代收集器，老年代收集器会自动配置上。 如何选择垃圾收集器 单 CPU 或者小内存，单机程序：-XX:UseSerialGC 多 CPU 需要最大吞吐量，如后台计算型应用：-XX:UseParallelGC 或者 -XX:UseParallelOldGC 多 CPU 追求低停顿时间，需要快速响应，如互联网应用：-XX:+UseConcMarkSweepGC G1 垃圾收集器你了解吗？以前收集器的特点 年轻代和老年代是各自独立且连续的内存块 年轻代收集器使用 eden + S0 + S1 进行复制算法 老年代收集必须扫描整个老年代区域 都是以尽可能的少而快速地执行 GC 为设计原则 G1 是什么 G1 是一种面向服务端的垃圾收集器，应用在多核处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集器的暂停时间要求。 像 CMS 收集器一样，能与应用程序线程并发执行，整理空闲空间更快，需要更多的时间来预测 GC 停顿时间，不希望牺牲大量的吞吐性能，不需要更大的 JAVA Heap。 G1 收集器的设计目的是取代 CMS 收集器，同时与 CMS 相比，G1 垃圾收集器是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。G1 的 Stop The World 更可控，G1 在停顿上添加了预测机制，用户可以指定期望的停顿时间。 G1 是在 2012 年才在 jdk.1.7u4 中可以呀用，在 jdk9 中将 G1 变成默认垃圾收集器来代替 CMS。它是以款面向服务应用的收集器。 主要改变是 Eden、Survivor 和 Tenured 等内存区域不再是连续的，而是变成了一个个大小一样的 region，每个 region 从 1M 到 32M 不等，一个 region 有可能属于 Eden、Survivor 或者 Tenured 内存区域。 G1的特点 G1 能充分利用多 CPU、多核环境硬件优势，尽量缩短 STW。 G1 整体采用标记-整理算法，局部是通过是通过复制算法，不会产生内存碎片。 宏观上看 G1 之中不在区分年轻代和老年代，被内存划分为多个独立的子区域。 G1 收集器里面讲整个的内存区域混合在一起，但其本身依然在小范围内要进行年轻代和老年代的区分。保留了新生代和老年代，但她们不在是物理隔离，而是一部分 Region 的集合且不需要 Region 是连续的，也就是说依然会采用不同的 GC 方式来处理不同的区域。 G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 Survivor to space 堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换。 底层原理 Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。 G1的内存结构和传统的内存空间划分有比较的不同。G1将内存划分成了多个大小相等的Region（默认是512K），Region逻辑上连续，物理内存地址不连续。同时每个Region被标记成E、S、O、H，分别表示Eden、Survivor、Old、Humongous。其中E、S属于年轻代，O与H属于老年代。 H表示Humongous。从字面上就可以理解表示大的对象（下面简称H对象）。当分配的对象大于等于Region大小的一半的时候就会被认为是巨型对象。H对象默认分配在老年代，可以防止GC的时候大对象的内存拷贝。通过如果发现堆内存容不下H对象的时候，会触发一次GC操作。 ** 参看：G1从入门到放弃 生产环境服务器变慢，诊断思路和性能评估谈谈？ 整机：top CPU：vmstat 内存：free 硬盘：df 磁盘IO：iostat 网络IO：ifstat 假如生产环境出现 CPU 过高，请谈谈你的分析思路和定位？ 先用 top 命令找出 CPU 占比最高的 ps -ef 或者 jps 进一步定位，得知是一个怎么样的一个后台程序 定位到具体的线程或代码 ps -mp 11111 -o THREAD,tid,time -m 显示所有的线程 -p 进程使用cpu的时间 -o 该参数后是用户自定义格式 将需要的线程 ID 转化为 16 进制格式 jstat &lt;进程ID&gt; | grep &lt;线程ID(16进制)&gt; -A60 对于 JDK 自带的 JVM 监控和性能分析工具用过哪些？一般机是怎么用到的？下一篇重点介绍。 参考链接 强引用、软引用、弱引用、幻象引用有什么区别？(评论) G1从入门到放弃","link":"/2019/05/10/JVM%E9%9D%A2%E8%AF%95/"},{"title":"Java8的深入与实战","text":"Lambda 表达式和函数式接口Lambda 表达式定义： Lambda: In programming languages such as Lisp, Python and Ruby lambda is an operator used to denote anonymous functions or closures, following the usage of lambda calculus. 为何需要使用 Lambda 表达式： 在 Java 中，我们无法将函数作为一个参数传递给一个方法，也无法声明一个返回一个函数的方法。 在 JavaScript 中，函数的参数是一个函数，返回值是另一个函数的情况是非常常见的，JavaScript 是一门典型的函数式语言。 我们通过一个例子来引入： /** * @Author: cuzz * @Date: 2019/8/11 14:55 * @Description: */public class Test1 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6); for (int i = 0; i &lt; list.size(); i++) { System.out.println(list.get(i)); } System.out.println(&quot;-----------------&quot;); for (int val : list) { System.out.println(val); } System.out.println(&quot;-----------------&quot;); list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 这是 3 种遍历集合的方式，第一就是简单的遍历，第二种是我们是常说的增强 for 循环遍历。第三种就是 Java 8 新增的方法，先看看 Consumer 这个接口。 package java.util.function;import java.util.Objects;@FunctionalInterfacepublic interface Consumer&lt;T&gt; { void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} 注解上是一个函数式接口，我们看看这个接口的作用。 package java.lang;import java.lang.annotation.*;/** * An informative annotation type used to indicate that an interface * type declaration is intended to be a &lt;i&gt;functional interface&lt;/i&gt; as * defined by the Java Language Specification. * * Conceptually, a functional interface has exactly one abstract * method. Since {@linkplain java.lang.reflect.Method#isDefault() * default methods} have an implementation, they are not abstract. If * an interface declares an abstract method overriding one of the * public methods of {@code java.lang.Object}, that also does * &lt;em&gt;not&lt;/em&gt; count toward the interface's abstract method count * since any implementation of the interface will have an * implementation from {@code java.lang.Object} or elsewhere. * * 有且只有一个抽象方法的接口，如果有重写 Object 中的方法，那也是可以的。 * * &lt;p&gt;Note that instances of functional interfaces can be created with * lambda expressions, method references, or constructor references. * * 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 * * &lt;p&gt;If a type is annotated with this annotation type, compilers are * required to generate an error message unless: * * &lt;ul&gt; * &lt;li&gt; The type is an interface type and not an annotation type, enum, or class. * &lt;li&gt; The annotated type satisfies the requirements of a functional interface. * &lt;/ul&gt; * * &lt;p&gt;However, the compiler will treat any interface meeting the * definition of a functional interface as a functional interface * regardless of whether or not a {@code FunctionalInterface} * annotation is present on the interface declaration. * * 编译器会对满足定义函数式接口的接口当做函数式接口，不管它有没有 @FunctionalInterface 注解声明。 * * @jls 4.3.2. The Class Object * @jls 9.8 Functional Interfaces * @jls 9.4.3 Interface Method Body * @since 1.8 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface {} 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 lambda 表达式：() -&gt; System.out.println(i) 方法引用：System.out::print 构造方法引用：new::ArrayList 用一个例子来说明什么是函数式接口。 @FunctionalInterfaceinterface Cons { void print(); String toString();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public void test(Cons func) { func.print(); } public static void main(String[] args) { Test2 test2 = new Test2(); test2.test(() -&gt; System.out.println(&quot;xxx&quot;)); Cons func = () -&gt; System.out.println(&quot;yyy&quot;); test2.test(func); System.out.println(func.getClass()); // 输出 class com.cuzz.Test2$$Lambda$2/2074407503 System.out.println(func.getClass().getSuperclass()); // 输出 class java.lang.Object }} 可以说明3点： 函数式接口只有一个非重写 Object 的抽象方法 lambda 表达式就是一个匿名类 对于一个函数式接口，我们并不关心这个抽象方法的名称。 从Consumer深入理解函数式接口和方法引用我们回到这个例子当中 public class Test1 { public static void main(String[] args) { list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 先看看 Iterable#forEach 这个方法，是 Iterable 这个接口这的默认方法，在 Java 8 中接口中是允许默认方法。对于 Iterable#forEach 是对每个元素执行给定的动作。 public interface Iterable&lt;T&gt; { /** * Returns an iterator over elements of type {@code T}. * * @return an Iterator. */ Iterator&lt;T&gt; iterator(); /** * Performs the given action for each element of the {@code Iterable} * until all elements have been processed or the action throws an * exception. Unless otherwise specified by the implementing class, * actions are performed in the order of iteration (if an iteration order * is specified). Exceptions thrown by the action are relayed to the * caller. * * 对每个元素执行给定的动作。 * * @implSpec * &lt;p&gt;The default implementation behaves as if: * &lt;pre&gt;{@code * for (T t : this) * action.accept(t); * }&lt;/pre&gt; * * @param action The action to be performed for each element * @throws NullPointerException if the specified action is null * @since 1.8 */ default void forEach(Consumer&lt;? super T&gt; action) { Objects.requireNonNull(action); for (T t : this) { action.accept(t); } } default Spliterator&lt;T&gt; spliterator() { return Spliterators.spliteratorUnknownSize(iterator(), 0); }} 看看 Consumer 是什么 package java.util.function;import java.util.Objects;/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, {@code Consumer} is expected * to operate via side-effects. * * 表示一个操作接受单一输入参数，无返回结果。 * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #accept(Object)}. * * @param &lt;T&gt; the type of the input to the operation * * @since 1.8 */@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); /** * Returns a composed {@code Consumer} that performs, in sequence, this * operation followed by the {@code after} operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the {@code after} operation will not be performed. * * @param after the operation to perform after this operation * @return a composed {@code Consumer} that performs in sequence this * operation followed by the {@code after} operation * @throws NullPointerException if {@code after} is null */ default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} lambda 表达式的作用： lambda 表达式为 Java 添加了缺失的函数式编程特性，使我们能将函数当做一等公民看待。 在将函数作为一等公民的语言中，lambda 表达式的类型是函数。但在 Java 中，lambda 表达式是对象，它们必须依附于一类特别的对象（函数式接口）； Lambda 表达式的深入对于 lambda 表达式需要根据上下文来推断，我们并不知道 () -&gt; {} 是什么，不知道对应的参数，方法是什么，只用通过前面的 Cons 定义才知道。 @FunctionalInterfaceinterface Cons1 { void print1();}@FunctionalInterfaceinterface Cons2 { void print2();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public static void main(String[] args) { Cons1 cons1 = () -&gt; {}; Cons2 cons2 = () -&gt; {}; System.out.println(cons1.getClass().getInterfaces()[0]); // interface com.cuzz.Cons1 System.out.println(cons2.getClass().getInterfaces()[0]); // interface com.cuzz.Cons2 }} 我们先看一个排序的例子： /** * @Author: cuzz * @Date: 2019/8/12 23:09 * @Description: 排序 */public class Test4 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); Collections.sort(list, (String s1, String s2) -&gt; { return s2.compareTo(s1); }); // 1 Collections.sort(list, (s1, s2) -&gt; s2.compareTo(s1)); // 2 }} 从 1 到 2 简化了很多，修饰符 String 和 return 都可以省略。Java Lambda 表达式是一种匿名函数，它没有声明方法，也没有访问修饰符、返回值和名字。 Lambda 表达式作用： 传递行为，而不仅仅是值 提升抽象层次 API 重用性好 更加灵活 Lambda 基本语法： Java 中的 Lambda 表达式基本语法 如：(argument) -&gt; {body} 省略类型：(arg1, arg2, ...) -&gt; {body} 有类型：(type1 arg1, type2 arg2, ...) -&gt; {body} Lambda 示例说明 (int a, int b) -&gt; {return a + b;} () -&gt; System.out.println(&quot;hello world&quot;) (String s) -&gt; {System.out.println(s);} () -&gt; 42 () -&gt; {return &quot;cuzz&quot;}; Lambda结构 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断，如：(int a) 与 (a) 效果相同 所有的参数需包含在圆括号内，参数之间用逗号相隔。如：(a, b) 或 (String a, int b float c) 空圆括号表示参数集为空，如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号可以省略，如：a -&gt; return a * a Lambda 表达式的主题可以包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号可以省略，匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，表达式必须使用花括号 Function直接先看源码 /** * Represents a function that accepts one argument and produces a result. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object)}. * * @param &lt;T&gt; the type of the input to the function * @param &lt;R&gt; the type of the result of the function * * @since 1.8 */@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); } default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); } /** * Returns a function that always returns its input argument. * * @param &lt;T&gt; the type of the input and output objects to the function * @return a function that always returns its input argument */ static &lt;T&gt; Function&lt;T, T&gt; identity() { return t -&gt; t; }} 可以看出 Function 有一个抽象方法和两个默认方法以及一个静态方法。 （1） Function#apply Stream#map 里就是接受一个 Function，对于 Function 意思就是从一个映射到另一个。下面例子就是把字符串映射到大写。对于 String::toUpperCase 使用的是方法引用。 /** * @Author: cuzz * @Date: 2019/8/11 23:13 * @Description: */public class Test3 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); list.stream().map(item -&gt; item.toUpperCase()).forEach(item -&gt; System.out.println(item)); list.stream().map(String::toUpperCase).forEach(System.out::println); Function&lt;String, String&gt; function = String::toUpperCase; System.out.println(function.getClass()); }} 我们看一个例子： /** * @Author: cuzz * @Date: 2019/8/13 0:08 * @Description: */public class FunctionTest { public static void main(String[] args) { FunctionTest function= new FunctionTest(); int res1 = function.compute(100, target -&gt; target * target); int res2 = function.compute(100, target -&gt; target + 1); System.out.println(res1); // 10000 System.out.println(res2); // 101 int res3 = function.pow(100); int res4 = function.addOne(100); System.out.println(res3); // 10000 System.out.println(res4); // 101 } public int compute(int a, Function&lt;Integer, Integer&gt; function) { return function.apply(a); } public int pow(int a) { return a * a; } public int addOne(int a) { return a + 1; }} 看看 #compute 这个方法，第二个参数传递的是行为，而不是具体的值。 我们本来要定义两个方法，pow 和 addOne 现在把这种行为传递进来。 （2）Function#compose 和 Function#andThen /** * Returns a composed function that first applies the {@code before} * function to its input, and then applies this function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of input to the {@code before} function, and to the * composed function * @param before the function to apply before this function is applied * @return a composed function that first applies the {@code before} * function and then applies this function * @throws NullPointerException if before is null * * @see #andThen(Function) */default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));}/** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null * * @see #compose(Function) */default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));} compose方法是一个默认方法，这个方法接收一个 function 作为参数，将参数 function 执行的结果作为参数给调用的 function，以此来实现两个function组合的功能。 andThen 方法也是接收一个 function 作为参数，与 compse 不同的是，先执行本身的 apply 方法，将执行的结果作为参数给参数中的 function。 /** * @Author: cuzz * @Date: 2019/8/20 23:59 * @Description: #compose and #andThen test */public class FunctionTest2 { public static void main(String[] args) { FunctionTest2 test = new FunctionTest2(); System.out.println(test.compute1(2, value -&gt; value * 2, value -&gt; value * value)); // 8 System.out.println(test.compute2(2, value -&gt; value * 2, value -&gt; value * value)); // 16 } public int compute1(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.compose(function2).apply(a); } public int compute2(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.andThen(function2).apply(a); }} 发现 compute1 是先执行第二个 Function 再执行第一，compute2 相反。 BiFunction先看源码 /** * Represents a function that accepts two arguments and produces a result. * This is the two-arity specialization of {@link Function}. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object, Object)}. * * @param &lt;T&gt; the type of the first argument to the function * @param &lt;U&gt; the type of the second argument to the function * @param &lt;R&gt; the type of the result of the function * * @see Function * @since 1.8 */@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u); /** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null */ default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t, U u) -&gt; after.apply(apply(t, u)); }} 我看一个例子 /** * @Author: cuzz * @Date: 2019/8/21 7:36 * @Description: */public class BiFunctionTest { public static void main(String[] args) { BiFunctionTest test = new BiFunctionTest(); // 加法 System.out.println(test.add(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a + b)); // 减法 System.out.println(test.subtract(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a - b)); } public int compute(int a, int b, BiFunction&lt;Integer, Integer, Integer&gt; biFunction) { return biFunction.apply(a, b); } public int add(int a, int b) { return a + b; } public int subtract(int a, int b) { return a - b; }} 以前我们定义一个四则运算需要需要先定义方法，现在通过 BiFunction 可以把这种行为传递进来。 Predicate（1）源码 /** * Represents a predicate (boolean-valued function) of one argument. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #test(Object)}. * * @param &lt;T&gt; the type of the input to the predicate * * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); /** * Returns a composed predicate that represents a short-circuiting logical * AND of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code false}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ANDed with this * predicate * @return a composed predicate that represents the short-circuiting logical * AND of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } /** * Returns a predicate that represents the logical negation of this * predicate. * * @return a predicate that represents the logical negation of this * predicate */ default Predicate&lt;T&gt; negate() { return (t) -&gt; !test(t); } /** * Returns a composed predicate that represents a short-circuiting logical * OR of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code true}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ORed with this * predicate * @return a composed predicate that represents the short-circuiting logical * OR of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); } /** * Returns a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)}. * * @param &lt;T&gt; the type of arguments to the predicate * @param targetRef the object reference with which to compare for equality, * which may be {@code null} * @return a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)} */ static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) { return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); }} （2）例子 以前我们根据不同的条件筛选数据需要些多个方法，现在只要先定义一个这种接受行为的方法。 /** * @Author: cuzz * @Date: 2019/8/21 23:35 * @Description: Predicate test */public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找奇数 test.findOdd(list); test.conditionFilter(list, i -&gt; i % 2 != 0); // 查找偶数 test.findEven(list); test.conditionFilter(list, i -&gt; i % 2 == 0); } public void conditionFilter(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) { for (int i : list) { if (predicate.test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findOdd(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 != 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findEven(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 == 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} （3）Predicate#and 和 Predicate#or public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找 大于 3 的奇数 test.conditionFilter2(list, i -&gt; i &gt; 3, i -&gt; i % 2 != 0); } public void conditionFilter2(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate1, Predicate&lt;Integer&gt; predicate2) { for (int i : list) { if (predicate1.and(predicate2).test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} Supplier（1）不接受参数，返回一个值。 /** * Represents a supplier of results. * * &lt;p&gt;There is no requirement that a new or distinct result be returned each * time the supplier is invoked. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #get()}. * * @param &lt;T&gt; the type of results supplied by this supplier * * @since 1.8 */@FunctionalInterfacepublic interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get();} （2）例子 /** * @Author: cuzz * @Date: 2019/8/22 23:32 * @Description: */public class SupplierTest { public static void main(String[] args) { Supplier&lt;Student&gt; supplier1 = () -&gt; new Student(); Supplier&lt;Student&gt; supplier2 = Student::new; }}@Dataclass Student { private String name = &quot;cuzz&quot;; private int age = 20;} Optional参考： 使用 Java 8 Optional 的正确姿势","link":"/2019/08/11/Java8%E7%9A%84%E6%B7%B1%E5%85%A5%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"title":"Go语言入门笔记","text":"Go语言是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言，它用批判吸收的眼光，融合C语言、Java等众家之长，将简洁、高效演绎得淋漓尽致。 Go语言起源于2007年，当时Google的技术大神们备受C++越来越臃肿的困扰，决心开发一种新的语言来取代C++。他们认为：与其在臃肿的语言上不断增加新的特性，不如简化编程语言。于是，Golang这门新语言应运而生。 在十年多的时间里，Go语言发展势头强劲，凭借其简洁、高效的特性，在竞争激烈的编程语言市场中占据了一席之地。Google、腾讯、阿里等大公司纷纷选择使用Go语言来开发服务应用项目。当然，和其他的编程语言一样，Go语言也有其自身的缺陷。 课程导论 特点 没有“对象”，没有继承，没有泛型，没有 try/catch 有接口，函数式编程，CSP 并发模型（goroutine + channel） 语法简单 基本语法 变量 选择，循环 指针，数组，容器 面向接口 结构体 duck typing 的概念 组合的思想 函数式编程 闭包的概念 工程化 资源管理，错误处理 测试和文档 性能调优 并发编程 goroutine 和 channel 理解调度器 基本语法HelloWorldpackage mainimport &quot;fmt&quot;func main() { fmt.Println(&quot;Hello World!&quot;)} 变量定义package mainimport &quot;fmt&quot;// 默认变量值func variableZeroValue() { var a int var s string fmt.Println(a, s)}// 定义变量值func variableInitialValue() { var a, b int = 3, 4 var s string = &quot;abc&quot; fmt.Println(a, b, s)}// 变量推断func variableTypeDeduction() { var a, b, c = 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 变量推断简写func variableShorter() { a, b, c := 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 全局变量var a = 1// 全局变量定义不能使用 :=// b := 2// 方便定义多个var ( b = &quot;abc&quot; c = 1 d = true)func main() { variableZeroValue() variableInitialValue() variableTypeDeduction() variableShorter()} 内建变量类型 bool, stiring (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr byte, rune float32, float64, complex64, complex128 常量与枚举package mainimport ( &quot;fmt&quot; &quot;math&quot;)func tri() { a, b := 3, 4 var c int // 先把 int 转 float64 再转回 int c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c)}// 定义常量func consts() { var c int // 指定类型, 下面需要强转为 float64 // const a, b int = 3, 4 // c = int(math.Sqrt(float64(a*a + b*b))) // 不指定类型, 不需要强转为 float64 const a, b = 3, 4 c = int(math.Sqrt(a*a + b*b)) fmt.Println(c)}// 定义枚举func enums() { //const ( // cpp = 0 // java = 1 // python = 2 // golang = 3 //) // 使用 iota 自增加，与上面一样 const ( cpp = iota java python golang _ // 跳开 4 javascript ) fmt.Println(cpp, java, python, golang, javascript) // 0 1 2 3 5 // b, kb, mb, gb, tb, pb const ( b = 1 &lt;&lt; (10 * iota) kb mb gb tb pb ) fmt.Println(b, kb, mb, gb, tb, pb) // 1 1024 1048576 1073741824 1099511627776 1125899906842624}func main() { tri() consts() enums()} 条件语句package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot;)// iffunc read() { const filename = &quot;abc.txt&quot; // 读取文件 contents, err := ioutil.ReadFile(filename) if err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) } // 也可以这样写 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) }}// switchfunc eval(a, b int, op string) int { var result int // switch 会自动 break, 除非使用 fallthrough switch op { case &quot;+&quot;: result = a + b case &quot;-&quot;: result = a - b case &quot;*&quot;: result = a * b case &quot;/&quot;: result = a / b default: panic(&quot;unsupported operator: &quot; + op) } return result}// switchfunc grade(score int) string { // switch 后面没有表达式 switch { case score &lt; 0 || score &gt; 100: panic(&quot;wrong score&quot;) case score &lt; 60: return &quot;E&quot; case score &lt; 70: return &quot;D&quot; case score &lt; 80: return &quot;C&quot; case score &lt; 90: return &quot;B&quot; case score &lt;= 100: return &quot;A&quot; } return &quot;&quot;}func main() { read() fmt.Println(eval(1, 2, &quot;+&quot;)) // 3 grade(100)} 循环package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot;)// 转为二进制func convertToBin(n int) string { res := &quot;&quot; for ; n &gt; 0; n /= 2 { lsb := n % 2 res = strconv.Itoa(lsb) + res } return res}// 打印文件func printFile(fileName string) { file, err := os.Open(fileName) if err != nil { panic(err) } scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) }}// 死循环func forever() { for { fmt.Println(&quot;forever&quot;) }}func main() { fmt.Println( convertToBin(5), convertToBin(13), ) printFile(&quot;abc.txt&quot;); forever()} 函数package mainimport ( &quot;fmt&quot; &quot;math&quot;)// 返回多个值func div(a, b int) (int, int) { return a / b, a % b}// 可以对返回值命名func div2(a, b int) (q, r int) { return a / b, a % b}// 返回 errorfunc eval(a, b int, op string) (int, error) { switch op { case &quot;+&quot;: return a + b, nil case &quot;-&quot;: return a - b, nil case &quot;*&quot;: return a * b, nil case &quot;/&quot;: return a / b, nil default: return 0, fmt.Errorf(&quot;unsupported opration: %s&quot;, op) }}// 使用函数式编程func apply(op func(int, int) int, a, b int) int { return op(a, b)}// 可变参数func sum(numbers ...int) int { sum := 0 for i := range numbers { sum += numbers[i] } return sum}func pow(a, b int) int { return int(math.Pow(float64(a), float64(b)))}func main() { i, i2 := div(5, 3) fmt.Println(i, i2) q, r := div2(5, 3) fmt.Println(q, r) res, err := eval(1, 2, &quot;&amp;&quot;) // unsupported opration: &amp; if err != nil { fmt.Println(err) } else { fmt.Println(res) } fmt.Println(apply(pow, 2, 2)) // 4 fmt.Println(sum(1, 2, 3, 4)) // 10} 指针package mainimport &quot;fmt&quot;// 使用指针func swap(a *int, b *int) { *b, *a = *a, *b}func swap2(a, b int) (int, int) { return b, a}func main() { a, b := 3, 4 swap(&amp;a, &amp;b) fmt.Println(a, b) // 4 3 a, b = 3, 4 a, b = swap2(a, b) fmt.Println(a, b) // 4 3} 数组、切片和容器数组package mainimport &quot;fmt&quot;// 数组定义func defineArray() { // 定义数组的方法 var arr1 [5]int arr2 := [3]int{1, 3, 5} arr3 := [...]int{2, 4, 6, 8} fmt.Println(arr1, arr2, arr3) // [0 0 0 0 0] [1 3 5] [2 4 6 8] // 定义二维数组 var grid [2][3]int fmt.Println(grid) // [[0 0 0] [0 0 0]]}// 遍历数组func printArray() { arr := [...]int{2, 4, 6, 8} for i := 0; i &lt; len(arr); i++ { fmt.Println(arr[i]) } // 通过 range 可以获取下标 for i := range arr { fmt.Println(arr[i]) } // 获取下标和值 for i, v := range arr { fmt.Println(i, v) } // 只获取值, 可以使用 _ 来省略变量 for _, v := range arr { fmt.Println(v) }}// [3]int 和 [5]int 是不同的类型func printArray2(arr [5]int) { fmt.Println(arr)}// 数组是值类型func printArray3(arr [5]int) { arr[0] = 100 fmt.Println(arr) // [100, 0, 0, 0, 0]}// 传递指针func printArray4(arr *[5]int) { arr[0] = 100 fmt.Println(*arr) // [100, 0, 0, 0, 0]}func main() { defineArray() printArray() var arr1 [5]int // arr2 := [3]int{1, 3, 5} // arr3 := [...]int{2, 4, 6, 8, 10} // [3]int 和 [5]int 是不同的类型 printArray2(arr1) // 在函数里面改变数组的值 // printArray2(arr2) // cannot use arr2 (type [3]int) as type [5]int in argument to printArray2 // 在函数里改变了数组第一个值, 后面打印还是不变，每次传递数组都是一个副本 printArray3(arr1) fmt.Println(arr1) // [0, 0, 0, 0, 0] // 传递地址过去就会改变 printArray4(&amp;arr1) fmt.Println(arr1) // [100, 0, 0, 0, 0]} 切片package mainimport &quot;fmt&quot;// 切片func mySlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(&quot;arr[2:6] = &quot;, arr[2:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[:6] = &quot;, arr[:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[2:] = &quot;, arr[2:]) // arr[2:] = [2 3 4 5 6 7] fmt.Println(&quot;arr[:] = &quot;, arr[:]) // arr[:] = [0 1 2 3 4 5 6 7]}// 更新func updateSlice(slice []int) { slice[0] = 2019}// 扩展func extendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 我们知道 s1 只有 4 个元素, 但是 s2 还是能 s1 := arr[2:6] s2 := s1[3:5] fmt.Println(s1) // [2 3 4 5] fmt.Println(s2) // [5 6] fmt.Printf(&quot;len=%d, cap=%d&quot;, len(s1), cap(s1)) // len=4, cap=6}// 添加func appendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 添加元素如果超过了 cap, 系统会重新分配更大的底层数组 // 由于值的传递关系, 必须接受 append 的返回值 s1 := arr[2:6] s2 := append(s1, 100) s3 := append(s2, 100) s4 := append(s3, 100) s5 := append(s4, 100) fmt.Println(s1, s2, s3, s4, s5) // [2 3 4 5] [2 3 4 5 100] [2 3 4 5 100 100] [2 3 4 5 100 100 100] [2 3 4 5 100 100 100 100]}// 创建 slicefunc createSlice() { // 0. 创建一个空的 slice var s []int // 发现 cap 是从 1 2 4 8 16 32... 扩大 for i := 0; i &lt; 100; i++ { s = append(s, 1+2*i) printSlice(s) } // 1. 创建一个带有值的 slice s1 := []int{1, 2, 3, 4, 5} printSlice(s1) // len=5, cap=5, slice=[1 2 3 4 5] // 2. 创建一个 cap = 16 s2 := make([]int, 16) printSlice(s2) // len=16, cap=16, slice=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] // 3. 创建一个 len = 10, cap = 32 s3 := make([]int, 10, 32) // len=10, cap=32, slice=[0 0 0 0 0 0 0 0 0 0] printSlice(s3)}// 复制func copySlice() { src := []int{1, 2, 3} dst := make([]int, 16) fmt.Println(dst) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] copy(dst, src) fmt.Println(dst) // [1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0]}// 删除func deleteSlice() { // 删除下标为3的元素 s := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s = append(s[:3], s[4:]...) // s[4:]... 转换为可变参数 fmt.Println(s) // [0 1 2 4 5 6 7 8] // 删除第一个 s1 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s1 = s1[1:] fmt.Println(s1) // [1 2 3 4 5 6 7 8] // 删除最后一个 s2 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s2 = s2[:len(s2) - 1] fmt.Println(s2) // [0 1 2 3 4 5 6 7]}func printSlice(s []int) { fmt.Printf(&quot;len=%d, cap=%d, slice=%v \\n&quot;, len(s), cap(s), s)}func main() { mySlice() arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} slice1 := arr[:] fmt.Println(&quot;Before update: &quot;, slice1) // Before update: [0 1 2 3 4 5 6 7] updateSlice(slice1) fmt.Println(&quot;After update: &quot;, slice1) // After update: [2019 1 2 3 4 5 6 7] extendSlice() appendSlice() createSlice() copySlice() deleteSlice()} Mappackage mainimport &quot;fmt&quot;// 定义 mapfunc defineMap() { // 定义一个带默认值的 map m1 := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 定义一个 empty map m2 := make(map[string]string) // 定义一个 nil map var m3 map[string]string fmt.Println(m1, m2, m3) // map[a:A b:B] map[] map[]}// 遍历 mapfunc traversingMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 打印 key value for k, v := range m { fmt.Println(k, v) } // 只打印 key for k := range m { fmt.Println(k) } // 只打印 value for _, v := range m { fmt.Println(v) }}// 判断是否存在func containMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } value, ok := m[&quot;c&quot;] if ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) } if value, ok := m[&quot;b&quot;]; ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) }}// 删除元素func deleteMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } fmt.Println(m) // map[a:A b:B] delete(m, &quot;a&quot;) fmt.Println(m) // map[b:B]}func main() { defineMap() traversingMap() containMap() deleteMap()} 例题：查找最长不重复子串 package mainimport &quot;fmt&quot;// 查早最长不重复子串func lengthOfSubString(s string) int { start := 0 maxLength := 0 lastOccuredMap := make(map[rune]int) for i, ru := range []rune(s) { if lastI, ok := lastOccuredMap[ru]; ok &amp;&amp; lastI &gt;= start { start = lastI + 1 } if i-start+1 &gt; maxLength { maxLength = i - start + 1 } lastOccuredMap[ru] = i } return maxLength}func main() { fmt.Println(lengthOfSubString(&quot;aaa&quot;)) fmt.Println(lengthOfSubString(&quot;abab&quot;)) fmt.Println(lengthOfSubString(&quot;abc&quot;)) fmt.Println(lengthOfSubString(&quot;abcabc&quot;))} 字符和字符串处理package mainimport &quot;fmt&quot;func runeTest() { s := &quot;cuzz是我!&quot; for i, b := range []byte(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, b, b) } fmt.Println() for i, u := range s { fmt.Printf(&quot;(%d %X %c) &quot;, i, u, u) } fmt.Println() for i, r := range []rune(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, r, r) } // 输出 // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 E6 æ) (5 98 ) (6 AF ¯) (7 E6 æ) (8 88 ) (9 91 ) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (7 6211 我) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (5 6211 我) (6 21 !) // 说明 range s 使用的 utf-8 遍历, 但是观察下标发现不是连续的 // ascii 转为 utf-8 如:(4 E6) (5 98) (6 AF) -&gt; (4 662F) // 使用 []rune() 转换可以使下标连续输出}func main() { runeTest()} 面向对象 go 语言仅支持封装，不支持继承和多态 go 语言没有 class，只有 struct 结构体和方法package mainimport ( &quot;fmt&quot;)// 定义结构体, 小写对外不可见type treeNode struct { value int left, right *treeNode}// setter, 错误, 由于 go 是传值, 不会改变func (node treeNode) setVal(value int) { node.value = value}func (node *treeNode) setValue(value int) { node.value = value}// 给结构体定义方法 node.print()func (node treeNode) print() { fmt.Println(node.value)}// 普通的方法 print(node)func print(node treeNode) { fmt.Println(node.value)}// 定义一个工厂方法func createNode(value int) *treeNode { return &amp;treeNode{value: value}}// 遍历func (node *treeNode) traverse() { if node == nil { return } node.left.traverse() node.print() node.right.traverse()}func main() { // 定义一个空的结构体 var node treeNode fmt.Println(node) // {0 &lt;nil&gt; &lt;nil&gt;} // 使用构造器定义一个结构体 node2 := treeNode{ value: 1, left: &amp;treeNode{}, // 取地址 right: new(treeNode), // new() 获取的是地址 } fmt.Println(node2) // {1 0xc00000c0c0 0xc00000c0a0} // 使用工厂方法创建 node3 := treeNode{ value: 0, } node3.left = createNode(1) node3.right = createNode(2) fmt.Println(node3) // {0 0xc00008e0a0 0xc00008e0c0} // 区别 node.print() // 0 print(node) // 0 // 不会改变, go 是传值 node.setVal(1) node.print() // 0 // 会改变 node.setValue(1) node.print() // 1 fmt.Println() // 中顺遍历 0 // 1 2 node3.traverse() // 1 0 2} 包和封装 包 每个目录一个包 main 包包含可执行入口 为结构定义的方法必须放在同一包内 可以是不同的文件 封装 一般使用驼峰命名 首字母大写表示 public 首字母小写表示 private Queue.go package queueimport &quot;fmt&quot;type Queue []intfunc (q *Queue) Push(v int) { *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}func (q *Queue) Head() int { return (*q)[0]}func (q *Queue) IsEmpty() bool { return len(*q) == 0}func (q *Queue) Print() { for _, v := range *q { fmt.Print(v, &quot; &quot;) } fmt.Println()} test.go package mainimport ( &quot;awesomeProject/queue&quot; &quot;fmt&quot;)func main() { // 定义一个有默认值的队列 q := queue.Queue{1} q.Push(2) q.Push(3) q.Push(4) q.Print() // 1 2 3 4 fmt.Println(q.Pop()) // 1 q.Print() // 2 3 4 q.Pop() q.Pop() q.Pop() fmt.Println(q.IsEmpty()) // true} 项目结构环境变量： GOROOT：go语言自带的类库 GOPATH：用户源代码目录 src：源文件 pkg：build 的之后的中间文件 bin：可执行文件 接口duck typing “像鸭子走路，像鸭子叫…”，那么就是鸭子 描述事物的外部行为而非内部结构 严格说 go 属于结构化类型系统，类似 duck typing 接口定义和实现定义一个假的发送请求，有一个 Get 方法 package mocktype Retriever struct { Contents string}func (r Retriever) Get(url string) string { return url + &quot;hi, cuzz...&quot;} 定义一个真正发送请求，有一个 Get 方法 package workimport ( &quot;net/http&quot; &quot;net/http/httputil&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) Get(url string) string { resp, err := http.Get(url) if err != nil { panic(err) } result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil { panic(err) } return string(result)} 测试 package mainimport ( &quot;awesomego/retriever/mock&quot; &quot;awesomego/retriever/work&quot; &quot;fmt&quot;)// 定义一个接口type Retriever interface { Get(url string) string}// 传入接口func download(r Retriever) string { return r.Get(&quot;http://blog.cuzz.site&quot;)}func main() { // 接口定义 // var mockRetriever Retriever // mockRetriever = mock.Retriever{} mockRetriever := mock.Retriever{} fmt.Println(download(mockRetriever)) workRetriever := work.Retriever{} fmt.Println(download(workRetriever))} 我们发现在接口是调用放定义的，结构体中的接口也是隐式的，结构体满足接口中的方法，就可以说这个结构体实现了这个接口。 接口的值类型在golang中，接口值是由两部分组成的，一部分是接口的类型，另一部分是该类型对应的值，我们称其为动态类型和动态值。 func main() { mockRetriever := mock.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, mockRetriever, mockRetriever) // mock.Retriever, {} workRetriever := work.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, workRetriever, workRetriever) // work.Retriever, { 0s}} 接口组合package main// 定义一个接口type Retriever interface { Get(url string) string}// 定义另一个接口type Poster interface { Post(url string, params map[string]string)}// 接口组合type RetrieverAndPoster interface { Retriever Poster // 也可以定义其他方法 AnotherMethod()}func main() {} 常用系统接口1、Stringer Stringer接口中的 string 相当与 Java #toString 方法 package workimport ( &quot;fmt&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) String() string { return fmt.Sprintf(&quot;UserAgent: %v, TimeOut: %v&quot;, r.UserAgent, r.TimeOut)} 测试 package mainimport ( &quot;awesomego/retriever/work&quot; &quot;fmt&quot; &quot;time&quot;)func main() { workRetriever := work.Retriever{&quot;Mozilla/5.0&quot;, time.Minute} fmt.Println(workRetriever) // UserAgent: Mozilla/5.0, TimeOut: 1m0s} 2、Reader type Reader interface { Read(p []byte) (n int, err error)} 3、Writer type Writer interface { Write(p []byte) (n int, err error)} 函数式编程 函数是一等公民：参数，变量，返回值都可以是函数 高级函数 闭包 package mainimport &quot;fmt&quot;// 定义一个 adder 函数, 没有参数, 返回值是一个函数func adder() func(int) int { sum := 0 return func(v int) int { sum += v return sum }}// 定义斐波那契数列func fibonacci() func() int{ a, b := 0, 1 return func() int { a, b = b, a + b fmt.Println(a) return a }}func main() { a := adder() for i := 0; i &lt; 10; i++ { fmt.Printf(&quot;0 + 1 + ... + %d = %d\\n&quot;, i, a(i)) } f := fibonacci() f() // 1 f() // 1 f() // 2 f() // 3 f() // 5} 资源管理与出错处理defer 调用你可以在 Go 函数中添加多个defer语句，当函数执行到最后时，这些 defer 语句会按照逆序执行（即最后一个defer语句将最先执行），最后该函数返回。特别是当你在进行一些打开资源的操作时，遇到错误需要提前返回，在返回前你需要关闭相应的资源，不然很容易造成资源泄露等问题。如下代码所示，我们一般写打开一个资源是这样操作的： func CopyFile(dst, src string) (w int64, err error) { srcFile, err := os.Open(src) if err != nil { return } defer srcFile.Close() dstFile, err := os.Create(dst) if err != nil { return } defer dstFile.Close() return io.Copy(dstFile, srcFile)} 错误处理错误处理是任何语言都需要考虑到的问题，而 Go 语言在错误处理上解决得更为完善，优雅的错误处理机制是 Go 语言的一大特点。 1、error Go 语言引入了一个错误处理的标准模式，即error接口，该接口定义如下： type error interface { Error() string} 对于大多数函数，如果要返回错误，可以将error作为多返回值的最后一个： func foo(param int)(ret int, err error) { ... } 调用时的代码： n, err := foo(0)if err != nil { // 错误处理} else { // 使用返回值n} 2、panic 停止当前函数执行 一直向上返回，执行每一层的 defer 如果没有遇见 recover，程序退出 3、recover 仅在 defer 中调用 获取 panic 的值 如果无法处理，可以重新 panic package mainimport ( &quot;fmt&quot;)func tryRecover() { // 匿名函数里 defer func() { r := recover() if err, ok := r.(error); ok { fmt.Println(&quot;Error occurred: &quot;, err) } else { panic(fmt.Sprintf(&quot;I don't know what to do: %v&quot;, r)) } }() a := 1 b := 0 fmt.Println(a / b) // runtime error: integer divide by zero // panic(errors.New(&quot;this is an error&quot;)) // panic(123) // 如果不是一个错误的话就, 再次 panic 出去}func main() { tryRecover() } 并发编程goroutine1、协程 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟器层面的多任务 多个协程可能在一个或者多个线程上运行 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func test() { // 此时, 不会输出, main 先退出了, 必须让 main sleep for i := 0; i &lt; 1000; i++ { // 匿名函数 go func(i int) { for { fmt.Printf(&quot;From %d\\n&quot;, i) } }(i) } time.Sleep(time.Millisecond)}func test2() { // 此时不会退出, 因为不能交出控制权 var arr [10]int for i := 0; i &lt; 10; i++ { // 匿名函数 go func(i int) { arr[i]++ }(i) } time.Sleep(time.Millisecond)}func main() { test() test2()} 2、go 语言中的调度器 协程可以相互通信 channelchannel是goroutine之间互相通讯的东西。类似我们 Unix 上的管道（可以在进程间传递消息），用来goroutine之间发消息和接收消息。其实，就是在做goroutine之间的内存共享。channel是类型相关的，也就是说一个channel只能传递一种类型的值，这个类型需要在channel声明时指定。 package mainimport ( &quot;fmt&quot; &quot;time&quot;)// 定义chanfunc defineChan() { // 声名一个传递int型的channel // var a chan int // 初始化一个int型channel a := make(chan int) // 从channel中获取 go func() { for { z := &lt;-a fmt.Println(z) } }() a &lt;- 1 time.Sleep(time.Millisecond)}// 定义带缓存chanfunc bufChan() { // 初始化一个int型channel a := make(chan int, 3) // 从channel中获取 go func() { for { //z, ok := &lt;-a //if !ok { // break //} //fmt.Println(z) // 或者使用这种, 确保发送完成 for z := range a { fmt.Println(z) } } }() a &lt;- 1 a &lt;- 2 a &lt;- 3 a &lt;- 4 close(a) // 关闭了的话, 就一直发送0 time.Sleep(time.Millisecond)}// 如何使用func chanDemo() { // 定义一个只能收数据的channel, 把数据放到channel中 var channels [10]chan&lt;- int for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i] &lt;- 'a' + i } time.Sleep(time.Millisecond)}func createWorker(i int) chan&lt;- int { c := make(chan int) go func() { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, &lt;-c) } }() return c}func main() { defineChan() bufChan() chanDemo()} 使用 Channel 等待任务结束package mainimport ( &quot;fmt&quot;)type worker struct { in chan int done chan bool // 使用done来通信确定完成}func chanDemo() { var channels [10]worker for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i].in &lt;- 'a' + i &lt;-channels[i].done // 等待channel完成 }}func createWorker(i int) worker { w := worker{ in: make(chan int), done: make(chan bool), } go func() { for in := range w.in { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, in) w.done &lt;- true } }() return w}func main() { chanDemo()} 使用 select 进行调度package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func selectDemo() { var c1, c2 chan int c1, c2 = createChan(), createChan() for { select { case n := &lt;-c1: fmt.Printf(&quot;from c1, val: %d\\n&quot;, n) case n := &lt;-c2: fmt.Printf(&quot;from c2, val: %d\\n&quot;, n) } }}func createChan() chan int { out := make(chan int) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) i++ out &lt;- i } }() return out}func main() { selectDemo()}","link":"/2019/10/11/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"title":"Java 中的锁","text":"Java中的锁分类在读很多并发文章中，会提及各种各样锁如公平锁，乐观锁等等，这篇文章介绍各种锁的分类。介绍的内容如下： 公平锁/非公平锁 可重入锁/不可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 上面是很多锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计，下面总结的内容是对每个锁的名词进行一定的解释。 公平锁/非公平锁是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 对于 Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁最近正在阅读Java ReentrantLock源码，始终对可重入和不可重入概念理解不透彻，进行学习后记录在这里。 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 Java多线程的 wait() 方法和 notify() 方法。这两个方法是成对出现和使用的，要执行这两个方法，有一个前提就是，当前线程必须获其对象的monitor（俗称“锁”），否则会抛 IllegalMonitorStateException 异常，所以这两个方法必须在同步块代码里面调用。wait()：阻塞当前线程， notify()：唤起被wait()阻塞的线程。 手动实现一个可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 手动实现一个不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 可重入锁的概念和设计思想大体如此，Java 中的可重入锁 ReentrantLock 设计思路也是这样。 独享锁/共享锁是什么 独享锁是指该锁一次只能被一个线程所持有。 共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 互斥锁/读写锁上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock 读写锁在Java中的具体实现就是ReadWriteLock 乐观锁/悲观锁乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。 从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在Java中的使用，就是利用各种锁。 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap 而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。 但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁/轻量级锁/重量级锁偏向锁 在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中 CAS 记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 缺点： 同样的，如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。 不过这个副作用已经小的多。 如果需要，使用参数-XX:-UseBiasedLocking禁止偏向锁优化（默认打开）。 轻量级锁 自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。 顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将 Mark Word 中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。 当然，由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 重量级锁 内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。 偏向锁、轻量级锁、重量级锁分配和膨胀的详细过程见后。会涉及一些Mark Word与CAS的知识。 偏向锁、轻量级锁、重量级锁适用于不同的并发场景： 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。 重量级锁：有实际竞争，且锁竞争时间长。 另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。 如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。 自旋锁首先，内核态与用户态的切换上不容易优化。但通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。 如果锁的粒度小，那么锁的持有时间比较短（尽管具体的持有时间无法得知，但可以认为，通常有一部分锁能满足上述性质）。那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。具体如下： 当前线程竞争锁失败时，打算阻塞自己 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会 在自旋的同时重新竞争锁 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己 如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。 “锁的持有时间比较短“这一条件可以放宽。实际上，只要锁竞争的时间比较短（比如线程1快释放锁的时候，线程2才会来竞争锁），就能够提高自旋获得锁的概率。这通常发生在锁持有时间长，但竞争不激烈的场景中。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 典型的自旋锁实现的例子，可以参考自旋锁的实现 锁分配和膨胀过程 参考链接 Java中的锁分类 Java不可重入锁和可重入锁理解 浅谈偏向锁、轻量级锁、重量级锁","link":"/2019/02/13/Java%20%E4%B8%AD%E7%9A%84%E9%94%81/"},{"title":"Spring注解驱动开发（一）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 组件注册@Configuration和@Bean的注入1、使用xml方式 我们一起注入一个bean使用xml来配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;person&quot; class=&quot;com.cuzz.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;cuzz&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 我可以使用ClassPathXmlApplicationContext来获取 /** * @Author: cuzz * @Date: 2018/9/23 10:48 * @Description: */public class MainTest { public static void main(String[] args) { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;); // 用id获取 Person bean = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(bean); }} 输出Person(name=cuzz, age=18) 2、使用注解的方式 编写一个配置类 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 可以通过AnnotationConfigApplicationContext来获取，并且获取id /** * @Author: cuzz * @Date: 2018/9/23 10:59 * @Description: */public class MainTest { public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Person person = (Person) context.getBean(Person.class); System.out.println(person); String[] names = context.getBeanNamesForType(Person.class); for (String name: names) { System.out.println(name); } }} 输出 Person(name=vhsj, age=16)person01 由于给bean添加一个一个value，可以改变默认id 组件注册@ComponentScan1、使用xml 只要标注了注解就能扫描到如： @Controller @Service @Repository @Component &lt;context:component-scan base-package=&quot;com.cuzz&quot;&gt;&lt;/context:component-scan&gt; 2、注解 在配置类中添加 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;) // 指定包public class MainConfig { } 添加controller、service等 测试 /** * @Author: cuzz * @Date: 2018/9/23 13:03 * @Description: */public class IOCTest { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } }} 输出结果 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookControllerbookDaobookServiceperson01 可以看出添加@Controller @Service @Repository @C omponent注解的都可以扫描到 还可以指定添加某些类，和排除某些类，进入ComponentScan注解中有下面两个方法 ComponentScan.Filter[] includeFilters() default {};ComponentScan.Filter[] excludeFilters() default {};includeFilters = Filter[] ：指定扫描的时候只需要包含哪些组件excludeFilters = Filter[] ：指定扫描的时候按照什么规则排除那些组件 配置类，排除Controller @Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;, excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {Controller.class})})public class MainConfig {} 运行测试方法，可以得出没有Controller类的 org.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaobookServiceperson01 自定义TypeFilter指定过滤规则 第一和第二比较常用 FilterType.ANNOTATION：按照注解FilterType.ASSIGNABLE_TYPE：按照给定的类型；FilterType.ASPECTJ：使用ASPECTJ表达式FilterType.REGEX：使用正则指定FilterType.CUSTOM：使用自定义规则 新建一个MyTypeFilte类实现TypeFilter接口 /** * @Author: cuzz * @Date: 2018/9/23 15:03 * @Description: */public class MyTypeFilter implements TypeFilter{ /** * metadataReader：读取到的当前正在扫描的类的信息 * metadataReaderFactory:可以获取到其他任何类信息的 */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { // 获取当前类注解的信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); // 获取当前类资源（类的路径） Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println(&quot;---&gt;&quot;+className); // 这些类名中包含er就返回true if(className.contains(&quot;er&quot;)){ return true; } return false; }} 使用自定义注解记得需要关闭默认过滤器useDefaultFilters = false /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration @ComponentScan(value = &quot;com.cuzz&quot;, includeFilters = @ComponentScan.Filter(type = FilterType.CUSTOM, classes = MyTypeFilter.class), useDefaultFilters = false)public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 测试 ---&gt;com.cuzz.AppTest---&gt;com.cuzz.bean.MainTest---&gt;com.cuzz.config.IOCTest---&gt;com.cuzz.config.MainTest---&gt;com.cuzz.App---&gt;com.cuzz.bean.Person---&gt;com.cuzz.config.MyTypeFilter---&gt;com.cuzz.controller.BookController---&gt;com.cuzz.dao.BookDao---&gt;com.cuzz.sevice.BookServiceorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig // 不是扫描的 person // 这个是在bean中myTypeFilter // 有erbookController // 有erbookService // 有erperson01 // 这个是在bean中 组件注册@Scope设置作用域Spring的bean默认是单例的 @Testpublic void test02() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } Object bean = applicationContext.getBean(&quot;person&quot;); Object bean2 = applicationContext.getBean(&quot;person&quot;); System.out.println(bean == bean2); // 输出true} Scope的四个范围 ConfigurableBeanFactory#SCOPE_PROTOTYPE // 多实例 每次获取时创建对象，不会放在ioc容器中ConfigurableBeanFactory#SCOPE_SINGLETON // 单实例 ioc容器启动是创建对象，以后从容器中获取WebApplicationContext#SCOPE_REQUEST // web同一次请求创建一个实例WebApplicationContext#SCOPE_SESSION // web同一个session创建一个实例 如果我们把Scope修改 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: */@Configurationpublic class MainConfig2 { @Scope(value = &quot;prototype&quot;) @Bean public Person person() { return new Person(&quot;vhuj&quot;, 25); }} 则测试输出false 组件注册@Lazy-bean懒加载懒加载 懒加载的是针对单实例Bean，默认是在容器启动的时创建的，我们可以设置懒加载容器启动是不创建对象，在第一次使用（获取）Bean创建对象，并初始化 测试 先给添加一个@Lazy注解 @Configurationpublic class MainConfig2 { @Lazy @Bean public Person person() { System.out.println(&quot;给容器中添加Person...&quot;); return new Person(&quot;vhuj&quot;, 25); }} 编写一个测试方法 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); System.out.println(&quot;ioc容器创建完成...&quot;); Object bean = applicationContext.getBean(&quot;person&quot;);} 输出 ioc容器创建完成...给容器中添加Person... 添加一个@Lazy是在第一次获取时，创建对象，以后获取就不需要创建了，直接从容器中获取，因为它是单实例 组件注册@Conditional按条件注册按照一定条件进行判断，满足条件给容器中注册Bean 编写自己的Condition类 如果系统是windows，给容器中注入”bill” 如果系统是linux，给容器中注入”linus” 编写WindowCondition类并重写matches方法 /** * @Author: cuzz * @Date: 2018/9/23 20:30 * @Description: 判断是否是windows */ public class WindowCondition implements Condition{ /** * @param context 判断条件 * @param metadata 注释信息 * @return boolean */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); if (property.contains(&quot;Windows&quot;)) { return true; } return false; } } context有以下方法 // 能获取ioc使用的beanfactoryConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// 能获取到类加载器ClassLoader classLoader = context.getClassLoader();// 获取到环境变量Environment environment = context.getEnvironment();// 获取到Bean定义的注册类BeanDefinitionRegistry registry = context.getRegistry(); 配置类 添加Bean添加Condition条件 @Configurationpublic class MainConfig2 { @Conditional({WindowCondition.class}) @Bean(&quot;bill&quot;) public Person person01() { return new Person(&quot;Bill Gates&quot;, 60); } @Conditional({LinuxCondition.class}) @Bean(&quot;linux&quot;) public Person person02() { return new Person(&quot;linus&quot;, 45); }} 测试 @Testpublic void test04() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取环境变量 ConfigurableEnvironment environment = applicationContext.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); System.out.println(property); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } // key 是id Map&lt;String, Person&gt; map = applicationContext.getBeansOfType(Person.class); System.out.println(map);} 发现只有“bill”这个Bean被注入 Windows 7org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2bill{bill=Person(name=Bill Gates, age=60)} 组件注册@Improt给容器中快速导入一个组件@Import导入 @Import可以导入第三方包，或则自己写的类，比较方便，Id默认为全类名 比如我们新建一个类 /** * @Author: cuzz * @Date: 2018/9/23 21:08 * @Description: */public class Color {} 我们只需要在配置类添加一个@Import把这个类导入 @Import({Color.class})@Configurationpublic class MainConfig2 {} ImportSelector接口导入的选择器 返回导入组件需要的全类名的数组 public interface ImportSelector { /** * Select and return the names of which class(es) should be imported based on * the {@link AnnotationMetadata} of the importing @{@link Configuration} class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);} 编写一个MyImportSelector类实现ImportSelector接口 /** * @Author: cuzz * @Date: 2018/9/23 21:15 * @Description: */public class MyImportSelector implements ImportSelector{ // 返回值就导入容器组件的全类名 // AnnotationMetadata:当前类标注的@Import注解类的所有注解信息 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { return new String[] {&quot;com.cuzz.bean.Car&quot;}; }} 在配置类中，通过@Import导入 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class})@Configurationpublic class MainConfig2 {} 测试结果，com.cuzz.bean.Car注入了 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car ImportBeanDefinitionRegistrar接口选择器 public interface ImportBeanDefinitionRegistrar { /** * Register bean definitions as necessary based on the given annotation metadata of * the importing {@code @Configuration} class. * &lt;p&gt;Note that {@link BeanDefinitionRegistryPostProcessor} types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to {@code @Configuration} * class processing. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);} 编写一个ImportBeanDefinitionRegistrar实现类 /** * @Author: cuzz * @Date: 2018/9/23 21:29 * @Description: */public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { /** * @param importingClassMetadata 当前类的注解信息 * @param registry 注册类 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 查询容器 boolean b = registry.containsBeanDefinition(&quot;com.cuzz.bean.Car&quot;); // 如果有car, 注册一个汽油类 if (b == true) { // 需要添加一个bean的定义信息 RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Petrol.class); // 注册一个bean, 指定bean名 registry.registerBeanDefinition(&quot;petrol&quot;, rootBeanDefinition); } }} 配置类 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})@Configurationpublic class MainConfig2 {} 测试结果，出现了petrol org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car petrol 组件注册使用FactoryBean注册组件编写一个ColorFactoryBean类 /** * @Author: cuzz * @Date: 2018/9/23 21:55 * @Description: Spring定义的工厂Bean */public class ColorFactoryBean implements FactoryBean&lt;Color&gt; { // 返回一个Color对象 @Override public Color getObject() throws Exception { return new Color(); } @Override public Class&lt;?&gt; getObjectType() { return Color.class; } // 是否为单例 @Override public boolean isSingleton() { return true; }} 注入到容器中 @Beanpublic ColorFactoryBean colorFactoryBean() { return new ColorFactoryBean();} 测试 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass());} 输出，发现此时的bean调用的方法是getObjectType方法 colorFactoryBean的类型是: class com.cuzz.bean.Color 如果需要获取BeanFactory本身，可以在id前面加一个“&amp;”标识 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass()); Object bean2 = applicationContext.getBean(&quot;&amp;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean2.getClass());} 此时输出 colorFactoryBean的类型是: class com.cuzz.bean.ColorcolorFactoryBean的类型是: class com.cuzz.bean.ColorFactoryBean 总结给容器中注册组件： 包扫描 + 组件组件（@Controller / @Service / @Repository / @Component） @Bean[导入第三方包组件] @Import[快速给容器中导入一个组件] @Import（要导入到容器中的组件），容器中就会自动注册这个组件，id 默认是全类名 ImportSelector，返回需要导入的组件的全类名数组 ImportBeanDefinitionRegistrar，手动注册bean到容器中 使用 Spring 提供的 FactoryBean （工厂Bean） 默认获取到的是工厂 bean 调用的 getObject 创建的对象 要获取工厂 Bean 本身，我们需要个 id 前面加一个 &amp; 符号，如 &amp;colorFactoryBean","link":"/2018/09/23/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Dubbo SPI源码分析","text":"对于一个优秀的框架需要很好的扩展性，给出一个接口，自己可以给出默认实现，同时也允许其他人实现拓展。即“对扩展开放，对修改封闭”的原则。Dubbo 采用微内核+插件的方式来实现，微内核架构中，内核通常采用 Factory、IoC、OSGi 等方式管理插件生命周期，Dubbo 最终决定采用 SPI 机制来加载插件，Dubbo SPI 参考 JDK 原生的 SPI 机制，进行了性能优化以及功能增强。 我们来看看 SPI 定义： Service Provider Interface (SPI) is an API intended to be implemented or extended by a third party. It can be used to enable framework extension and replaceable components. JDK SPIJDK SPI 最比较常见的在访问数据库会使用到java.sql.Driver这个接口，不同的数据库产商会有不同的实现，JDK SPI机制可以为某个接口寻找服务实现。 JDK SPI 机制我们先看一个例子，模拟连接数据库，先定义一个 Driver 接口。 package com.cuzz.api;public interface Driver { void connect(String url);} 然后不同的产商有不同的实现，以 mysql 和 oracle 两个实现。 package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/services 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 JDK SPI 需要读取的配置文件，具体内容如下： com.cuzz.mysql.MysqlDrivercom.cuzz.oracle.OracleDriver 加载配置： public class Main { public static void main(String[] args) { // Java spi 机制 ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); System.out.println(serviceLoader); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while (iterator.hasNext()) { Driver driver = iterator.next(); driver.connect(&quot;localhost:3306&quot;); } }} 运行结果： java.util.ServiceLoader[com.cuzz.api.Driver]connect mysql: localhost:3306connect oracle: localhost:3306 JDK SPI 源码分析我们从ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class);定位到ServiceLoader构造方法中的java.util.ServiceLoader#reload方法 // 前缀private static final String PREFIX = &quot;META-INF/services/&quot;;// The class or interface representing the service being loadedprivate final Class&lt;S&gt; service;// The class loader used to locate, load, and instantiate providersprivate final ClassLoader loader;// The access control context taken when the ServiceLoader is createdprivate final AccessControlContext acc;// Cached providers, in instantiation order// 缓存private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();// The current lazy-lookup iterator// 懒加载迭代器private LazyIterator lookupIterator;public void reload() { providers.clear(); lookupIterator = new LazyIterator(service, loader);} 重点看看这个 LazyIterator 类，这是一个内部类，主要以懒加载形式实现。Iterator 这个接口需要实现 Iterator#hasNext 方法和 Iterator#next 方法，hasNext方法调用了LazyIterator#hasNextService，而next方法调用LazyIterator#nextService。 private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; // 像这样的URL file:/Users/cuzz/Projects/Java/dubbo/cuzz-demo/cuzz-demo-spi/target/classes/META-INF/services/com.cuzz.api.Driver Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } // 第一次获取，config 为空开始加载文件 if (configs == null) { try { // 获取文件名 META-INF/services/com.cuzz.api.Driver String fullName = PREFIX + service.getName(); // 加载配置路径 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } // 解析文件 pending = parse(service, configs.nextElement()); } // 把实现类的名称记录下来 com.cuzz.mysql.MysqlDriver nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); // 存一个备份 String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { // 通过反射获取该实现类 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }} 最后我们来 ServiceLoader#iterator 这个方法是怎么实现的，主要是先走缓存，在走懒加载。 public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); } public S next() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } };} JDK SPI 在 JDBC 中的应用当我们引入mysql 驱动时候，在 META-INF/services 目录下，有一个 java.sql.Driver 文件，内容如下。 om.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 当我们要链接 JDBC 会通过 DriverManager驱动管理来连接。 String url = &quot;jdbc:mysql://localhost:3306/demo?useSSL=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;;String username = &quot;root&quot;;String pwd = &quot;12345&quot;;Connection conn = DriverManager.getConnection(url, username, pwd); DriverManager类的静态方法在 JVM加载类的时候会执行，执行 loadInitialDrivers 方法。 private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;); } private static void loadInitialDrivers() { // 看看系统属性是否配置了jdbc.drivers String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } // If the driver is packaged as a Service Provider, load it. // Get all the drivers through the classloader // exposed as a java.sql.Driver.class service. // ServiceLoader.load() replaces the sun.misc.Providers() AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // JDK SPI 方式加载并实例化 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); /* Load these drivers, so that they can be instantiated. * It may be the case that the driver class may not be there * i.e. there may be a packaged driver with the service class * as implementation of java.sql.Driver but the actual class * may be missing. In that case a java.util.ServiceConfigurationError * will be thrown at runtime by the VM trying to locate * and load the service. * * Adding a try catch block to catch those runtime errors * if driver not available in classpath but it's * packaged as service and that service is there in classpath. */ try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } // 配置了jdbc.dirvers属性通过反射实例化 String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 实例化 java.sql.Driver 接口实现类，在MySQL提供的，会吧自己注册到 DriverManager 中。 package com.mysql.jdbc;import java.sql.SQLException;public class Driver extends NonRegisteringDriver implements java.sql.Driver { // Register ourselves with the DriverManager static { try { // 注册到DriverManager的CopyOnWriteArrayList中 java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can't register driver!&quot;); } }} 最后调用 DriverManager#getConnection 从注册中获取连接。 // Worker method called by the public getConnection() methods.private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException { // 循环从注册中获取，获取到一个就返回。 for(DriverInfo aDriver : registeredDrivers) { try { Connection con = aDriver.driver.connect(url, info); if (con != null) { // Success! println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName()); return (con); } } catch (SQLException ex) { if (reason == null) { reason = ex; } } }} JDK SPI 的缺点 虽然ServiceLoader也算是使用的延迟加载，但是基本只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果你并不想用某些实现类，它也被加载并实例化了，这就造成了浪费。 获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 Dubbo SPIDubbo SPI 对 JDK SPI 进行了扩展，由原来的提供者类的全限定名列表改成了 K-V 形式，如果 SPI 配置文件中定义了多个实现类，而我们只需要使用其中一个实现类时，就会生成不必要的对象，除此之外 Dubbo 对 JDK SPI 做了三个方面的扩展： 方便获取扩展实现：JDK SPI仅仅通过接口类名获取所有实现，而 ExtensionLoader 则通过接口类名和key值获取一个实现。 IOC依赖注入功能：Adaptive实现，就是生成一个代理类，这样就可以根据实际调用时的一些参数动态决定要调用的类了。 采用装饰器模式进行功能增强，自动包装实现，这种实现的类一般是自动激活的，常用于包装类，比如：Protocol的两个实现类：ProtocolFilterWrapper、ProtocolListenerWrapper。 Dubbo 按照 SPI 配置文件的用途，将其分成了三类目录。 META-INF/services/ 目录：该目录下的 SPI 配置文件用来兼容 JDK SPI 。 META-INF/dubbo/ 目录：该目录用于存放用户自定义 SPI 配置文件。 META-INF/dubbo/internal/ 目录：该目录用于存放 Dubbo 内部使用的 SPI 配置文件。 Dubbo SPI 机制定义一个接口，用 @SPI 标识表示是 Dubbo SPI。 @SPIpublic interface Driver { void connect(String url);} 实现类： package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/dubbo 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 Dubbo SPI 需要读取的配置文件，与JDK SPI 不一样是KV形式，具体内容如下： mysqlDriver=com.cuzz.mysql.MysqlDriveroracleDriver=com.cuzz.oracle.OracleDriver 获取实现类： public class App { public static void main(String[] args) { Driver driver = ExtensionLoader.getExtensionLoader(Driver.class).getExtension(&quot;mysqlDriver&quot;); driver.connect(&quot;localhost:3306&quot;); }} 输出： connect mysql: localhost:3306 Dubbo SPI 主流程我们先从获取 ExtensLoader 实例开始，ExtensionLoader#getExtensionLoader /** * Dubbo 中一个扩展接口对应一个 ExtensionLoader 实例，该集合缓存了全部 ExtensionLoader 实例， * 其中的 Key 为扩展接口，Value 为加载其扩展实现的 ExtensionLoader 实例。 */private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;&gt;(64);public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) { if (type == null) { throw new IllegalArgumentException(&quot;Extension type == null&quot;); } // 必须为接口 if (!type.isInterface()) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an interface!&quot;); } // 必须有@SPI接口 if (!withExtensionAnnotation(type)) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an extension, because it is NOT annotated with @&quot; + SPI.class.getSimpleName() + &quot;!&quot;); } // 从缓存中获取 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) { // 如果已经存在 key 就不往 map 中添加 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); // ---&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); } return loader;} 接着看看 ExtensionLoader#ExtensionLoader 构造方法，如果 type 不为 ExtensionFactory.class 初始化拓展适配器。 /*** 表示拓展类实例工厂，可以通过工厂创建实例*/private final ExtensionFactory objectFactory;private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} 获取拓展实现类，ExtensionLoader#getExtension /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现对象之间的映射关系。*/private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;&gt;();public T getExtension(String name) { if (StringUtils.isEmpty(name)) { throw new IllegalArgumentException(&quot;Extension name == null&quot;); } // @SPI中value有值，如@SPI(&quot;dubbo&quot;) 默认获取 key 为 dubbo 的 Extension if (&quot;true&quot;.equals(name)) { return getDefaultExtension(); } // getOrCreateHolder()方法中封装了查找cachedInstances缓存的逻辑 final Holder&lt;Object&gt; holder = getOrCreateHolder(name); Object instance = holder.get(); if (instance == null) { synchronized (holder) { // 双重锁防止并发 instance = holder.get(); if (instance == null) { instance = createExtension(name); // ---&gt; holder.set(instance); } } } return (T) instance;}private Holder&lt;Object&gt; getOrCreateHolder(String name) { Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) { cachedInstances.putIfAbsent(name, new Holder&lt;&gt;()); holder = cachedInstances.get(name); } return holder;} ExtensionLoader#createExtension 方法中完成了 SPI 配置文件的查找以及相应扩展实现类的实例化，同时还实现了自动装配以及自动 Wrapper 包装等功能。 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); // ---&gt; 1 if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容. Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} Dubbo SPI 获取拓展类ExtensionLoader#getExtensionClasses /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现类之间的映射关系。cachedNames 集合的反向关系缓存。*/private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;&gt;();private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() { // 先从缓存中获取 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) { synchronized (cachedClasses) { classes = cachedClasses.get(); if (classes == null) { // 加载类 classes = loadExtensionClasses(); // ---&gt; cachedClasses.set(classes); } } } return classes;} ExtensionLoader#loadExtensionClasses /*** synchronized in getExtensionClasses*/private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() { // 只能有一个默认值 cacheDefaultExtensionName(); // 加载的扩展名与扩展实现类之间的映射关系 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;&gt;(); for (LoadingStrategy strategy : strategies) { loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); // ---&gt; loadDirectory(extensionClasses, strategy.directory(), type.getName().replace(&quot;org.apache&quot;, &quot;com.alibaba&quot;), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); } return extensionClasses;}private void cacheDefaultExtensionName() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation == null) { return; } String value = defaultAnnotation.value(); // 只能有一个车默认值，这种 @SPI(&quot;dubbo,http&quot;) 就会报错 if ((value = value.trim()).length() &gt; 0) { String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) { throw new IllegalStateException(&quot;More than 1 default extension name on extension &quot; + type.getName() + &quot;: &quot; + Arrays.toString(names)); } if (names.length == 1) { cachedDefaultName = names[0]; } }} ExtensionLoader#loadDirectory private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type, boolean extensionLoaderClassLoaderFirst, boolean overridden, String... excludedPackages) { String fileName = dir + type; try { Enumeration&lt;java.net.URL&gt; urls = null; ClassLoader classLoader = findClassLoader(); // try to load from ExtensionLoader's ClassLoader first if (extensionLoaderClassLoaderFirst) { ClassLoader extensionLoaderClassLoader = ExtensionLoader.class.getClassLoader(); if (ClassLoader.getSystemClassLoader() != extensionLoaderClassLoader) { urls = extensionLoaderClassLoader.getResources(fileName); } } if (urls == null || !urls.hasMoreElements()) { if (classLoader != null) { urls = classLoader.getResources(fileName); } else { urls = ClassLoader.getSystemResources(fileName); } } // 循环获取 if (urls != null) { while (urls.hasMoreElements()) { java.net.URL resourceURL = urls.nextElement(); loadResource(extensionClasses, classLoader, resourceURL, overridden, excludedPackages); // ---&gt; } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, description file: &quot; + fileName + &quot;).&quot;, t); }} ExtensionLoader#loadResource private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL, boolean overridden, String... excludedPackages) { try { // 必须 utf-8 格式 try (BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null) { final int ci = line.indexOf('#'); if (ci &gt;= 0) { // 去掉注释 line = line.substring(0, ci); } line = line.trim(); if (line.length() &gt; 0) { try { String name = null; int i = line.indexOf('='); if (i &gt; 0) { name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); } // 没有被排除外 if (line.length() &gt; 0 &amp;&amp; !isExcluded(line, excludedPackages)) { loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name, overridden); // ---&gt; } } catch (Throwable t) { IllegalStateException e = new IllegalStateException(&quot;Failed to load extension class (interface: &quot; + type + &quot;, class line: &quot; + line + &quot;) in &quot; + resourceURL + &quot;, cause: &quot; + t.getMessage(), t); exceptions.put(line, e); } } } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, class file: &quot; + resourceURL + &quot;) in &quot; + resourceURL, t); }} ExtensionLoader#loadClass private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name, boolean overridden) throws NoSuchMethodException { if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(&quot;Error occurred when loading extension class (interface: &quot; + type + &quot;, class line: &quot; + clazz.getName() + &quot;), class &quot; + clazz.getName() + &quot; is not subtype of interface.&quot;); } // 处理Adaptive注解，若存在则将该实现类保存至cachedAdaptiveClass属性 if (clazz.isAnnotationPresent(Adaptive.class)) { cacheAdaptiveClass(clazz, overridden); } // 是否为包装类，是包装类缓存到 cachedWrapperClasses Set中 else if (isWrapperClass(clazz)) { cacheWrapperClass(clazz); } else { clazz.getConstructor(); if (StringUtils.isEmpty(name)) { name = findAnnotationName(clazz); if (name.length() == 0) { throw new IllegalStateException(&quot;No such extension name for the class &quot; + clazz.getName() + &quot; in the config &quot; + resourceURL); } } // key可以为多个，如：mysqlDriver,mysqlDriver2=com.cuzz.mysql.MysqlDriver String[] names = NAME_SEPARATOR.split(name); if (ArrayUtils.isNotEmpty(names)) { // 缓存到 cachedActivates 属性中 cacheActivateClass(clazz, names[0]); for (String n : names) { // 缓存了该 ExtensionLoader 加载的扩展实现类与扩展名之间的映射关系。 cacheName(clazz, n); // 加载的扩展名与扩展实现类之间的映射关系 saveInExtensionClass(extensionClasses, clazz, n, overridden); } } }}private void cacheAdaptiveClass(Class&lt;?&gt; clazz, boolean overridden) { if (cachedAdaptiveClass == null || overridden) { cachedAdaptiveClass = clazz; } else if (!cachedAdaptiveClass.equals(clazz)) { throw new IllegalStateException(&quot;More than 1 adaptive class found: &quot; + cachedAdaptiveClass.getName() + &quot;, &quot; + clazz.getName()); }} Dubbo SPI 的自动包装和自动注入回到前面我们分析ExtensionLoader#createExtension方法，现在我们重点关注 ExtensionLoader#injectExtension 方法 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // ---&gt; // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容。 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { // 遍历所有的包装类，包装类需要有一个参数类被包装类型的构造器。 for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} ExtensionLoader#injectExtension private T injectExtension(T instance) { if (objectFactory == null) { return instance; } try { for (Method method : instance.getClass().getMethods()) { // 判断是否为set方法 if (!isSetter(method)) { continue; } // 如果有 @DisableInject 注解也不注入 if (method.getAnnotation(DisableInject.class) != null) { continue; } // 获取参数类型，如果是基本类型也忽略 Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) { continue; } try { // 根据 Setter 方法获取属性名 String property = getSetterProperty(method); // 加载这个类，并实例化 Object object = objectFactory.getExtension(pt, property); if (object != null) { // 反射注入 method.invoke(instance, object); } } catch (Exception e) { logger.error(&quot;Failed to inject via method &quot; + method.getName() + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e); } } } catch (Exception e) { logger.error(e.getMessage(), e); } return instance;} Dubbo SPI 的 @Adaptive 注解与适配器在dubbo扩展中，适配器模式被广泛使用，其作用在于为同一扩展类型下的多个扩展实现的调用提供路由功能，如指定优先级等。dubbo提供了两种方式来生成扩展适配器： 静态代码形式的默认适配器：这些类会被Adaptive注解修饰，且一个接口只能有一个这样的静态适配器。这种形式仅应用于一些特殊的接口，如：AdaptiveCompiler、AdaptiveExtensionFactory这两个适配器，ExtensionLoader需要依赖它们来工作，所以使用了这种特殊的构建方式。 动态代码适配器：实际上其余的接口都是使用动态适配器，ExtensionLoader 根据接口定义动态生成一段适配器代码，并构建这个动态类的实例。这个时候接口中的一些方法具有 Adaptive 标记，它提供了一些用于查找具体 Extension 的key，如果这些方法中有URL类型的参数，则会依次在url中查找这些key对应的value，再以此为 name 确定要使用的 Extension。如果没有从url中找到该参数，则会使用 SPI 注解中的默认值 name 进行构建。 我们回到构造方法中ExtensionLoader#getAdaptiveExtension private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} ExtensionLoader#getAdaptiveExtension public T getAdaptiveExtension() { // 先从缓存中获取 Object instance = cachedAdaptiveInstance.get(); if (instance == null) { if (createAdaptiveInstanceError != null) { throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); } synchronized (cachedAdaptiveInstance) { instance = cachedAdaptiveInstance.get(); if (instance == null) { try { // 创建 instance = createAdaptiveExtension(); // ---&gt; 1 cachedAdaptiveInstance.set(instance); } catch (Throwable t) { createAdaptiveInstanceError = t; throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + t.toString(), t); } } } } return (T) instance;}private T createAdaptiveExtension() { try { // 注入属性 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); // ---&gt; 2 } catch (Exception e) { throw new IllegalStateException(&quot;Can't create adaptive extension &quot; + type + &quot;, cause: &quot; + e.getMessage(), e); }}private Class&lt;?&gt; getAdaptiveExtensionClass() { getExtensionClasses(); if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } return cachedAdaptiveClass = createAdaptiveExtensionClass(); // ---&gt; 3}private Class&lt;?&gt; createAdaptiveExtensionClass() { // 创建适配器类，并继承 type 接口 String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); // ---&gt; 4 ClassLoader classLoader = findClassLoader(); // ExtensionLoader再调用默认的JavassitCompiler进行编译和类加载 org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader);} ExtensionLoader#createAdaptiveExtensionClass 以 Transsporter为例子 @SPI(&quot;netty&quot;) public interface Transporter { @Adaptive({Constants.SERVER_KEY, Constants.TRANSPORTER_KEY}) RemotingServer bind(URL url, ChannelHandler handler) throws RemotingException; @Adaptive({Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY}) Client connect(URL url, ChannelHandler handler) throws RemotingException; } Dubbo 会生成一个 Transporter$Adaptive 适配器类，该类继承了 Transporter 接口： public class Transporter$Adaptive implements Transporter { public org.apache.dubbo.remoting.Client connect(URL arg0, ChannelHandler arg1) throws RemotingException { // 必须传递URL参数 if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg0; // 确定扩展名，优先从URL中的client参数获取，其次是transporter参数 // 这两个参数名称由@Adaptive注解指定，最后是@SPI注解中的默认值 String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if (extName == null) throw new IllegalStateException(&quot;...&quot;); // 通过ExtensionLoader加载Transporter接口的指定扩展实现 Transporter extension = (Transporter) ExtensionLoader .getExtensionLoader(Transporter.class) .getExtension(extName); return extension.connect(arg0, arg1); } ... // 省略bind()方法 } Dubbo SPI 的 @Activate注解与自动激活特性这里以 Dubbo 中的 Filter 为例说明自动激活特性的含义，org.apache.dubbo.rpc.Filter 接口有非常多的扩展实现类，在一个场景中可能需要某几个 Filter 扩展实现类协同工作，而另一个场景中可能需要另外几个实现类一起工作。这样，就需要一套配置来指定当前场景中哪些 Filter 实现是可用的，这就是 @Activate 注解要做的事情。 @Activate 注解标注在扩展实现类上，有 group、value 以及 order 三个属性。 group 属性：修饰的实现类是在 Provider 端被激活还是在 Consumer 端被激活。 value 属性：修饰的实现类只在 URL 参数中出现指定的 key 时才会被激活。 order 属性：用来确定扩展实现类的排序。 如 Filter 接口和实现类： @SPIpublic interface Filter { Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException;1}@Activate(group = Constants.PROVIDER)public class TimeoutFilter implements Filter { ...}@Activate(group = {Constants.PROVIDER, Constants.CONSUMER})public class MonitorFilter implements Filter { ...} 首先来关注 getActivateExtension() 方法的参数：url 中包含了配置信息，values 是配置中指定的扩展名，group 为 Provider 或 Consumer。 public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) { List&lt;T&gt; activateExtensions = new ArrayList&lt;&gt;(); // values配置就是扩展名 List&lt;String&gt; names = values == null ? new ArrayList&lt;&gt;(0) : asList(values); if (!names.contains(REMOVE_VALUE_PREFIX + DEFAULT_KEY)) {// ---1 getExtensionClasses(); // 触发cachedActivates等缓存字段的加载 for (Map.Entry&lt;String, Object&gt; entry : cachedActivates.entrySet()) { String name = entry.getKey(); // 扩展名 Object activate = entry.getValue(); // @Activate注解 String[] activateGroup, activateValue; if (activate instanceof Activate) { // @Activate注解中的配置 activateGroup = ((Activate) activate).group(); activateValue = ((Activate) activate).value(); } else { continue; } if (isMatchGroup(group, activateGroup) // 匹配group // 没有出现在values配置中的，即为默认激活的扩展实现 &amp;&amp; !names.contains(name) // 通过&quot;-&quot;明确指定不激活该扩展实现 &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name) // 检测URL中是否出现了指定的Key &amp;&amp; isActive(activateValue, url)) { // 加载扩展实现的实例对象，这些都是激活的 activateExtensions.add(getExtension(name)); } } // 排序 --- 2 activateExtensions.sort(ActivateComparator.COMPARATOR); } List&lt;T&gt; loadedExtensions = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; names.size(); i++) { // ---3 String name = names.get(i); // 通过&quot;-&quot;开头的配置明确指定不激活的扩展实现，直接就忽略了 if (!name.startsWith(REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name)) { if (DEFAULT_KEY.equals(name)) { if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合前面 activateExtensions.addAll(0, loadedExtensions); loadedExtensions.clear(); } } else { loadedExtensions.add(getExtension(name)); } } } if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合后面 activateExtensions.addAll(loadedExtensions); } return activateExtensions; } 总结本文总结了 JDK SPI 和 Dubbo SPI 机制和原理，参考了很多文章，以下几点需要值得注意： JDK SPI 需要对加载实例化所有的推展对象，而 Dubbo SPI 根据 KV 形式，只需要实例化需要的拓展。 Dubbo SPI 对 JDK SPI 拓展了自动注入、自动注入以及自动激活等特性。 参考 Dubbo官网-Dubbo SPI Dubbo SPI 精析 Dubbo源码解读全集 聊聊Dubbo（五）：核心源码-SPI扩展 Dubbo源码分析（五）ExtensionLoader","link":"/2020/08/26/Dubbo%20SPI%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java 并发编程","text":"请谈谈你对 volatile 的理解volatile 是 Java 虚拟机提供的轻量级的同步机制 保证可见性 禁止指令排序 不保证原子性 JMM（Java 内存模型） JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JMM 同步规定 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。 首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 内存模型图 三大特性： 可见性 原子性 有序性 （1）可见性，如果不加 volatile 关键字，则主线程会进入死循环，加 volatile 则主线程能够退出，说明加了 volatile 关键字变量，当有一个线程修改了值，会马上被另一个线程感知到，当前值作废，从新从主内存中获取值。对其他线程可见，这就叫可见性。 /** * @Author: cuzz * @Date: 2019/4/16 21:29 * @Description: 可见性代码实例 */public class VolatileDemo { public static void main(String[] args) { Data data = new Data(); new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; coming...&quot;); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } data.addOne(); // 调用 System.out.println(Thread.currentThread().getName() + &quot; updated...&quot;); }).start(); while (data.a == 0) { // looping } System.out.println(Thread.currentThread().getName() + &quot; job is done...&quot;); }}class Data { // int a = 0; volatile int a = 0; void addOne() { this.a += 1; }} （2）原子性，发现下面输出不能得到 20000。 public class VolatileDemo { public static void main(String[] args) { // test01(); test02(); } // 测试原子性 private static void test02() { Data data = new Data(); for (int i = 0; i &lt; 20; i++) { new Thread(() -&gt; { for (int j = 0; j &lt; 1000; j++) { data.addOne(); } }).start(); } // 默认有 main 线程和 gc 线程 while (Thread.activeCount() &gt; 2) { Thread.yield(); } System.out.println(data.a); }}class Data { volatile int a = 0; void addOne() { this.a += 1; }} （3）有序性 计算机在执行程序时，为了提高性能，编译器个处理器常常会对指令做重排，一般分为以下 3 种 编译器优化的重排 指令并行的重排 内存系统的重排 单线程环境里面确保程序最终执行的结果和代码执行的结果一致 处理器在进行重排序时必须考虑指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证用的变量能否一致性是无法确定的，结果无法预测 代码示例 public class ReSortSeqDemo { int a = 0; boolean flag = false; public void method01() { a = 1; // flag = true; // ----线程切换---- flag = true; // a = 1; } public void method02() { if (flag) { a = a + 3; System.out.println(&quot;a = &quot; + a); } }} 如果两个线程同时执行，method01 和 method02 如果线程 1 执行 method01 重排序了，然后切换的线程 2 执行 method02 就会出现不一样的结果。 禁止指令排序 volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性） 由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 线程安全性保证 工作内存与主内存同步延迟现象导致可见性问题 可以使用 synchronzied 或 volatile 关键字解决，它们可以使用一个线程修改后的变量立即对其他线程可见 对于指令重排导致可见性问题和有序性问题 可以利用 volatile 关键字解决，因为 volatile 的另一个作用就是禁止指令重排序优化 你在哪些地方用到过 volatile？单例 多线程环境下可能存在的安全问题，发现构造器里的内容会多次输出 @NotThreadSafepublic class Singleton01 { private static Singleton01 instance = null; private Singleton01() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton01 getInstance() { if (instance == null) { instance = new Singleton01(); } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton01.getInstance()); } executorService.shutdown(); }} 双重锁单例 public class Singleton02 { private static volatile Singleton02 instance = null; private Singleton02() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton02 getInstance() { if (instance == null) { synchronized (Singleton01.class) { if (instance == null) { instance = new Singleton02(); } } } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton02.getInstance()); } executorService.shutdown(); }} 如果没有加 volatile 就不一定是线程安全的，原因是指令重排序的存在，加入 volatile 可以禁止指令重排。原因是在于某一个线程执行到第一次检测，读取到的 instance 不为 null 时，instance 的引用对象可能还没有完成初始化。instance = new Singleton() 可以分为以下三步完成。 memory = allocate(); // 1.分配对象空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null 步骤 2 和步骤 3 不存在依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种优化是允许的，发生重排。 memory = allocate(); // 1.分配对象空间instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null，但对象还没有初始化完成instance(memory); // 2.初始化对象 所以不加 volatile 返回的实例不为空，但可能是未初始化的实例 CAS 你知道吗？CAS 底层原理？谈谈对 UnSafe 的理解？public class CASDemo { public static void main(String[] args) { AtomicInteger atomicInteger = new AtomicInteger(666); // 获取真实值，并替换为相应的值 boolean b = atomicInteger.compareAndSet(666, 2019); System.out.println(b); // true boolean b1 = atomicInteger.compareAndSet(666, 2020); System.out.println(b1); // false atomicInteger.getAndIncrement(); }} getAndIncrement()方法 /*** Atomically increments by one the current value.** @return the previous value*/public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1);} 引出一个问题：UnSafe 类是什么？我们先看看AtomicInteger 就使用了Unsafe 类。 public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取下面 value 的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; // ...} Unsafe类： Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。 变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 CAS 是什么？ CAS 的全称 Compare-And-Swap，它是一条 CPU 并发。 它的功能是判断内存某一个位置的值是否为预期，如果是则更改这个值，这个过程就是原子的。 CAS 并发原体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。 分析一下 getAndAddInt 这个方法 // unsafe.getAndAddIntpublic final int getAndAddInt(Object obj, long valueOffset, long expected, int val) { int temp; do { temp = this.getIntVolatile(obj, valueOffset); // 获取快照值 } while (!this.compareAndSwap(obj, valueOffset, temp, temp + val)); // 如果此时 temp 没有被修改，就能退出循环，否则重新获取 return temp;} CAS 的缺点？ 循环时间长开销很大 如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。 只能保证一个共享变量的原子操作 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性。 引出 ABA 问题 原子类 AtomicInteger 的 ABA 问题谈一谈？原子更新引用知道吗？原子引用 public class AtomicReferenceDemo { public static void main(String[] args) { User cuzz = new User(&quot;cuzz&quot;, 18); User faker = new User(&quot;faker&quot;, 20); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(cuzz); System.out.println(atomicReference.compareAndSet(cuzz, faker)); // true System.out.println(atomicReference.get()); // User(userName=faker, age=20) }} ABA 问题是怎么产生的 /** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo { private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }).start(); new Thread(() -&gt; { // 保证上面线程先执行 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicReference.compareAndSet(100, 2019); System.out.println(atomicReference.get()); // 2019 }).start(); }} 当有一个值从 A 改为 B 又改为 A，这就是 ABA 问题。 时间戳原子引用 package com.cuzz.thread;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo2 { private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); }).start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(b); // false System.out.println(atomicStampedReference.getReference()); // 100 }).start(); }} 我们先保证两个线程的初始版本为一致，后面修改是由于版本不一样就会修改失败。 我们知道 ArrayList 是线程不安全，请编写一个不安全的案例并给出解决方案？故障现象 public class ContainerDemo { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 100; i++) { new Thread(() -&gt; { list.add(random.nextInt(10)); System.out.println(list); }).start(); } }} 发现报 java.util.ConcurrentModificationException 导致原因 并发修改导致的异常 解决方案 new Vector(); Collections.synchronizedList(new ArrayList&lt;&gt;()); new CopyOnWriteArrayList&lt;&gt;(); 优化建议 在读多写少的时候推荐使用 CopeOnWriteArrayList 这个类 java 中锁你知道哪些？请手写一个自旋锁？1、公平和非公平锁 是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 2、可重入锁和不可重入锁 是什么 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 代码实现 可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 测试 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 3、自旋锁 是指定尝试获取锁的线程不会立即堵塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上线文切换的消耗，缺点就是循环会消耗 CPU。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 4、独占锁（写锁）/共享锁（读锁） 是什么 独占锁：指该锁一次只能被一个线程持有 共享锁：该锁可以被多个线程持有 对于 ReentrantLock 和 synchronized 都是独占锁；对与 ReentrantReadWriteLock 其读锁是共享锁而写锁是独占锁。读锁的共享可保证并发读是非常高效的，读写、写读和写写的过程是互斥的。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 CountDownLatch/CyclicBarrier/Semaphore 使用过吗？1、CountDownLatch 让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒。CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，调用线程会被堵塞，其他线程调用 countDown 方法会将计数减一（调用 countDown 方法的线程不会堵塞），当计数其值变为零时，因调用 await 方法被堵塞的线程会被唤醒，继续执行。 假设我们有这么一个场景，教室里有班长和其他6个人在教室上自习，怎么保证班长等其他6个人都走出教室在把教室门给关掉。 public class CountDownLanchDemo { public static void main(String[] args) { for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...班长把门给关了，离开了教室...5 离开了教室...4 离开了教室... 发现班长都没有等其他人理他教室就把门给关了，此时我们就可以使用 CountDownLatch 来控制 public class CountDownLanchDemo { public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...4 离开了教室...5 离开了教室...班长把门给关了，离开了教室... 2、CyclicBarrier 我们假设有这么一个场景，每辆车只能坐个人，当车满了，就发车。 public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -&gt; { System.out.println(&quot;车满了，开始出发...&quot;); }); for (int i = 0; i &lt; 8; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 开始上车...&quot;); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } }} 输出结果 Thread-0 开始上车...Thread-1 开始上车...Thread-3 开始上车...Thread-4 开始上车...车满了，开始出发...Thread-5 开始上车...Thread-7 开始上车...Thread-2 开始上车...Thread-6 开始上车...车满了，开始出发... 3、Semaphore 假设我们有 3 个停车位，6 辆车去抢 public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { try { semaphore.acquire(); // 获取一个许可 System.out.println(Thread.currentThread().getName() + &quot; 抢到车位...&quot;); Thread.sleep(3000); System.out.println(Thread.currentThread().getName() + &quot; 离开车位&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); // 释放一个许可 } }).start(); } }} 输出 Thread-1 抢到车位...Thread-2 抢到车位...Thread-0 抢到车位...Thread-2 离开车位Thread-0 离开车位Thread-3 抢到车位...Thread-1 离开车位Thread-4 抢到车位...Thread-5 抢到车位...Thread-3 离开车位Thread-5 离开车位Thread-4 离开车位 堵塞队列你知道吗？1、阻塞队列有哪些 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）对元素进行排序。 LinkedBlokcingQueue：是一个基于链表结构的阻塞队列，此队列按 FIFO（先进先出）对元素进行排序，吞吐量通常要高于 ArrayBlockingQueue。 SynchronousQueue：是一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlokcingQueue。 2、什么是阻塞队列 阻塞队列，顾名思义，首先它是一个队列，而一个阻塞队列在数据结构中所起的作用大致如图所示： 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。 当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。 核心方法 方法\\行为 抛异常 特定的值 阻塞 超时 插入方法 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除方法 poll()、remove(o) take() poll(timeout, timeunit) 检查方法 element() peek() 行为解释： 抛异常：如果操作不能马上进行，则抛出异常 特定的值：如果操作不能马上进行，将会返回一个特殊的值，一般是 true 或者 false 阻塞：如果操作不能马上进行，操作会被阻塞 超时：如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是 true 或者 false 插入方法： add(E e)：添加成功返回true，失败抛 IllegalStateException 异常 offer(E e)：成功返回 true，如果此队列已满，则返回 false put(E e)：将元素插入此队列的尾部，如果该队列已满，则一直阻塞 删除方法： remove(Object o) ：移除指定元素,成功返回true，失败返回false poll()：获取并移除此队列的头元素，若队列为空，则返回 null take()：获取并移除此队列头元素，若没有元素则一直阻塞 检查方法： element() ：获取但不移除此队列的头元素，没有元素则抛异常 peek() :获取但不移除此队列的头；若队列为空，则返回 null 3、SynchronousQueue SynchronousQueue，实际上它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移出队列。 public class SynchronousQueueDemo { public static void main(String[] args) { SynchronousQueue&lt;Integer&gt; synchronousQueue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; { try { synchronousQueue.put(1); Thread.sleep(3000); synchronousQueue.put(2); Thread.sleep(3000); synchronousQueue.put(3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(() -&gt; { try { Integer val = synchronousQueue.take(); System.out.println(val); Integer val2 = synchronousQueue.take(); System.out.println(val2); Integer val3 = synchronousQueue.take(); System.out.println(val3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }} 4、使用场景 生产者消费者模式 线程池 消息中间件 synchronized 和 Lock 有什么区别？ 原始结构 synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。 Lock 是具体类（java.util.concurrent.locks.Lock）是 api 层面的锁。 使用方法 synchronized 不需要用户手动去释放锁，当 synchronized 代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock 则需要用户手动的释放锁，若没有主动释放锁，可能导致出现死锁的现象，lock() 和 unlock() 方法需要配合 try/finally 语句来完成。 等待是否可中断 synchronized 不可中断，除非抛出异常或者正常运行完成。 ReentrantLock 可中断，设置超时方法 tryLock(long timeout, TimeUnit unit)，lockInterruptibly() 放代码块中，调用 interrupt() 方法可中断。 加锁是否公平 synchronized 非公平锁 ReentrantLock 默认非公平锁，构造方法中可以传入 boolean 值，true 为公平锁，false 为非公平锁。 锁可以绑定多个 Condition synchronized 没有 Condition。 ReentrantLock 用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个线程要么唤醒全部线程。 线程池使用过吗？谈谈对 ThreadPoolExector 的理解？为什使用线程池，线程池的优势？ 线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，那么超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点为： 线程复用 控制最大并发数量 管理线程 主要优点 降低资源消耗，通过重复利用已创建的线程来降低线程创建和销毁造成的消耗。 提高相应速度，当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性，线程是稀缺资源，如果无限制的创建，不仅仅会消耗系统资源，还会降低体统的稳定性，使用线程可以进行统一分配，调优和监控。 创建线程的几种方式 继承 Thread 实现 Runnable 接口 实现 Callable public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { // 在 FutureTask 中传入 Callable 的实现类 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { return 666; } }); // 把 futureTask 放入线程中 new Thread(futureTask).start(); // 获取结果 Integer res = futureTask.get(); System.out.println(res); }} 线程池如果使用？ 架构说明 编码实现 Executors.newSingleThreadExecutor()：只有一个线程的线程池，因此所有提交的任务是顺序执行 Executors.newCachedThreadPool()：线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除 Executors.newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待 Executors.newScheduledThreadPool()：用来调度即将执行的任务的线程池 Executors.newWorkStealingPool()： newWorkStealingPool适合使用在很耗时的操作，但是newWorkStealingPool不是ThreadPoolExecutor的扩展，它是新的线程池类ForkJoinPool的扩展，但是都是在统一的一个Executors类中实现，由于能够合理的使用CPU进行对任务操作（并行操作），所以适合使用在很耗时的任务中 ThreadPoolExecutor ThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务。 线程池的几个重要参数介绍？ 参数 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过 corePoolSize 数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true) 使得核心线程有效时间 TimeUnit keepAliveTime 时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 说说线程池的底层工作原理？ 重点讲解： 其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。 当设置allowCoreThreadTimeOut(true) 时，线程池中 corePoolSize 线程空闲时间达到 keepAliveTime 也将关闭。 线程池用过吗？生产上你如何设置合理参数？线程池的拒绝策略你谈谈？ 是什么 等待队列已经满了，再也塞不下新的任务，同时线程池中的线程数达到了最大线程数，无法继续为新任务服务。 拒绝策略 AbortPolicy：处理程序遭到拒绝将抛出运行时 RejectedExecutionException CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 DiscardPolicy：不能执行的任务将被删除 DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 你在工作中单一的、固定数的和可变的三种创建线程池的方法，你用哪个多，超级大坑？ 如果读者对Java中的阻塞队列有所了解的话，看到这里或许就能够明白原因了。 Java中的BlockingQueue主要有两种实现，分别是ArrayBlockingQueue 和 LinkedBlockingQueue。 ArrayBlockingQueue是一个用数组实现的有界阻塞队列，必须设置容量。 LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。 这里的问题就出在：不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。也就是说，如果我们不设置LinkedBlockingQueue的容量的话，其默认容量将会是Integer.MAX_VALUE。 而newFixedThreadPool中创建LinkedBlockingQueue时，并未指定容量。此时，LinkedBlockingQueue就是一个无边界队列，对于一个无边界队列来说，是可以不断的向队列中加入任务的，这种情况下就有可能因为任务过多而导致内存溢出问题。 上面提到的问题主要体现在newFixedThreadPool和newSingleThreadExecutor两个工厂方法上，并不是说newCachedThreadPool和newScheduledThreadPool这两个方法就安全了，这两种方式创建的最大线程数可能是Integer.MAX_VALUE，而创建这么多线程，必然就有可能导致OOM。 你在工作中是如何使用线程池的，是否自定义过线程池使用？ 自定义线程池 public class ThreadPoolExecutorDemo { public static void main(String[] args) { Executor executor = new ThreadPoolExecutor(2, 3, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); }} 合理配置线程池你是如果考虑的？ CPU 密集型 CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。 IO 密集型 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 。 也可以使用公式：CPU 核数 / (1 - 阻塞系数)；其中阻塞系数在 0.8 ～ 0.9 之间。 死锁编码以及定位分析产生死锁的原因 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种相互等待的现象，如果无外力的干涉那它们都将无法推进下去，如果系统的资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。 代码 public class DeadLockDemo { public static void main(String[] args) { String lockA = &quot;lockA&quot;; String lockB = &quot;lockB&quot;; DeadLockDemo deadLockDemo = new DeadLockDemo(); Executor executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; deadLockDemo.method(lockA, lockB)); executor.execute(() -&gt; deadLockDemo.method(lockB, lockA)); } public void method(String lock1, String lock2) { synchronized (lock1) { System.out.println(Thread.currentThread().getName() + &quot;--获取到：&quot; + lock1 + &quot;; 尝试获取：&quot; + lock2); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (lock2) { System.out.println(&quot;获取到两把锁!&quot;); } } }} 解决 jps -l 命令查定位进程号 28519 org.jetbrains.jps.cmdline.Launcher32376 com.intellij.idea.Main28521 com.cuzz.thread.DeadLockDemo27836 org.jetbrains.kotlin.daemon.KotlinCompileDaemon28591 sun.tools.jps.Jps jstack 28521 找到死锁查看 2019-05-07 00:04:15Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode):&quot;Attach Listener&quot; #13 daemon prio=9 os_prio=0 tid=0x00007f7acc001000 nid=0x702a waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE// ...Found one Java-level deadlock:=============================&quot;pool-1-thread-2&quot;: waiting to lock monitor 0x00007f7ad4006478 (object 0x00000000d71f60b0, a java.lang.String), which is held by &quot;pool-1-thread-1&quot;&quot;pool-1-thread-1&quot;: waiting to lock monitor 0x00007f7ad4003be8 (object 0x00000000d71f60e8, a java.lang.String), which is held by &quot;pool-1-thread-2&quot;Java stack information for the threads listed above:===================================================&quot;pool-1-thread-2&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60b0&gt; (a java.lang.String) - locked &lt;0x00000000d71f60e8&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$1(DeadLockDemo.java:21) at com.cuzz.thread.DeadLockDemo$$Lambda$2/2074407503.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;pool-1-thread-1&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60e8&gt; (a java.lang.String) - locked &lt;0x00000000d71f60b0&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$0(DeadLockDemo.java:20) at com.cuzz.thread.DeadLockDemo$$Lambda$1/558638686.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 最后发现一个死锁。 后续JVM 面试 参考链接 Java内存模型-volatile","link":"/2019/04/16/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Full-Text Search","slug":"Full-Text-Search","link":"/tags/Full-Text-Search/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"英文","slug":"英文","link":"/tags/%E8%8B%B1%E6%96%87/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"OOP","slug":"OOP","link":"/tags/OOP/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"SPI","slug":"SPI","link":"/tags/SPI/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"categories":[{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"JAVA","slug":"JAVA","link":"/categories/JAVA/"},{"name":"Java 基础","slug":"Java-基础","link":"/categories/Java-%E5%9F%BA%E7%A1%80/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Dubbo","slug":"Dubbo","link":"/categories/Dubbo/"}]}