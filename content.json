{"pages":[{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz1234@163.com","link":"/about/index.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"","text":"","link":"/tags/index.html"},{"title":"","text":"","link":"/categories/index.html"}],"posts":[{"title":"Data Lab","text":"前言CSAPP 这本书买了好几年，最近抽出一些时间开始重头读这本书，发现这些基础知识比较重要，边看书边跟着视频课程过了一遍，有些东西还是比较模糊。本文开始做 CSAPP Lab 实验，加强巩固书的内容。 说明这个实验主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 任务指引还是比较清晰的，主要有以下一些说明： 整型的范围是 0 到 255(0xFF)，不允许用更大 只能包含参数和局部变量 一元操作符 ! ~ 二元操作符 &amp; | + &lt;&lt; &gt;&gt; 不允许的操作有： 使用任何条件控制语句 定义和使用宏 定义其他的函数 调用函数 使用其他的操作符 使用类型转换 使用除 int 之外的类型（针对整型） 使用除 int, unsigned 之外的类型（针对浮点数） 题目bitXor/* * bitXor - x^y using only ~ and &amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ &amp; * Max ops: 14 * Rating: 1 */int bitXor(int x, int y) { return ~(~(~x &amp; y) &amp; ~(x &amp; ~y));} 异或就是二级制不相等才为1，同时为 0 或者同时为 1，结果为 0 ，比如： 十进制 二进制 4 100 5 101 001 // 异或结果 其中(~x &amp; y) 表示 x 中的 0 和 y 中的 1，(x &amp; ~y)表示 x 中的 1和 y 中的 1，然后通过德·摩根定律~(a &amp; b) = ~a | ~b。 x ^ y = (~x &amp; y) | (x &amp; ~y) = ~(~(~x &amp; y) &amp; ~(x &amp; ~y)) tmin/* * tmin - return minimum two's complement integer * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 4 * Rating: 1 */int tmin(void) { return 1 &lt;&lt; 31;} 这个题目比较简单，int 有符号采用的是补码表示如图，最小为10000000 00000000 00000000 00000000 我们只需要把 1 往左移动 31 位就行。 isTmax//2/* * isTmax - returns 1 if x is the maximum, two's complement number, * and 0 otherwise * Legal ops: ! ~ &amp; ^ | + * Max ops: 10 * Rating: 1 */int isTmax(int x) { return !(x + 1 + x + 1) &amp; !!(~x);} 我们发现最大值两倍加二为0，但是要排除 -1（补码全为1）后面!!(~x) 就是这个逻辑。 x 01111111 11111111 11111111 11111111x + 1 10000000 00000000 00000000 00000000x + 1 + x 11111111 11111111 11111111 11111111x + 1 + x + 1 00000000 00000000 00000000 00000000 allOddBits/* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 2 */int allOddBits(int x) { int e = 0xAA | (0xAA &lt;&lt; 8); e = e | (e &lt;&lt; 16); return !((e &amp; x) ^ e);} 先获取全为奇数位的数，这里的奇数指的是位的阶级是 2 的几次幂。然后取并如果偶数为有值得化，那个异或之后就不会为0。 // 10101010 10101010 10101010 10101010int a = 0xAA; // 00000000 00000000 00000000 10101010int b = 0xAA &lt;&lt; 8; // 00000000 00000000 10101010 00000000int c = a | b; // 00000000 00000000 10101010 10101010int d = c &lt;&lt; 16; // 10101010 10101010 00000000 00000000int e = c | d; // 10101010 10101010 10101010 10101010 negate/* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 5 * Rating: 2 */int negate(int x) { return ~x + 1;} 可以发发现取反之后两个之和为-1，x + ~x = -1，那么-x = ~x + 1然后只需要取反加1就行， -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 0111 1001 0101 0100 0011 0010 0001 0000 1111 1110 1101 1100 1011 1010 1001 1000 7 6 5 4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 isAsciiDigit/* * isAsciiDigit - return 1 if 0x30 &lt;= x &lt;= 0x39 (ASCII codes for characters '0' to '9') * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 15 * Rating: 3 */int isAsciiDigit(int x) { int min = 0x1 &lt;&lt; 31; int max = ~min; int start = ~0x39; int end = max - 0x30 + 1; int c = (x + start) &gt;&gt; 31; int d = (x + end) &gt;&gt; 31; // printf(&quot;x=%d, c=%d, d=%d\\n&quot;,x, c, d); return !!(c &amp; d);} 比如保证 a + start &lt; 0 并且 b + start &lt; 0，然后 a + end &lt; 0 并且 b + end &lt; 0，这个时候是溢出小于零。根据如果 x 为负数x &gt;&gt; 31 = -1，否者 x &gt;&gt; 31 = 0，再通过两次去反获得。 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 a &lt;= x &lt;= b 1 &lt;= x &lt;= 3 2&lt;= x &lt;= 5 start end -4 7 -6 6 -y = ~y + 1start + b = -1 =&gt; start = -1 - b = ~ba + end = max + 1 =&gt; end = max + 1 - a = max - a + 1 conditional/* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 16 * Rating: 3 */int conditional(int x, int y, int z) { int mask = ~!x + 1; return (y &amp; ~mask) | (z &amp; mask);} 这是一个if-else 语句，我们可以转化为 (y op expr) | (z op expr)，其中 op 为操作符，expr 为表达式。 (y op expr) | (z op expr)x == 0 mask = 0xFFFFFFFx != 0 mask = 0xOOOOOOO isLessOrEqual/* * isLessOrEqual - if x &lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 24 * Rating: 3 */int isLessOrEqual(int x, int y) { int x_sign = (x &gt;&gt; 31) &amp; 0x01; // x 的符号 int y_sign = (y &gt;&gt; 31) &amp; 0x01; // y 的符号 int a = !(x ^ y); int b = (x_sign &amp; (!y_sign)); // 判断是否 x &lt; 0 y &gt; 0 int c = (!((x_sign ^ y_sign) &amp; 0x01)); // 判断符号是否相等 // x - y = x + ~y + 1 int res_sign = ((x + ~y + 1) &gt;&gt; 31) &amp; 0x01;// 判断x-y的符号 return a | b | (c &amp; res_sign);} 用 x - y 通过符号来判断，但是可能会溢出，所以当符号不相同就可以直接判断大小。 x y x - y x &gt; 0 y &gt; 0 正常 x &gt; 0 y &lt; 0 可能向上溢出 x &lt; 0 y &gt; 0 可能向下溢出 x &lt; 0 y &lt; 0 正常 主要分为3部， 看看是否两个数相等 !(x ^ y) 如果相等为1 判断符号是否相反，主要看 x &lt; 0，y &gt; 0 判断符号相等的时候，x - y &lt; 0 logicalNeg/* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 4 */int logicalNeg(int x) { int neg_x = ~x + 1; return ((neg_x | x) &gt;&gt; 31) + 1;} 求 x | -x ，如果 x 不为 0 的化，那么符号位一定为 1，如果 x 为 0 那么符号为0。 howManyBits/* howManyBits - return the minimum number of bits required to represent x in * two's complement * Examples: howManyBits(12) = 5 // 0_1100 * howManyBits(298) = 10 // 0_100101010 * howManyBits(-5) = 4 // 1_101 * howManyBits(0) = 1 // 0 * howManyBits(-1) = 1 // 1 * howManyBits(1) = 2 // 0_1 * howManyBits(0x80000000) = 32 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 90 * Rating: 4 */int howManyBits(int x) { int b16, b8, b4, b2, b1, b0; int mask = x &gt;&gt; 31; // 如果x为正数，保持不变；如果为负数，按位取反 x = (mask &amp; ~x) | (~mask &amp; x); // 如果高16位有1，b16 = 16，否者为0 b16 = !!(x &gt;&gt; 16) &lt;&lt; 4; // 如果高16位有1，x右移16位，在新的16为重继续找 x = x &gt;&gt; b16; // 高8 b8 = !!(x &gt;&gt; 8) &lt;&lt; 3; x = x &gt;&gt; b8; // 高4位 b4 = !!(x &gt;&gt; 4) &lt;&lt; 2; x = x &gt;&gt; b4; // 高2位 b2 = !!(x &gt;&gt; 2) &lt;&lt; 1; x = x &gt;&gt; b2; // 高1位 b1 = !!(x &gt;&gt; 1); x = x &gt;&gt; b1; // 底1位 b0 = x; return b16 + b8 + b4 + b2 + b1 + b0 + 1;} 对于正数，找到最左边的 1，对于负数，按位取反处理。 0 1 1 1 0 0 0 1 b4 = 40 1 1 1 b2 = 20 1 b1 = 0 1 b0 = 1 floatScale2/* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int's, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */unsigned floatScale2(unsigned uf) { return 2;}","link":"/2020/10/11/CSAPP%20Data%20Lab/"},{"title":"Let&#39;s build a Full-Text Search engine","text":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。 Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search. Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text. Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word cat“ and we’ll extend the engine to support more sophisticated boolean queries. Note Most well-known FTS engine is Lucene (as well as Elasticsearch and Solr built on top of it). Why FTSBefore we start writing code, you may ask “can’t we just use grep or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea. CorpusWe are going to search a part of the abstract of English Wikipedia. The latest dump is available at dumps.wikimedia.org. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents. Document example: &lt;title&gt;Wikipedia: Kit-Cat Klock&lt;/title&gt;&lt;url&gt;https://en.wikipedia.org/wiki/Kit-Cat_Klock&lt;/url&gt;&lt;abstract&gt;The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.&lt;/abstract&gt; Loading documentsFirst, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy: import ( &quot;encoding/xml&quot; &quot;os&quot;)type document struct { Title string `xml:&quot;title&quot;` URL string `xml:&quot;url&quot;` Text string `xml:&quot;abstract&quot;` ID int}func loadDocuments(path string) ([]document, error) { f, err := os.Open(path) if err != nil { return nil, err } defer f.Close() dec := xml.NewDecoder(f) dump := struct { Documents []document `xml:&quot;doc&quot;` }{} if err := dec.Decode(&amp;dump); err != nil { return nil, err } docs := dump.Documents for i := range docs { docs[i].ID = i } return docs, nil} Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on. First attemptSearching the contentNow that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring cat: func search(docs []document, term string) []document { var r []document for _, doc := range docs { if strings.Contains(doc.Text, term) { r = append(r, doc) } } return r} On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches caterpillar and category, but doesn’t match Cat with the capital C. That’s not quite what I was looking for. We need to fix two things before moving forward: Make the search case-insensitive (so Cat matches as well). Match on a word boundary rather than on a substring (so caterpillar and communication don’t match). Searching with regular expressionsOne solution that quickly comes to mind and allows implementing both requirements is regular expressions. Here it is - (?i)\\bcat\\b: (?i) makes the regex case-insensitive \\b matches a word boundary (position where one side is a word character and another side is not a word character) func search(docs []document, term string) []document { re := regexp.MustCompile(`(?i)\\b` + term + `\\b`) // Don't do this in production, it's a security risk. term needs to be sanitized. var r []document for _, doc := range docs { if re.MatchString(doc.Text) { r = append(r, doc) } } return r} Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that. Inverted IndexTo make search queries faster, we’ll preprocess the text and build an index in advance. The core of FTS is a data structure called Inverted Index. The Inverted Index associates every word in documents with documents that contain the word. Example: documents = { 1: &quot;a donut on a glass plate&quot;, 2: &quot;only the donut&quot;, 3: &quot;listen to the drum machine&quot;,}index = { &quot;a&quot;: [1], &quot;donut&quot;: [1, 2], &quot;on&quot;: [1], &quot;glass&quot;: [1], &quot;plate&quot;: [1], &quot;only&quot;: [2], &quot;the&quot;: [2, 3], &quot;listen&quot;: [3], &quot;to&quot;: [3], &quot;drum&quot;: [3], &quot;machine&quot;: [3],} Below is a real-world example of the Inverted Index. An index in a book where a term references a page number: Text analysisBefore we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching. The text analyzer consists of a tokenizer and multiple filters. TokenizerThe tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks: func tokenize(text string) []string { return strings.FieldsFunc(text, func(r rune) bool { // Split on any character that is not a letter or a number. return !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r) })} &gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;] FiltersIn most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization. LowercaseIn order to make the search case-insensitive, the lowercase filter converts tokens to lower case. cAt, Cat and caT are normalized to cat. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term cAt match the text Cat. func lowercaseFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = strings.ToLower(token) } return r} &gt; lowercaseFilter([]string{&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;] Dropping common wordsAlmost any English text contains commonly used words like a, I, the or be. Such words are called stop words. We are going to remove them since almost any document would match the stop words. There is no “official” list of stop words. Let’s exclude the top 10 by the OEC rank. Feel free to add more: var stopwords = map[string]struct{}{ // I wish Go had built-in sets. &quot;a&quot;: {}, &quot;and&quot;: {}, &quot;be&quot;: {}, &quot;have&quot;: {}, &quot;i&quot;: {}, &quot;in&quot;: {}, &quot;of&quot;: {}, &quot;that&quot;: {}, &quot;the&quot;: {}, &quot;to&quot;: {},}func stopwordFilter(tokens []string) []string { r := make([]string, 0, len(tokens)) for _, token := range tokens { if _, ok := stopwords[token]; !ok { r = append(r, token) } } return r} &gt; stopwordFilter([]string{&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;] StemmingBecause of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, fishing, fished and fisher may be reduced to the base form (stem) fish. Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the existing modules: import snowballeng &quot;github.com/kljensen/snowball/english&quot;func stemmerFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = snowballeng.Stem(token, false) } return r} &gt; stemmerFilter([]string{&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] Note A stem is not always a valid word. For example, some stemmers may reduce airline to airlin. Putting the analyzer togetherfunc analyze(text string) []string { tokens := tokenize(text) tokens = lowercaseFilter(tokens) tokens = stopwordFilter(tokens) tokens = stemmerFilter(tokens) return tokens} The tokenizer and filters convert sentences into a list of tokens: &gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] The tokens are ready for indexing. Building the indexBack to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs: type index map[string][]int Building the index consists of analyzing the documents and adding their IDs to the map: func (idx index) add(docs []document) { for _, doc := range docs { for _, token := range analyze(doc.Text) { ids := idx[token] if ids != nil &amp;&amp; ids[len(ids)-1] == doc.ID { // Don't add same ID twice. continue } idx[token] = append(ids, doc.ID) } }}func main() { idx := make(index) idx.add([]document{{ID: 1, Text: &quot;A donut on a glass plate. Only the donuts.&quot;}}) idx.add([]document{{ID: 2, Text: &quot;donut is a donut&quot;}}) fmt.Println(idx)} It works! Each token in the map refers to IDs of the documents that contain the token: map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]] QueryingTo query the index, we are going to apply the same tokenizer and filters we used for indexing: func (idx index) search(text string) [][]int { var r [][]int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { r = append(r, ids) } } return r} &gt; idx.search(&quot;Small wild cat&quot;)[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]] And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)! With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups. Boolean queriesThe query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type small wild cat in a search box is a list of results that contain small, wild and cat at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens. Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both: func intersection(a []int, b []int) []int { maxLen := len(a) if len(b) &gt; maxLen { maxLen = len(b) } r := make([]int, 0, maxLen) var i, j int for i &lt; len(a) &amp;&amp; j &lt; len(b) { if a[i] &lt; b[j] { i++ } else if a[i] &gt; b[j] { j++ } else { r = append(r, a[i]) i++ j++ } } return r} Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs: func (idx index) search(text string) []int { var r []int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { if r == nil { r = ids } else { r = intersection(r, ids) } } else { // Token doesn't exist. return nil } } return r} The Wikipedia dump contains only two documents that match small, wild and cat at the same time: &gt; idx.search(&quot;Small wild cat&quot;)130764 The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).131692 Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat. The search is working as expected! By the way, this is the first time I hear about catopuma, here is one of them: ConclusionsWe just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects. I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements: Extend boolean queries to support OR and NOT. Store the index on disk: Rebuilding the index on every application restart may take a while. Large indexes may not fit in memory. Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at Roaring Bitmaps. Support indexing multiple document fields. Sort results by relevance. The full source code is available on GitHub. I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!","link":"/2020/08/17/Let's%20build%20a%20Full-Text%20Search%20engine/"},{"title":"Shell入门","text":"Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell Shell编程之Hello World编写一个hello world shell一般使用.sh作为后缀 #!/bin/bash # 使用/bin/sh来解释执行 # auto echo hello world! # 解释这个脚本是干什么的# by authors cuzz # 作者和时间一些信息echo &quot;hello world!&quot; 给脚本添加执行权限 &gt; chmod +x hello.sh Shell编程之变量Shell变量可以分为两类：局部变量和环境变量 #!/bin/bash# define path variables# by authors cuzzname=cuzz # 等号两边不能有空格echo &quot;my name is $name&quot; # 使用$引用 基本变量 echo $PWD # 当前路径echo $0 # 脚本名echo $1 # 第一个参数echo $2 # 第二个参数echo $? # 判断上一个命令是否正确echo $* # 所有参数echo $# # 参数的个数 Shell编程之if条件语句比较大小 #!/bin/bash# if test# by authors cuzznum=100# 计算使用两个小括号if (($num &gt; 10)); then echo &quot;this num greater than 10.&quot;else echo &quot;this num littler than 10.&quot;fi 逻辑运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 目录 操作符 说明 举例 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 创建文件 #!/bin/bash# if test# by authors cuzzDIR=cuzzif [ ! -d $DIR ]; then # 都有空格 mkdir $DIR echo &quot;this $DIR create success.&quot;else echo &quot;this dir is exit.&quot;fi 测试文件是否存在 #!/bin/bash# if test# by authors cuzzfile=test.txtif [ ! -e $file ]; then echo &quot;OK&quot; &gt;&gt; $file # &gt;&gt;是追加内容 &gt;是覆盖内容else cat $filefi mysql备份 #!/bin/bash# auto backup mysql db# by authors cuzz# define backup pathBAK_DIR=/data/backup/`date +%Y%m%d` # 反引号可以把里面当作命令来解析 # mysqlMYSQLDB=testMYSQLUSER=rootMYSQLPW=123456MYSQLCMD=/usr/bin/mysqldump # 备份命令# 判断是否是rootif [ $UID -ne 0 ]; then echo &quot;Only root can execute Shell.&quot; exitfiif [ ! -d $BAK_DIR ]; then mkdir -p $BAK_DIR # -p 父目录不存在就创建 echo &quot;The $BAK_DIR create success.&quot;else echo &quot;This $BAK_DIR is exist.&quot;fi# mysql backup command$MYSQLCMD -u$MYSQLUSER -p$MYSQLPW -d $MYSQLDB &gt;$BAK_DIR/$MYSQLDB.sqlif [ $? -eq 0 ]; then echo &quot;backup success.&quot;else echo &quot;backup fail.&quot;fi Shell编程之for循环基本语句 #!/bin/bashfor i in `seq 1 15`do echo &quot;the number is $i.&quot;done 求和 #!/bin/bashsum=0for ((i=1; i&lt;=100; i++)) # 双括号用于运算相当与其他语言的单括号do sum=`expr $sum + $i` # expr用于计算doneecho &quot;$sum&quot; 打包，只能打包到最后一个，后面的会把前面的覆盖了 #!/bin/bashfor file in `find ./ -name &quot;*.sh&quot;`do tar -czf all.tgz $filedone Shell编程之while循环使用 #!/bin/bashi=0while [[ $i -lt 10 ]] # (( $i &lt; 10))是一样的do echo &quot;$i&quot; ((i++))done 结合read使用 #!/bin/bashwhile read line # 把读取的东西赋值给linedo echo $linedone &lt;/etc/hosts # 从哪里读取 Shell编程之数组Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： my_array=(A B &quot;C&quot; D) # 定义数组array_name[0]=value0 # 使用下标来定义array_name[1]=value1array_name[2]=value2${array_name[0]} # 读取第一个元素${my_array[*]} # 读取所有元素 ${my_array[@]} # 读取所有元素${#my_array[*]} # 读取数组长度${#my_array[@]} # 读取数组长度 Shell编程之函数无返回值得函数 sayHello(){ # 定义函数一 echo &quot;hello&quot;}function sayHelloWorld(){ # 定义函数二 echo &quot;hello world&quot;}sayhell # 使用函数 有返回值得，使用return只能返回0-255 function sum(){ returnValue=$(( $1 + $2 )) return $returnValue}sum 22 4echo $? 可以使用echo来传递参数 function length(){ str=$1 result=0 if [ &quot;$str&quot; != &quot;&quot; ] ; then result=${#str} fi echo &quot;$result&quot;}len=$(length &quot;abc123&quot;) # 调用echo &quot;The string's length is $len &quot; Shell编程之sed命令把test.txt中的old修改为new，要使用-i才能插入 &gt; sed -i 's/old/new/s' test.txt 在每行行前面添加一个cuzz &gt; sed -i sed 's/^/&amp;cuzz/g' test.txt 在每行的末尾添加一个cuzz &gt; sed -i 's/$/&amp; cuzz/g' test.txt 匹配某一行，在下方插入一行，找到cuzz这行在下方插入#### &gt; sed '/cuzz/a #######' test.txt 在之前添加一行，只要把a改成i &gt; sed '/cuzz/i #######' test.txt 打印 &gt; sed -n '/cuzz/p' test.txt # 打印含有cuzz这一行&gt; sed -n '1p' test.txt # 打印第一行&gt; sed -n '1,5p' text.txt # 打印1到5行 查找最大和最小值 number.txt 12 324 56 0034 -23 345345 349- 245 345 345 0989 0459 -25 命令 cat number.txt | sed 's/ /\\n/g' | grep -v &quot;^$&quot; | sort -nr | sed -n '1p;$p'sed 's/ /\\n/g' # 把所有空格换成换行grep -v &quot;^$&quot; # 去掉所有空格sort -nr # 降序排列sed -n '1p;$p # 找出第1行和最后一行 Shell编程之grep命令 -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’ 的次数 -i ：忽略大小写的不同，所以大小写视为相同 -n ：顺便输出行号 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行 –color=auto ：可以将找到的关键词部分加上颜色的显示 egrep 和grep -E 相同，可以使用正则表达式 Shell编程之awk命令# 每行按空格或TAB分割cat test.txt | awk '{print $1}' # 行匹配语句 awk '' 只能用单引号# 指定分割awk -F #-F相当于内置变量FS, 指定分割字符cat test.txt | awk -F: '{print $1}' # 以分号分割# 指定添加某些内容cat test.txt | awk -F: '{print &quot;haha&quot; $1}' # 提前出来再添加haha Shell编程之find命令基本命令 find /dir -name &quot;test.txt&quot; # 在/dir目录下查找find . -name &quot;test.txt&quot; # 在当前目录下找 find . -maxdepth 1 -name &quot;text.txt&quot; # 只遍历一层find . -type f -name &quot;text&quot; # 指定类型find . -name &quot;text&quot; -mtime -1 # 指定时间find . -size +20M # 指定大小 查找并执行其他命令 find . -name &quot;text.txt&quot; -exec rm -rf {} \\; # 后面{} \\是固定格式","link":"/2018/10/04/Shell%E5%85%A5%E9%97%A8/"},{"title":"Spring 的复杂类型注入","text":"Spring 的类型注入先定义一个接口： public interface Animal {} 对应的有一些实现类： @Componentpublic class Dog implements Animal {}@Component(&quot;myCat&quot;)public class Cat implements Animal {} 我们用 Spring 比较常见的用类型注入和名称注入： @Resourceprivate Dog dog; // 按类型注入@Resource(&quot;myCat&quot;)private Cat myCat; // 按名称注入 然后今天在公司看到同事使用观察者模式的时候，使用了另外一种注入方式，注入的是List&lt;XXX&gt;： @Resourceprivate List&lt;Animal&gt; animalList; 这个时候注入的时候实现 Animal 这个接口的所有实现类 Spring 按类型自动注入Array、List、Set、MapSpring 按类型不仅仅注入类本身的，而且还可以注入Array、List、Set 和 Map 。 @Resourceprivate Animal[] animalArr;@Resourceprivate List&lt;Animal&gt; animalList;@Resourceprivate Set&lt;Animal&gt; animalSet;@Resourceprivate Map&lt;String, Animal&gt; animalMap; 我们写一个测试类看看： @Autowiredprivate void print() { System.out.println(Arrays.toString(animalArr)); System.out.println(animalList); System.out.println(animalSet); System.out.println(animalMap);} 发现输出： [com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f][com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f][com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f]{myCat=com.cuzz.spring.impl.Cat@58cd06cb, dog=com.cuzz.spring.impl.Dog@3be8821f} 当为数组和集合的时候会把所有接口的实现类放入其中，当为 Map 时，key 对应的是 Bean 的名称，value 对应Bean。 源码分析先定位到这个方法org.springframework.beans.factory.support.DefaultListableBeanFactory#resolveDependency resolveDependency 方法中定位到根据类型查找依赖 doResolveDependency。 @Override@Nullablepublic Object resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { // ... Object result = getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary( descriptor, requestingBeanName); if (result == null) { result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter); } return result; }} doResolveDependency 封装了依赖查找的各种情况，我们主要看 resolveMultipleBeans 方法。 @Nullablepublic Object doResolveDependency(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor); try { // ... // 集合依赖，如 Array、List、Set、Map。 Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter); if (multipleBeans != null) { return multipleBeans; } // ... }} 最终调用resolveMultipleBeans方法 private Object resolveMultipleBeans(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) { Class&lt;?&gt; type = descriptor.getDependencyType(); // Stream 类型 if (descriptor instanceof StreamDependencyDescriptor) { Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, type, descriptor); if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } Stream&lt;Object&gt; stream = matchingBeans.keySet().stream() .map(name -&gt; descriptor.resolveCandidate(name, type, this)) .filter(bean -&gt; !(bean instanceof NullBean)); if (((StreamDependencyDescriptor) descriptor).isOrdered()) { stream = stream.sorted(adaptOrderComparator(matchingBeans)); } return stream; } // Array else if (type.isArray()) { Class&lt;?&gt; componentType = type.getComponentType(); ResolvableType resolvableType = descriptor.getResolvableType(); Class&lt;?&gt; resolvedArrayType = resolvableType.resolve(type); if (resolvedArrayType != type) { componentType = resolvableType.getComponentType().resolve(); } if (componentType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, componentType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), resolvedArrayType); if (result instanceof Object[]) { Comparator&lt;Object&gt; comparator = adaptDependencyComparator(matchingBeans); if (comparator != null) { Arrays.sort((Object[]) result, comparator); } } return result; } // 集合 else if (Collection.class.isAssignableFrom(type) &amp;&amp; type.isInterface()) { Class&lt;?&gt; elementType = descriptor.getResolvableType().asCollection().resolveGeneric(); if (elementType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, elementType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), type); if (result instanceof List) { if (((List&lt;?&gt;) result).size() &gt; 1) { Comparator&lt;Object&gt; comparator = adaptDependencyComparator(matchingBeans); if (comparator != null) { ((List&lt;?&gt;) result).sort(comparator); } } } return result; } // Map else if (Map.class == type) { ResolvableType mapType = descriptor.getResolvableType().asMap(); Class&lt;?&gt; keyType = mapType.resolveGeneric(0); if (String.class != keyType) { return null; } Class&lt;?&gt; valueType = mapType.resolveGeneric(1); if (valueType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, valueType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } return matchingBeans; } else { return null; }} 从源码发现，不仅仅可以注入数组、集合和Map，还可以注入 Stream。 总结Spring按类型注入不仅仅注入简单的Bean，还可以注入一些数组、集合、Map 以及 Stream。 如果想进一步了解这一块可以看看这篇文章Spring IoC 依赖注入（三）resolveDependency","link":"/2020/09/29/Spring%20%E7%9A%84%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E6%B3%A8%E5%85%A5/"},{"title":"Spring注解驱动开发（三）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 属性赋值@value赋值使用@Value赋值 基本数值 可以写SPEL表达式 #{} 可以${}获取配置文件信息（在运行的环境变量中的值） 使用xml时候导入配置文件是 &lt;context:property-placeholder location=&quot;classpath:person.properties&quot;/&gt; 使用注解可以在配置类添加一个@PropertySource注解把配置文件中k/v保存到运行的环境中 使用${key}来获取 /** * @Author: cuzz * @Date: 2018/9/24 18:43 * @Description: */@PropertySource(value = {&quot;classpath:/person.properties&quot;})@Configurationpublic class MainConfigOfPropertyValue { @Bean public Person person() { return new Person(); }} Person 类 @Datapublic class Person { @Value(&quot;vhuj&quot;) private String name; @Value(&quot;#{20-2}&quot;) private Integer age; @Value(&quot;${person.nickName}&quot;) private String nickName;} 测试 @Testpublic void test01() { printBean(applicationContext); System.out.println(&quot;---------------------------&quot;); Person person = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(person); System.out.println(&quot;---------------------------&quot;);} 输出 ---------------------------Person(name=vhuj, age=18, nickName=三三)--------------------------- 自动装配@Autowired@Qualifier@Primary自动转配： Spring利用依赖注入（DI），完成对IOC容器中各个组件的依赖关系赋值 @Autowired自动注入: a. 默认优先按照类型去容器中寻找对应的组件，如果找到去赋值 b. 如果找到到相同类型的组件，再将属性名（BookDao bookdao）作为组件的id去容器中查找 c. 接下来还可以使用@Qualifier(&quot;bookdao&quot;)明确指定需要装配的id d. 默认是必须的，我们可以指定 @Autowired(required=false)，指定非必须 @Primary让Spring自动装配时首先装配 自动装配@Resource和@InjectSpring还支持使用@Resource (JSR250) 和@Inject (JSR330) 注解，这两个是java规范 @Resource和@Autowired一样实现自动装配功能，默认是按组件名称进行装配的 没有支持@Primary和@Autowird(required=false)的功能 自动装配其他地方的自动装配@Autowired：构造器、参数、方法属性等 标注到方法位子上@Bean+方法参数，参数从容器中获取 /** * @Author: cuzz * @Date: 2018/9/24 20:57 * @Description: */public class Boss { // 属性 @Autowired private Car car; // 构造器 如果构造器只有一个有参构造器可以省略 @Autowired public Boss(@Autowired Car car) { } public Car getCar() { return car; } // set方法 @Autowired // 参数 public void setCar(@Autowired Car car) { this.car = car; }} 自动装配Aware注入Spring底层注解自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory 等等），自定义组件实现xxxAware，在创建对象的时候会调用接口规定的方法注入相关的组件 /** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. */public interface Aware {} 我们实现几个常见的Aware接口 /** * @Author: cuzz * @Date: 2018/9/25 10:18 * @Description: */@Componentpublic class Red implements BeanNameAware ,BeanFactoryAware, ApplicationContextAware { private ApplicationContext applicationContext; @Override public void setBeanName(String name) { System.out.println(&quot;当前Bean的名字: &quot; + name); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;当前的BeanFactory: &quot; + beanFactory); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; System.out.println(&quot;传入的ioc: &quot; + applicationContext); }} 注入到配置中测试 /** * @Author: cuzz * @Date: 2018/9/25 10:28 * @Description: */public class IOCTestAware { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAware.class); }} 测试结果 当前Bean的名字: red当前的BeanFactory: org.springframework.beans.factory.support.DefaultListableBeanFactory@159c4b8: defining beans [org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,mainConfigOfAware,red]; root of factory hierarchy传入的ioc: org.springframework.context.annotation.AnnotationConfigApplicationContext@1e89d68: startup date [Tue Sep 25 10:29:17 CST 2018]; root of context hierarchy 把Spring自定义组件注入到容器中 原理： public interface ApplicationContextAware extends Aware {} 通过 Debug 方式，定位到 org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization @Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { invokeAwareInterfaces(bean); return null; } }, acc); } else { invokeAwareInterfaces(bean); // 调用 } 调用下面方法进行判断，每种 xxxAware 接口中只有一种方法，并调用相应的方法 private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } }} xxxAware都是通过xxxProcessor来处理的 比如：ApplicationContextAware 对应 ApplicationContextAwareProcessor 自动装配@Profile环境搭建Profile是Spring为我们提供可以根据当前环境，动态的激活和切换一系组件的功能 a. 使用命令动态参数激活：虚拟机参数位子加载 -Dspring.profiles.active=test b. 使用代码激活环境 我们想配置类 /** * @Author: cuzz * @Date: 2018/9/25 10:47 * @Description: */@Configurationpublic class MainConfigOfProfile { @Profile(value = &quot;test&quot;) @Bean(value = &quot;testDataSource&quot;) public DataSource testDataSource() { System.out.println(&quot;testDataSource&quot;); return null; } @Profile(value = &quot;dev&quot;) @Bean(value = &quot;devDataSource&quot;) public DataSource devDataSource() { System.out.println(&quot;devDataSource&quot;); return null; }} 测试 /** * @Author: cuzz * @Date: 2018/9/25 10:59 * @Description: */public class IOCTestProfile { @Test public void test01() { // 1. 使用无参构造器创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置要激活的环境 applicationContext.getEnvironment().setActiveProfiles(&quot;test&quot;); // 3. 注册主配置类 applicationContext.register(MainConfigOfProfile.class); // 4. 启动刷新容器 applicationContext.refresh(); }} 输出 testDataSource","link":"/2018/09/25/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Spring注解驱动开发（二）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 声明周期@Bean指定初始化和销毁方法Bean的生命周期Bean的创建、初始化和销毁是由容器帮我们管理的 我们可以自定义初始化和销毁方法，容器在进行到当前生命周期的时候来调用我买自定义的初始化和销毁方法 构造（对象创建） ​ 单实例： 在容器启动的时候创建 ​ 多实例： 在每次获取的时候创建对象 指定初始化方法初始化：对象创建完成后，并赋值化，调用初始化方法 销毁：单实例是在容器关闭的时候销毁，多实例容器不会管理这个Bean，容器不会调用销毁方法 编写一个Car类 /** * @Author: cuzz * @Date: 2018/9/23 21:20 * @Description: */public class Car { public Car () { System.out.println(&quot;car constructor...&quot;); } public void init() { System.out.println(&quot;car...init...&quot;); } public void destroy() { System.out.println(&quot;car...destroy...&quot;); }} 在xml中我们可以指定init-method和destroy-method方法，如 &lt;bean id=&quot;car&quot; class=&quot;com.cuzz.bean.Car&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt; 使用注解我们可以 /** * @Author: cuzz * @Date: 2018/9/24 12:49 * @Description: 配置类 */@Configurationpublic class MainConfigOfLifecycle { @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;) public Car car() { return new Car(); }} 测试 /** * @Author: cuzz * @Date: 2018/9/24 13:00 * @Description: */public class IOCTestLifeCycle { @Test public void test01() { // 创建ioc容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifecycle.class); System.out.println(&quot;容器创建完成...&quot;); // 关闭容器 System.out.println(&quot;---&gt;开始关闭容器&quot;); applicationContext.close(); System.out.println(&quot;---&gt;已经关闭容器&quot;); }} 可以看出先创建car，再调用init方法，在容器关闭时销毁实例 car constructor...car...init...容器创建完成...---&gt;开始关闭容器car...destroy...---&gt;已经关闭容器 在配置数据源的时候，有很多属性赋值，销毁的时候要把连接给断开 生命周期InitializingBean和DisposableBeanInitializingBean可以通过Bean实现InitializingBean来定义初始化逻辑，是设置好所有属性会调用afterPropertiesSet()方法 public interface InitializingBean { /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;} DisposableBean可以通过Bean实现DisposableBean来定义销毁逻辑，会调用destroy()方法 public interface DisposableBean { /** * Invoked by a BeanFactory on destruction of a singleton. * @throws Exception in case of shutdown errors. * Exceptions will get logged but not rethrown to allow * other beans to release their resources too. */ void destroy() throws Exception;} 例子编写一个Cat类 /** * @Author: cuzz * @Date: 2018/9/24 13:36 * @Description: */public class Cat implements InitializingBean, DisposableBean{ public Cat() { System.out.println(&quot;cat constructor...&quot;); } @Override public void afterPropertiesSet() throws Exception { System.out.println(&quot;cat...init...&quot;); } @Override public void destroy() throws Exception { System.out.println(&quot;cat...destroy...&quot;); }} 测试 cat constructor...cat...init...容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 生命周期@PostContruct和@PreDestroy注解@PostContruct在Bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy在容器销毁Bean之前通知我们进行清理工作 编写一个Dog类，并把他注入到配置类中 /** * @Author: cuzz * @Date: 2018/9/24 14:03 * @Description: */public class Dog { public Dog() { System.out.println(&quot;dog constructor...&quot;); } @PostConstruct public void postConstruct() { System.out.println(&quot;post construct...&quot;); } @PreDestroy public void preDestroy() { System.out.println(&quot;pre destroy...&quot;); }} 测试结果 dog constructor...post construct...容器创建完成...---&gt;开始关闭容器pre destroy...---&gt;已经关闭容器 生命周期BeanPostProscessor后置处理器我们先看看源码，解释的很清楚，BeanPostProscessor 中postProcessBeforeInitialization方法会在每一个bean对象的初始化方法调用之前回调；postProcessAfterInitialization方法会在每个bean对象的初始化方法调用之后被回调 。 /** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement {@link #postProcessBeforeInitialization}, * while post-processors that wrap beans with proxies will normally * implement {@link #postProcessAfterInitialization}. */public interface BeanPostProcessor { /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding {@code bean instanceof FactoryBean} checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * {@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation} method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;} 编写一个MyBeanPostProcessor实现BeanPostProcessor接口 /** * @Author: cuzz * @Date: 2018/9/24 14:21 * @Description: 后置处理器，初始化前后进行处理工作 */public class MyBeanPostProcessor implements BeanPostProcessor{ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessBeforeInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessAfterInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; }} 添加到配置中 @Configurationpublic class MainConfigOfLifecycle { @Bean public Cat cat() { return new Cat(); } @Bean public MyBeanPostProcessor myBeanPostProcessor() { return new MyBeanPostProcessor(); }} 测试 ---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765cat constructor...---&gt;postProcessBeforeInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207cat...init...---&gt;postProcessAfterInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 在实例创建之前后创建之后会被执行 生命周期BeanPostProcessor原理通过debug到populateBean，先给属性赋值在执行initializeBean方法 try { populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) { exposedObject = initializeBean(beanName, exposedObject, mbd); }} initializeBean方法时， protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) { Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 执行before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } ... try { // 执行初始化 invokeInitMethods(beanName, wrappedBean, mbd); } if (mbd == null || !mbd.isSynthetic()) { // 执行after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;} Spring底层对BeanPostProcessor的使用： Bean赋值、注入其他组件、@Autowired、生命周期注解功能、@Async等等都使用到了BeanPostProcessor这个接口的实现类，很重要 总结Bean 的初始化顺序 首先执行 bean 的构造方法 BeanPostProcessor 的 postProcessBeforeInitialization 方法 InitializingBean 的 afterPropertiesSet 方法 @Bean 注解的 initMethod方法 BeanPostProcesso r的 postProcessAfterInitialization 方法 DisposableBean 的 destroy 方法 @Bean注解的 destroyMethod 方法","link":"/2018/09/24/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Spring注解驱动开发（四）","text":"AOP面向切面编程AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 底层实现Spring 的 AOP 的底层用到两种代理机制： JDK 的动态代理 ：类必须实现接口，所以是针对实现了接口的类产生代理. Cglib 的动态代理：针对没有实现接口的类产生代理，应用的是底层的字节码增强的技术生成当前类的子类对象 JDK 的动态代理 UserService接口，实现增删改查的功能 package com.cuzz.service;public interface UserService { void add(); void delete(); void update(); void get();} UserService接口的实现的类 public class UserServiceImpl implements UserService { @Override public void add() { System.out.println(&quot;添加一个user&quot;); } @Override public void delete() { System.out.println(&quot;删除一个user&quot;); } @Override public void update() { System.out.println(&quot;更新一个user&quot;); } @Override public void get() { System.out.println(&quot;查询一个user&quot;); }} 实现动态代理 package com.cuzz.service;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class UserServiceProxyFactory implements InvocationHandler{ private UserService us; public UserServiceProxyFactory(UserService us) { super(); this.us = us; } // 获得动态代理 public UserService getUserServiceProxy() { // 生成动态代理 UserService usProxy = (UserService) Proxy.newProxyInstance(UserServiceProxyFactory.class.getClassLoader(), UserServiceImpl.class.getInterfaces(), this); // 这个 this 就是实现 InvocationHandler 的对象 return usProxy; } @Override public Object invoke(Object arg0, Method method, Object[] arg2) throws Throwable { System.out.println(&quot;打开事务!&quot;); Object invoke = method.invoke(us, arg2); System.out.println(&quot;提交事务!&quot;); return invoke; }} 测试 public class TestDemo { @Test public void test01(){ UserService us = new UserServiceImpl(); UserServiceProxyFactory factory = new UserServiceProxyFactory(us); UserService usProxy = factory.getUserServiceProxy(); usProxy.add(); }} 输出 打开事务!添加一个user提交事务! Cglib 的动态代理 Cglib 的动态代理的代码实现 package com.cuzz.service;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class UserServiceProxyFactory2 implements MethodInterceptor { public UserService getUserServiceProxy(){ // 帮我们生成代理对象 Enhancer en = new Enhancer(); // 设置对谁进行代理 en.setSuperclass(UserServiceImpl.class); // 代理要做什么 en.setCallback(this); // 创建代理对象 UserService us = (UserService) en.create(); return us; } @Override public Object intercept(Object prxoyobj, Method method, Object[] arg, MethodProxy methodProxy) throws Throwable { // 打开事务 System.out.println(&quot;打开事务!&quot;); // 调用原有方法 Object returnValue = methodProxy.invokeSuper(prxoyobj, arg); // 提交事务 System.out.println(&quot;提交事务!&quot;); return returnValue; }} 测试 @Testpublic void test02() { UserServiceProxyFactory2 factory = new UserServiceProxyFactory2(); UserService usProxy = factory.getUserServiceProxy(); usProxy.add();} Spring的AOP开发(基于AspectJ)AOP的开发中的相关术语： Joinpoint(连接点)：所谓连接点是指那些被拦截到的点，在 spring 中这些点指的是方法，因为 spring 只支持方法类型的连接点 Pointcut(切入点)：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义 Advice(通知/增强)：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介)：引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target(目标对象)：代理的目标对象 Weaving(织入)：是指把增强应用到目标对象来创建新的代理对象的过程，spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装在期织入 Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类 Aspect(切面)：是切入点和通知（引介）的结合 通知类型 前置通知 ：在目标方法执行之前执行 后置通知 ：在目标方法执行之后执行 环绕通知 ：在目标方法执行前和执行后执行 异常抛出通知：在目标方法执行出现异常的时候执行 最终通知 ：无论目标方法是否出现异常 最终通知都会执行 代码演示通知类，给切面的目标方法标注何时地运行，必须告诉 Spring 哪个类是切面类，添加注解 @Aspect @Aspect // 表示该类是一个通知类public class MyAdvice { // 前置通知 @Before(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void before(){ System.out.println(&quot;这是前置通知!!&quot;); } // 后置通知 @AfterReturning(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterReturning(){ System.out.println(&quot;这是后置通知(如果出现异常不会调用)!!&quot;); } // 环绕通知 @Around(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(&quot;这是环绕通知之前的部分!!&quot;); // 调用目标方法 Object proceed = pjp.proceed(); System.out.println(&quot;这是环绕通知之后的部分!!&quot;); return proceed; } // 异常通知 @AfterThrowing(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterException(){ System.out.println(&quot;出事啦!出现异常了!!&quot;); } // 后置通知 @After(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void after(){ System.out.println(&quot;这是后置通知(出现异常也会调用)!!&quot;); }} 配置类，将切面类和业务逻辑类都加入到容器中，给配置类加 @EnableAspectJAutoProxy 注解 /** * @Author: cuzz * @Date: 2019/2/10 20:43 * @Description: */@Configuration@EnableAspectJAutoProxypublic class MainConfigOfAOP { @Bean public UserService userService() { return new UserServiceImpl(); } @Bean public MyAdvice myAdvice() { return new MyAdvice(); }} 测试 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); UserService userService = (UserService) applicationContext.getBean(&quot;userService&quot;); userService.add(); userService.delete(); userService.update(); userService.get();} 如果报错添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt;","link":"/2019/02/10/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Understanding Object Oriented Programming","text":"这是一篇很早的文章，讲的关于面向对象，原文地址：Understanding Object Oriented Programming。这里有关于这篇文章的评论如此理解面向对象编程，很有有趣。我觉得这篇作为一篇入门讲面向对象的例子还是很不错的，通过不同的例子讲述了不同人的实现想法。最后用策略模式+工厂模式来实现，来达到消除if-else。 The code on this page grew out of a discussion on the Object Technology in Computer Science Education list server. The discussion had been going on for about 36 hours in late March and early April 2000 centered on the question of “What is OO really; is it a real paradigm, different from procedural programming or is it just a packaging mechanism for procedural programming?” Both of the authors believe that it is a real paradigm shift, requiring a change in mental model in the practitioners. Winder produced the first three of the following code fragments to show the difference in styles between hackers, procedural programmers, and (naive) object oriented programmers. Bergin then added the more sophisticated OO version that appears last. TheProblemThe problem to be solved is to output a value judgment about operating systems. The assumptions being (of course) that UNIX is good and Windows is bad. Hacker Solutionpublic class PrintOS { public static void main(final String[] args) { String osName = System.getProperty(&quot;os.name&quot;); if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { System.out.println(&quot;This is a UNIX box and therefore good.&quot;); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { System.out.println(&quot;This is a Windows box and therefore bad.&quot;); } else { System.out.println(&quot;This is not a box.&quot;); } }} Their claim: It works doesn’t it what more do you want? Also I got mine implemented and working faster than any of the others, so there. Evaluation: While this solves the problem, it would not be easy to modify in the future if the problem changes. In particular, if we need to add new operating systems, we need to extend the if structure. If we want to add additional functionality for each operating system, we would likely see this expand to nested if statements. This would get unwieldy over time. Thus, the hacker has solved the immediate problem, but made little progress on future evolution of the program. Procedural Solutionpublic class PrintOS { private static String unixBox() { return &quot;This is a UNIX box and therefore good.&quot;; } private static String windowsBox() { return &quot;This is a Windows box and therefore bad.&quot;; } private static String defaultBox() { return &quot;This is not a box.&quot;; } private static String getTheString(final String osName) { if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { return unixBox(); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { return windowsBox(); } else { return defaultBox(); } } public static void main(final String[] args) { System.out.println(getTheString(System.getProperty(&quot;os.name&quot;))); }} Their claim: Java is a wonderful procedural programming language; it naturally supports top-down decomposition which is clearly the only way of analyzing and designing quality solutions to problems – as exemplified by this example. Evaluation: The procedural programmer has made some progress on the larger problem. If an operating system needs to be added, we extend the if statement in the getTheString function and add a new function for that OS. However, if the functionality of each OS needs to be extended, what we are likely to see is that the if statement will most likely be replicated elsewhere in the program each time we need to make the distinction between operating systems. Once that happens, whenever we add a new OS or change or add functionality we will need to find ALL of these if statements and update them compatibly*. This is very error prone and results in entropy setting into such programs over time. In effect the programmer is using ad-hoc polymorphism. We want different things to happen, but the programmer must specifically make the choice of what is to happen in each instance. Naive Object Oriented SolutionThis solution requires several classes in several files. // PrintOS.javapublic class PrintOS { public static void main(final String[] args) { System.out.println(OSDiscriminator.getBoxSpecifier().getStatement()); }}// ---------------// OSDiscriminator.javapublic class OSDiscriminator { // Factory Pattern private static BoxSpecifier theBoxSpecifier = null; public static BoxSpecifier getBoxSpecifier() { if (theBoxSpecifier == null) { String osName = System.getProperty(&quot;os.name&quot;); if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { theBoxSpecifier = new UNIXBox(); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { theBoxSpecifier = new WindowsBox(); } else { theBoxSpecifier = new DefaultBox(); } } return theBoxSpecifier; }}// ---------------// BoxSpecifier.javapublic interface BoxSpecifier { String getStatement();}// ---------------// DefaultBox.javapublic class DefaultBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is not a box.&quot;; }}// ---------------// UNIXBox.javapublic class UNIXBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is a UNIX box and therefore good.&quot;; }}// ---------------// WindowsBox.javapublic class WindowsBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is a Windows box and therefore bad.&quot;; }} Their claim: Well I managed to get both Singleton and Factory Method into the implementation so according to all the hype about object-oriented programming and patterns it must be good. Note: The factory here is a kind of naive singleton. Evaluation This programmer has made quite a lot more progress toward the goal of writing a maintainable program. In particular, if we need to add an OS, we extend the if statement as before, and write a new class for that OS. This is similar to what the procedural programmer had to do. However, if we need to add functionality for each OS, we only need to change the classes that deal with that OS. The if statement in OSDiscriminator is still a “logic bottleneck” but it is the only one in the program. This means that the location of change is easy to find (the classes that implement the functionality). Also, if we add functionality by changing the interface BoxSpecifier, then the compiler will tell us if some class fails to implement the new required functionality. We won’t have to search the program for the locus of each change with no help from the tools. However, this solution still does ad-hoc polymorphism in the if statement. Object oriented programming attempts to remove all such ad-hoc decision making. Every if and every switch should be viewed as a lost opportunity for dynamic polymorphism. If we can replace this with dynamic polymorphism then the program will be much easier to maintain. Sophisticated Object Oriented + Patterns SolutionIn the following, PrintOS.java and BoxSpecifier.java are unchanged from the above. // PrintOS.javapublic class PrintOS { public static void main(final String[] args) { System.out.println(OSDiscriminator.getBoxSpecifier().getStatement()); }}// ----------// OSDiscriminator.javapublic class OSDiscriminator {// Factory Pattern private static java.util.HashMap storage = new java.util.HashMap(); public static BoxSpecifier getBoxSpecifier() { BoxSpecifier value = (BoxSpecifier) storage.get(System.getProperty(&quot;os.name&quot;)); if (value == null) return DefaultBox.value; return value; } public static void register(final String key, final BoxSpecifier value) { storage.put(key, value); // Should guard against null keys, actually. } static { WindowsBox.register(); UNIXBox.register(); MacBox.register(); }}// ----------// BoxSpecifier.javapublic interface BoxSpecifier { String getStatement();}// ----------// DefaultBox.javapublic class DefaultBox implements BoxSpecifier {// Singleton Pattern public static final DefaultBox value = new DefaultBox(); private DefaultBox() { } @Override public String getStatement() { return &quot;This is not a box.&quot;; }}// ----------// UNIXBox.javapublic class UNIXBox implements BoxSpecifier {// Singleton Pattern public static final UNIXBox value = new UNIXBox(); private UNIXBox() { } @Override public String getStatement() { return &quot;This is a UNIX box and therefore good.&quot;; } public static final void register() { OSDiscriminator.register(&quot;SunOS&quot;, value); OSDiscriminator.register(&quot;Linux&quot;, value); }}// ----------// WindowsBox.javapublic class WindowsBox implements BoxSpecifier {// Singleton Pattern public static final WindowsBox value = new WindowsBox(); private WindowsBox() { } @Override public String getStatement() { return &quot;This is a Windows box and therefore bad.&quot;; } public static final void register() { OSDiscriminator.register(&quot;Windows NT&quot;, value); OSDiscriminator.register(&quot;Windows 95&quot;, value); }}// ----------// MacBox.javapublic class MacBox implements BoxSpecifier { // Singleton Pattern public static final MacBox value = new MacBox(); private MacBox() { } @Override public String getStatement() { return &quot;This is a Macintosh box and therefore far superior.&quot;; } public static final void register() { OSDiscriminator.register(&quot;Mac OS&quot;, value); }} Their claim: Aaaaahhhhh. And besides, I added important functionality – Mac OS. Evaluation Here we have turned the OS objects into singletons, so there can be only one such object in each of these classes. This may be desirable or not. If it is not, then the factory wouldn’t return the objects in the hash table, but would return clones of them instead. Here we have maintainable code. To add a new OS, like the Mac OS, we just add a new class and add its registration to the factory. To change the functionality we change the OS classes. To add new functionality, we either modify the OS classes, or extend them. Note that there is NO ad-hoc polymorphism here except the single test for null in the factory. DeconstructionWhether it is clear or not, the mental processes of the programmers who wrote these different versions was quite different. The hacker wanted to get the immediate job done at all cost. The procedural programmer views the nature of computation as a decomposition of a function into sub-functions (helper functions) that solve sub-problems. The object-oriented programmers see the nature of computation as a swarm of interacting agents that provide services for other objects. Further, the sophisticated OO programmer lets the system take care of all polymorphic tasks possible. This programmer sees the essence of object oriented programming as the naive object-oriented programmer may not. NotesSingleton and Factory are discussed in Design Patterns by Gamma, Helm, Johnson, and Vlissides (Addison-Wesley, 1995). This is the now famous “Gang of Four” or GOF book. The DefaultBox is a kind of Null Object. This pattern is by Bobby Wolfe and can be found in Pattern Languages of Program Design 3, edited by Martin, Riehle, and Buschmann (Addison-Wesley, 1998) While object oriented programmers try to avoid ad-hoc polymorphism it isn’t always possible. The hard-to-impossible cases are when dealing with primitive (non-object) data in hybrid languages like Java, parsing input, and when creating new objects. Here, however, we have solved the creational problem with a simple factory containing singletons. The creational problem can be solved in general through the use of reflection, such as the Java Reflection API. The other situations are less tractable. For more on ad-hoc polymorphism, see Bergin’s Selection Patterns.For more on dynamic polymorphism, see Bergin’s Polymorphism Patterns.For more on how the object oriented programmer thinks, see Bergin’s Object Patterns. MoreHere is another perspective on the same ideas from out friend and colleague Dung X. Nguyen of Rice University. By the way, Dung has done a lot with using patterns to enhance object-oriented code seen by students. He often works with Stephen Wong of Oberlin College. They have some nice papers on this in the last few SIGCSE conference proceedings. Note: For a discussion on why replicated code, such as that in the if structure of the procedural solution, is bad see Kent Beck’s discussion on OnceAndOnlyOnce on the Wiki Wiki Web. Last Updated: July 30, 2000","link":"/2020/08/25/Understanding%20Object%20Oriented%20Programming/"},{"title":"关于null的思考","text":"写代码的时候有个地方需要把 Integer 类型强转为 String Integer firstEventType = eventTask.getEventType1();String firstEventTypeName = eventTypeService.queryDescByCode(String.valueOf(firstEventType)); 当我点开 String#valueof 这个静态方式时 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();} 当我们没有获取到 firstEventType 这个值时，为 null，此时它返回给我们的是字符串 “null” ，有时候就不符合我们的业务场景，最好是提前做空值判断。 看下面一个例子 Integer i = null;System.out.println(String.valueOf(i)); // 输出 nullSystem.out.println(String.valueOf(null)); // 空指针 感觉很奇怪，竟然输出结果不一样。 看看这两个重载方法 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();}public static String valueOf(char data[]) { return new String(data);} 凭直觉来看以为String.valueOf(null) 会选择第一做为 valueOf(Object obj) 这个从载方法，然而选择的是valueOf(char data[]) 所以会报空指针异常。 下面是查到官方文档 https://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.12.2.5 如果第一个方法处理的任何调用都可以传递给另一个没有编译时类型错误的调用，那么一个方法比另一个方法更具体。 从意思来看 valueOf(char data[]) 比 valueOf(Object obj) 更具体。 我们非常痛恨的 null 到底是什么 Java 语言定义 There is also a special null type, the type of the expression null, which has no name. Because the null type has no name, it is impossible to declare a variable of the null type or to cast to the null type. The null reference is the only possible value of an expression of null type. The null reference can always be cast to any reference type. In practice, the programmer can ignore the null type and just pretend that null is merely a special literal that can be of any reference type.","link":"/2019/06/03/%E5%85%B3%E4%BA%8Enull%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"分布式事务框架Seata","text":"分布式基础CAP 定理CAP 定理指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得。在分布式系统中，分区容错性是必须需要实现的。所以只能在一致性和可用性之间进行权衡（AP 或者 CP）。 BASE 理论BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的缩写。是对 CAP 中 AP 的一个扩展 BA 基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 S 软状态：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。 E 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。 BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 分布式事务实现方式 XA 方案(两阶段提交) TCC 方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 Seata简介Seata (Simple Extensible Autonomous Transaction Architecture) 是阿里巴巴开源的分布式事务中间件，，解决微服务场景下面临的分布式事务问题。 具体看 Seata 官网： Seata主要由三个重要组件组成： Transaction Coordinator(TC)：管理全局的分支事务的状态，用于全局性事务的提交和回滚。 Transaction Manager(TM)：事务管理器，用于开启全局事务、提交或者回滚全局事务，是全局事务的开启者。 Resource Manager(RM)：资源管理器，用于分支事务上的资源管理，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务。 Seata 两种模式Seata 关注的就是微服务架构下的数据一致性问题，是一整套的分布式事务解决方案。Seata 框架包含两种模式，一种是 AT 模式。AT 模式主要从数据分片的角度，关注多 DB 访问的数据一致性，当然也包括多服务下的多 DB 数据访问一致性问题。 另外一个就是 TCC 模式，TCC 模式主要关注业务拆分，在按照业务横向扩展资源时，解决微服务间调用的一致性问题，保证读资源访问的事务属性。 AT 模式AT 模式是通过两段提交的方式实现，AT 模式下，把每个数据库被当做是一个 Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。 这就是我们的 AT 模式。简单总结一下，就是把每个数据库当做一个 Resource，在本地事务提交时会去注册一个分支事务。 这种模式是对业务零入侵，并发没那么高。 TCC 模式TCC 模型是把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm / Cancel 接口。 TCC 模式本质也是 2PC ，只是 TCC 在应用层控制。 Try: 尝试执行业务 完成所有业务检查（一致性） 预留必须业务资源（准隔离性） Confirm: 确认执行业务； 真正执行业务，不作任何业务检查 只使用Try阶段预留的业务资源 Confirm 操作满足幂等性 Cancel: 取消执行业务 释放Try阶段预留的业务资源 Cancel操作满足幂等性 这三个阶段，都会按本地事务的方式执行。不同于 XA 的 prepare ，TCC 无需将 XA 的投票期间的所有资源挂起，因此极大的提高了吞吐量。 那么对应到 TCC 模式里，也是一样的，Seata 框架把每组 TCC 接口当做一个 Resource，称为 TCC Resource。这套 TCC 接口可以是 RPC，也以是服务内 JVM 调用。在业务启动时，Seata 框架会自动扫描识别到 TCC 接口的调用方和发布方。如果是 RPC 的话，就是 sofa:reference、sofa:service、dubbo:reference、dubbo:service 等。 扫描到 TCC 接口的调用方和发布方之后。如果是发布方，会在业务启动时向 TC 注册 TCC Resource，与 DataSource Resource 一样，每个资源也会带有一个资源 ID。 如果是调用方，Seata 框架会给调用方加上切面，与 AT 模式一样，在运行时，该切面会拦截所有对 TCC 接口的调用。每调用一次 Try 接口，切面会先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。当请求链路调用完成后，TC 通过分支事务的资源 ID 回调到正确的参与者去执行对应 TCC 资源的 Confirm 或 Cancel 方法。 在讲完了整个框架模型以后，大家可能会问 TCC 三个接口怎么实现。因为框架本身很简单，主要是扫描 TCC 接口，注册资源，拦截接口调用，注册分支事务，最后回调二阶段接口。最核心的实际上是 TCC 接口的实现逻辑。下面我将根据蚂蚁金服内部多年的实践来为大家分析怎么实现一个完备的 TCC 接口。 运行 Demo官方Demo 下面是 dubbo 的例子，运行后报错可以看到回滚信息： INFO [rpcDispatch_RMROLE_4_8] - onMessage:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchType=AT,resourceId=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC,applicationData=null INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacking: 10.116.22.63:8091:2016481020 2016481022 jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC INFO [rpcDispatch_RMROLE_4_8] - xid 10.116.22.63:8091:2016481020 branch 2016481022, undo_log deleted with GlobalFinished INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacked result: PhaseTwo_RollbackedDEBUG [rpcDispatch_RMROLE_4_8] - branch rollback result:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null INFO [rpcDispatch_RMROLE_4_8] - RmRpcClient sendResponse xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =nullDEBUG [rpcDispatch_RMROLE_4_8] - send response:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null,channel:[id: 0xc8027ef7, L:/127.0.0.1:62873 - R:/127.0.0.1:8091] 注意： 数据库驱动与 Mysql 版本一致 数据库 rul 添加时区 jdbc.account.url=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC 参考链接Seata AT 模式分布式事务源码分析 分布式事务 Seata TCC 模式深度解析","link":"/2019/07/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6Seata/"},{"title":"堆排序","text":"今天看到一篇面经，算法题是手写堆排序，《算法》放在书架已经有一段时间了，想试试能不能写出来，然而并没有，所以记录一下 自顶到底构造堆这是一道 lintcode上面的题目堆化 构造一个堆只需要从左到右遍历数组，每次只要保证所遍历到的位子能满足堆的条件 public class Solution { /* * @param A: Given an integer array * @return: nothing */ public void heapify(int[] A) { for (int i = 0; i &lt; A.length; i++) { swim(A, i); } } // 上浮 private void swim(int[] A, int i) { while(i &gt; 0 &amp;&amp; A[i] &lt; A[(i-1) / 2]) { swap(A, i, (i-1) / 2); i = (i-1) / 2; } } private void swap(int[] A, int i, int j) { int temp = A[i]; A[i] = A[j]; A[j] = temp; }} 自底到顶构造堆而堆排序采用的是自底到顶构造堆，每次把第一个元素和最后一个元素交换，交换之后把第一个元素下沉，同时堆数组减一，下面是代码 public class Heap { private static void heapSort(int[] array) { int len = array.length - 1; for (int i = (len - 1) / 2; i &gt;= 0; i--) { sink(array, i, len); } printArr(array); while (len &gt;= 0) { swap(array, 0, len); sink(array, 0, --len); } } private static void sink(int[] array, int i, int len) { while (i * 2 + 1 &lt;= len) { int j = i * 2 + 1; if (j + 1 &lt;= len &amp;&amp; array[j+1] &gt; array[j]) j++; if (array[i] &gt; array[j]) break; swap(array, i, j); i = j; } } private static void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } public static void main(String[] args) { int[] array = {2, 3, 1, 6, 4, 5, 2, 1}; heapSort(array); printArr(array); } private static void printArr(int[] array) { Arrays.stream(array).forEach(a -&gt; System.out.print(a + &quot; &quot;)); System.out.println(); }}","link":"/2018/11/23/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"title":"浮点数在计算机中的表示","text":"前言相信大家在编程过程中都有使用过浮点数，但是浮点数总是给我带来预期不一样的结果，下面展示了在 C 语言中的精度问题，发现使用浮点数总是会带来精度缺失。在学习和工作当中总能听到不能使用浮点数来表示金钱，会有精度缺失。 #include &lt;stdio.h&gt;int main() { float a = 0.1 + 0.2; printf(&quot;a = %.20f\\n&quot;, a); // 0.30000001192092895508 return 0;} 但是在一些特殊领域，单靠整数是无法满足精度要求，这个时候就需要用到浮点数。这边篇文章来解释浮点数在计算机中是如何表示。 二进制小数我们先类比一下比较熟悉的十进制数，比如 3.25 可以表示为： 3 * 10^0 + 2 * 10^-1 + 5 * 10^-2 = 3.25 如果我们只用 1 字节二进制来表示，一共 8 位，前 4 位表示整数，后 4 位表示小数，可以表示为0011 0100 ： 1 * 2^1 + 1 * 2^0 + 0 * 2^-1 + 1 * 2^-2 = 3.25 这种定点表示不能很有效的表示很大的数，我们一般在计算机中表示小数也不是使用这种方式，而是使用 IEEE 浮点表示方法。 IEEE 浮点数表示 IEEE 二进制浮点数算术标准（IEEE 754）是20世纪80运算标准，为许多CPU与浮点运算器所采用。这个标准定义了表示浮点数的格式包括负零（-0）与反常值（denormal number），一些特殊数值，比如无穷（Inf）与非数值（NaN），以及这些数值的“浮点数运算符”；它也指明了四种数值舍入规则和五种例外状况（包括例外发生的时机与处理方式） IEEE 浮点数标准用如下 V = (-1)^s * M * 2^E 形式来表示一个数： 符号（sign）：s 决定这个数是负数（s = 1）还是正数（s = 0） 尾数（significand）：M 是一个二进制小数他的范围是 [1,2) 阶码（exponent）: E 的作用是对浮点数加权，这个权重是 2 的 E 次幂，也可以为负 其中 s 对应着符号位，exp 对应着 E（注意，不一定等于 E，因为位数限制表达能力有限），frac 对应着 M（注意，不一定等于 M，因为位数限制表达能力有限）。不同的位数就代表了不同的表示能力，也就是单精度，双精度，扩展精度的来源。 给定表示，根据 exp 的值，被编码的值可以分成三种不同的情况，最后一种有两种不同的变种： 规范化值(Normalized Values) 当 exp 位不全为 0，也不全为 1，阶码的值 E = e - Bias ，其中 e 是无符号数（单精度取值范围 [1, 254] ），而 Bias 是一个等于 2^(k-1) - 1的偏置值（单精度为127）。所以 E 的取值范围为[-126, 127]。 小数字段 frac 被解释描述为 f 取值范围 [0, 1)，表示二进制小数点最高有效位。尾数定义为 M = 1 + f ，隐式表示。既然我们总能调整阶码 E，使得尾数的范围在 [1, 2) 范围中，那么这种表示方法就可以额外获取一个精度位技巧，既然第一位总是 1，那么我们就不需要显式地表现。 非规范化值(Denormalized Values) 当阶码域全为 0 时，所表示的数是非规格化形式。在这种情况下，阶码的值 E = 1 - Bias，而尾数的值 M = f 也就是小数字段，不包含隐式的开头 1。 为什么阶码的值为 1 - Bias 而不是 -Bias，这种方式提供了一种从非规格化值平滑转换的规格化值得一直手段。 非规格化有两个用途： 表示 0 ，当 f 全为 0 时，但是由于有符号位，则有 +0 和 -0 两种。 表示那些非常接近 0 的数。 特殊值 当阶码全为 1，而小数域全为 0 时，当符号位为 0 表示正无穷，当符号为 1，表示负无穷。 当小数域不全为 0 时，被称为 NaN （Not a Number），比如当计算根号一个负数，或者计算无穷减无穷。 具体表示 浮点数在坐标轴上的表示，接下来举一个实际的例子。 我们采用 1 位符号位，4 位 exp 位，3 位 frac 位，因此对应的 bias 为 7。 回顾前面公式，V = (-1)^s * M * 2^E，对于规范化数：E = exp − Bias ；对于非规范数：E = 1 − Bias。 这种形式的最小规格化同样有 E = 1 - 7 = -6 ，并且小数的取值范围也 0，1/8，…，7/8，发现最大规格化数 7/512 到最小规格化数 8/512 直接的平滑转变，这种平滑性归功于我们对非规格化数 E 的定义为 1 - Bias，而不是 -Bias，我们补偿非规格化的尾数没有隐含开头的 1。 最大规格数为 240，再增大就会溢出为正无穷。 例子求 01000011110110000000110011001101 代表的浮点数？ s exp frac1 8 230 10000111 10110000000110011001101 E = exp - Bias = 135 - 127 = 8 M = 1.10110000000110011001101 V = (-1)^s * M * 2^E = 1 * 1.10110000000110011001101 * 2^8 = 110110000.000110011001101 = 432.10000620 求 123.4 的二进制表示？ s exp frac 1 8 230 0000000 00000000000000000000除 2 乘 2123 0.4 61 1 0.8 0 30 1 0.6 1 15 0 0.2 1 7 1 0.4 0 3 1 0.8 0 1 1 0.6 1 0 1 0.2 1所以这个数为：01111011.01100110011001100110 = 01.11101101100110011001100110 * 2^6 所以 E = 5 exp = 1110 1101 1001 1001 1001 100 因为 123.4 为正数，所以 s 为 0 E = exp - Bias ，单精度 Bias 为 127，E 为 5，所以 exp = E + Bias = 6 + 127 = 133 = 1000 0101 结果为 0 10000101 11101101100110011001100 最后我们用 Java 程序来验证一下 public class BitTest { public static void main(String[] args) { printf(432.1f); printf(123.4f); } private static void printf(float f) { String s = Integer.toBinaryString(Float.floatToIntBits(f)); StringBuilder zero = new StringBuilder(); if (s.length() &lt; 32) { int len = 32 - s.length(); for (int i = 0; i &lt; len; i++) { zero.append(&quot;0&quot;); } } String binary = zero.toString() + s; System.out.println(binary.substring(0, 1) + &quot; &quot; + binary.substring(1, 9) + &quot; &quot; + binary.substring(9, 32)); }} 输出结果 0 10000111 101100000001100110011010 10000101 11101101100110011001101 发现我我们前面所计算的相同，验证我们手动计算的正确性，通过这两个例子可以加深对浮点数表示的认识。 总结本篇文章简单的介绍了 IEEE 浮点表示，介绍了规格化和非规格化的计算方式，以及如何从非规格化过度到规格化，通过通过这两个例子可以加深对浮点数表示的认识。虽然平时工作可能用不太到，但是当我看到这样设计觉得挺赞的，尤其是从非规格化到规格化的平滑过度。 参考 深入理解计算机系统 【读薄 CSAPP】壹 数据表示","link":"/2020/10/17/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E8%A1%A8%E7%A4%BA/"},{"title":"Go语言入门笔记","text":"Go语言是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言，它用批判吸收的眼光，融合C语言、Java等众家之长，将简洁、高效演绎得淋漓尽致。 Go语言起源于2007年，当时Google的技术大神们备受C++越来越臃肿的困扰，决心开发一种新的语言来取代C++。他们认为：与其在臃肿的语言上不断增加新的特性，不如简化编程语言。于是，Golang这门新语言应运而生。 在十年多的时间里，Go语言发展势头强劲，凭借其简洁、高效的特性，在竞争激烈的编程语言市场中占据了一席之地。Google、腾讯、阿里等大公司纷纷选择使用Go语言来开发服务应用项目。当然，和其他的编程语言一样，Go语言也有其自身的缺陷。 课程导论 特点 没有“对象”，没有继承，没有泛型，没有 try/catch 有接口，函数式编程，CSP 并发模型（goroutine + channel） 语法简单 基本语法 变量 选择，循环 指针，数组，容器 面向接口 结构体 duck typing 的概念 组合的思想 函数式编程 闭包的概念 工程化 资源管理，错误处理 测试和文档 性能调优 并发编程 goroutine 和 channel 理解调度器 基本语法HelloWorldpackage mainimport &quot;fmt&quot;func main() { fmt.Println(&quot;Hello World!&quot;)} 变量定义package mainimport &quot;fmt&quot;// 默认变量值func variableZeroValue() { var a int var s string fmt.Println(a, s)}// 定义变量值func variableInitialValue() { var a, b int = 3, 4 var s string = &quot;abc&quot; fmt.Println(a, b, s)}// 变量推断func variableTypeDeduction() { var a, b, c = 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 变量推断简写func variableShorter() { a, b, c := 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 全局变量var a = 1// 全局变量定义不能使用 :=// b := 2// 方便定义多个var ( b = &quot;abc&quot; c = 1 d = true)func main() { variableZeroValue() variableInitialValue() variableTypeDeduction() variableShorter()} 内建变量类型 bool, stiring (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr byte, rune float32, float64, complex64, complex128 常量与枚举package mainimport ( &quot;fmt&quot; &quot;math&quot;)func tri() { a, b := 3, 4 var c int // 先把 int 转 float64 再转回 int c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c)}// 定义常量func consts() { var c int // 指定类型, 下面需要强转为 float64 // const a, b int = 3, 4 // c = int(math.Sqrt(float64(a*a + b*b))) // 不指定类型, 不需要强转为 float64 const a, b = 3, 4 c = int(math.Sqrt(a*a + b*b)) fmt.Println(c)}// 定义枚举func enums() { //const ( // cpp = 0 // java = 1 // python = 2 // golang = 3 //) // 使用 iota 自增加，与上面一样 const ( cpp = iota java python golang _ // 跳开 4 javascript ) fmt.Println(cpp, java, python, golang, javascript) // 0 1 2 3 5 // b, kb, mb, gb, tb, pb const ( b = 1 &lt;&lt; (10 * iota) kb mb gb tb pb ) fmt.Println(b, kb, mb, gb, tb, pb) // 1 1024 1048576 1073741824 1099511627776 1125899906842624}func main() { tri() consts() enums()} 条件语句package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot;)// iffunc read() { const filename = &quot;abc.txt&quot; // 读取文件 contents, err := ioutil.ReadFile(filename) if err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) } // 也可以这样写 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) }}// switchfunc eval(a, b int, op string) int { var result int // switch 会自动 break, 除非使用 fallthrough switch op { case &quot;+&quot;: result = a + b case &quot;-&quot;: result = a - b case &quot;*&quot;: result = a * b case &quot;/&quot;: result = a / b default: panic(&quot;unsupported operator: &quot; + op) } return result}// switchfunc grade(score int) string { // switch 后面没有表达式 switch { case score &lt; 0 || score &gt; 100: panic(&quot;wrong score&quot;) case score &lt; 60: return &quot;E&quot; case score &lt; 70: return &quot;D&quot; case score &lt; 80: return &quot;C&quot; case score &lt; 90: return &quot;B&quot; case score &lt;= 100: return &quot;A&quot; } return &quot;&quot;}func main() { read() fmt.Println(eval(1, 2, &quot;+&quot;)) // 3 grade(100)} 循环package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot;)// 转为二进制func convertToBin(n int) string { res := &quot;&quot; for ; n &gt; 0; n /= 2 { lsb := n % 2 res = strconv.Itoa(lsb) + res } return res}// 打印文件func printFile(fileName string) { file, err := os.Open(fileName) if err != nil { panic(err) } scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) }}// 死循环func forever() { for { fmt.Println(&quot;forever&quot;) }}func main() { fmt.Println( convertToBin(5), convertToBin(13), ) printFile(&quot;abc.txt&quot;); forever()} 函数package mainimport ( &quot;fmt&quot; &quot;math&quot;)// 返回多个值func div(a, b int) (int, int) { return a / b, a % b}// 可以对返回值命名func div2(a, b int) (q, r int) { return a / b, a % b}// 返回 errorfunc eval(a, b int, op string) (int, error) { switch op { case &quot;+&quot;: return a + b, nil case &quot;-&quot;: return a - b, nil case &quot;*&quot;: return a * b, nil case &quot;/&quot;: return a / b, nil default: return 0, fmt.Errorf(&quot;unsupported opration: %s&quot;, op) }}// 使用函数式编程func apply(op func(int, int) int, a, b int) int { return op(a, b)}// 可变参数func sum(numbers ...int) int { sum := 0 for i := range numbers { sum += numbers[i] } return sum}func pow(a, b int) int { return int(math.Pow(float64(a), float64(b)))}func main() { i, i2 := div(5, 3) fmt.Println(i, i2) q, r := div2(5, 3) fmt.Println(q, r) res, err := eval(1, 2, &quot;&amp;&quot;) // unsupported opration: &amp; if err != nil { fmt.Println(err) } else { fmt.Println(res) } fmt.Println(apply(pow, 2, 2)) // 4 fmt.Println(sum(1, 2, 3, 4)) // 10} 指针package mainimport &quot;fmt&quot;// 使用指针func swap(a *int, b *int) { *b, *a = *a, *b}func swap2(a, b int) (int, int) { return b, a}func main() { a, b := 3, 4 swap(&amp;a, &amp;b) fmt.Println(a, b) // 4 3 a, b = 3, 4 a, b = swap2(a, b) fmt.Println(a, b) // 4 3} 数组、切片和容器数组package mainimport &quot;fmt&quot;// 数组定义func defineArray() { // 定义数组的方法 var arr1 [5]int arr2 := [3]int{1, 3, 5} arr3 := [...]int{2, 4, 6, 8} fmt.Println(arr1, arr2, arr3) // [0 0 0 0 0] [1 3 5] [2 4 6 8] // 定义二维数组 var grid [2][3]int fmt.Println(grid) // [[0 0 0] [0 0 0]]}// 遍历数组func printArray() { arr := [...]int{2, 4, 6, 8} for i := 0; i &lt; len(arr); i++ { fmt.Println(arr[i]) } // 通过 range 可以获取下标 for i := range arr { fmt.Println(arr[i]) } // 获取下标和值 for i, v := range arr { fmt.Println(i, v) } // 只获取值, 可以使用 _ 来省略变量 for _, v := range arr { fmt.Println(v) }}// [3]int 和 [5]int 是不同的类型func printArray2(arr [5]int) { fmt.Println(arr)}// 数组是值类型func printArray3(arr [5]int) { arr[0] = 100 fmt.Println(arr) // [100, 0, 0, 0, 0]}// 传递指针func printArray4(arr *[5]int) { arr[0] = 100 fmt.Println(*arr) // [100, 0, 0, 0, 0]}func main() { defineArray() printArray() var arr1 [5]int // arr2 := [3]int{1, 3, 5} // arr3 := [...]int{2, 4, 6, 8, 10} // [3]int 和 [5]int 是不同的类型 printArray2(arr1) // 在函数里面改变数组的值 // printArray2(arr2) // cannot use arr2 (type [3]int) as type [5]int in argument to printArray2 // 在函数里改变了数组第一个值, 后面打印还是不变，每次传递数组都是一个副本 printArray3(arr1) fmt.Println(arr1) // [0, 0, 0, 0, 0] // 传递地址过去就会改变 printArray4(&amp;arr1) fmt.Println(arr1) // [100, 0, 0, 0, 0]} 切片package mainimport &quot;fmt&quot;// 切片func mySlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(&quot;arr[2:6] = &quot;, arr[2:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[:6] = &quot;, arr[:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[2:] = &quot;, arr[2:]) // arr[2:] = [2 3 4 5 6 7] fmt.Println(&quot;arr[:] = &quot;, arr[:]) // arr[:] = [0 1 2 3 4 5 6 7]}// 更新func updateSlice(slice []int) { slice[0] = 2019}// 扩展func extendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 我们知道 s1 只有 4 个元素, 但是 s2 还是能 s1 := arr[2:6] s2 := s1[3:5] fmt.Println(s1) // [2 3 4 5] fmt.Println(s2) // [5 6] fmt.Printf(&quot;len=%d, cap=%d&quot;, len(s1), cap(s1)) // len=4, cap=6}// 添加func appendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 添加元素如果超过了 cap, 系统会重新分配更大的底层数组 // 由于值的传递关系, 必须接受 append 的返回值 s1 := arr[2:6] s2 := append(s1, 100) s3 := append(s2, 100) s4 := append(s3, 100) s5 := append(s4, 100) fmt.Println(s1, s2, s3, s4, s5) // [2 3 4 5] [2 3 4 5 100] [2 3 4 5 100 100] [2 3 4 5 100 100 100] [2 3 4 5 100 100 100 100]}// 创建 slicefunc createSlice() { // 0. 创建一个空的 slice var s []int // 发现 cap 是从 1 2 4 8 16 32... 扩大 for i := 0; i &lt; 100; i++ { s = append(s, 1+2*i) printSlice(s) } // 1. 创建一个带有值的 slice s1 := []int{1, 2, 3, 4, 5} printSlice(s1) // len=5, cap=5, slice=[1 2 3 4 5] // 2. 创建一个 cap = 16 s2 := make([]int, 16) printSlice(s2) // len=16, cap=16, slice=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] // 3. 创建一个 len = 10, cap = 32 s3 := make([]int, 10, 32) // len=10, cap=32, slice=[0 0 0 0 0 0 0 0 0 0] printSlice(s3)}// 复制func copySlice() { src := []int{1, 2, 3} dst := make([]int, 16) fmt.Println(dst) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] copy(dst, src) fmt.Println(dst) // [1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0]}// 删除func deleteSlice() { // 删除下标为3的元素 s := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s = append(s[:3], s[4:]...) // s[4:]... 转换为可变参数 fmt.Println(s) // [0 1 2 4 5 6 7 8] // 删除第一个 s1 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s1 = s1[1:] fmt.Println(s1) // [1 2 3 4 5 6 7 8] // 删除最后一个 s2 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s2 = s2[:len(s2) - 1] fmt.Println(s2) // [0 1 2 3 4 5 6 7]}func printSlice(s []int) { fmt.Printf(&quot;len=%d, cap=%d, slice=%v \\n&quot;, len(s), cap(s), s)}func main() { mySlice() arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} slice1 := arr[:] fmt.Println(&quot;Before update: &quot;, slice1) // Before update: [0 1 2 3 4 5 6 7] updateSlice(slice1) fmt.Println(&quot;After update: &quot;, slice1) // After update: [2019 1 2 3 4 5 6 7] extendSlice() appendSlice() createSlice() copySlice() deleteSlice()} Mappackage mainimport &quot;fmt&quot;// 定义 mapfunc defineMap() { // 定义一个带默认值的 map m1 := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 定义一个 empty map m2 := make(map[string]string) // 定义一个 nil map var m3 map[string]string fmt.Println(m1, m2, m3) // map[a:A b:B] map[] map[]}// 遍历 mapfunc traversingMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 打印 key value for k, v := range m { fmt.Println(k, v) } // 只打印 key for k := range m { fmt.Println(k) } // 只打印 value for _, v := range m { fmt.Println(v) }}// 判断是否存在func containMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } value, ok := m[&quot;c&quot;] if ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) } if value, ok := m[&quot;b&quot;]; ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) }}// 删除元素func deleteMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } fmt.Println(m) // map[a:A b:B] delete(m, &quot;a&quot;) fmt.Println(m) // map[b:B]}func main() { defineMap() traversingMap() containMap() deleteMap()} 例题：查找最长不重复子串 package mainimport &quot;fmt&quot;// 查早最长不重复子串func lengthOfSubString(s string) int { start := 0 maxLength := 0 lastOccuredMap := make(map[rune]int) for i, ru := range []rune(s) { if lastI, ok := lastOccuredMap[ru]; ok &amp;&amp; lastI &gt;= start { start = lastI + 1 } if i-start+1 &gt; maxLength { maxLength = i - start + 1 } lastOccuredMap[ru] = i } return maxLength}func main() { fmt.Println(lengthOfSubString(&quot;aaa&quot;)) fmt.Println(lengthOfSubString(&quot;abab&quot;)) fmt.Println(lengthOfSubString(&quot;abc&quot;)) fmt.Println(lengthOfSubString(&quot;abcabc&quot;))} 字符和字符串处理package mainimport &quot;fmt&quot;func runeTest() { s := &quot;cuzz是我!&quot; for i, b := range []byte(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, b, b) } fmt.Println() for i, u := range s { fmt.Printf(&quot;(%d %X %c) &quot;, i, u, u) } fmt.Println() for i, r := range []rune(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, r, r) } // 输出 // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 E6 æ) (5 98 ) (6 AF ¯) (7 E6 æ) (8 88 ) (9 91 ) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (7 6211 我) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (5 6211 我) (6 21 !) // 说明 range s 使用的 utf-8 遍历, 但是观察下标发现不是连续的 // ascii 转为 utf-8 如:(4 E6) (5 98) (6 AF) -&gt; (4 662F) // 使用 []rune() 转换可以使下标连续输出}func main() { runeTest()} 面向对象 go 语言仅支持封装，不支持继承和多态 go 语言没有 class，只有 struct 结构体和方法package mainimport ( &quot;fmt&quot;)// 定义结构体, 小写对外不可见type treeNode struct { value int left, right *treeNode}// setter, 错误, 由于 go 是传值, 不会改变func (node treeNode) setVal(value int) { node.value = value}func (node *treeNode) setValue(value int) { node.value = value}// 给结构体定义方法 node.print()func (node treeNode) print() { fmt.Println(node.value)}// 普通的方法 print(node)func print(node treeNode) { fmt.Println(node.value)}// 定义一个工厂方法func createNode(value int) *treeNode { return &amp;treeNode{value: value}}// 遍历func (node *treeNode) traverse() { if node == nil { return } node.left.traverse() node.print() node.right.traverse()}func main() { // 定义一个空的结构体 var node treeNode fmt.Println(node) // {0 &lt;nil&gt; &lt;nil&gt;} // 使用构造器定义一个结构体 node2 := treeNode{ value: 1, left: &amp;treeNode{}, // 取地址 right: new(treeNode), // new() 获取的是地址 } fmt.Println(node2) // {1 0xc00000c0c0 0xc00000c0a0} // 使用工厂方法创建 node3 := treeNode{ value: 0, } node3.left = createNode(1) node3.right = createNode(2) fmt.Println(node3) // {0 0xc00008e0a0 0xc00008e0c0} // 区别 node.print() // 0 print(node) // 0 // 不会改变, go 是传值 node.setVal(1) node.print() // 0 // 会改变 node.setValue(1) node.print() // 1 fmt.Println() // 中顺遍历 0 // 1 2 node3.traverse() // 1 0 2} 包和封装 包 每个目录一个包 main 包包含可执行入口 为结构定义的方法必须放在同一包内 可以是不同的文件 封装 一般使用驼峰命名 首字母大写表示 public 首字母小写表示 private Queue.go package queueimport &quot;fmt&quot;type Queue []intfunc (q *Queue) Push(v int) { *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}func (q *Queue) Head() int { return (*q)[0]}func (q *Queue) IsEmpty() bool { return len(*q) == 0}func (q *Queue) Print() { for _, v := range *q { fmt.Print(v, &quot; &quot;) } fmt.Println()} test.go package mainimport ( &quot;awesomeProject/queue&quot; &quot;fmt&quot;)func main() { // 定义一个有默认值的队列 q := queue.Queue{1} q.Push(2) q.Push(3) q.Push(4) q.Print() // 1 2 3 4 fmt.Println(q.Pop()) // 1 q.Print() // 2 3 4 q.Pop() q.Pop() q.Pop() fmt.Println(q.IsEmpty()) // true} 项目结构环境变量： GOROOT：go语言自带的类库 GOPATH：用户源代码目录 src：源文件 pkg：build 的之后的中间文件 bin：可执行文件 接口duck typing “像鸭子走路，像鸭子叫…”，那么就是鸭子 描述事物的外部行为而非内部结构 严格说 go 属于结构化类型系统，类似 duck typing 接口定义和实现定义一个假的发送请求，有一个 Get 方法 package mocktype Retriever struct { Contents string}func (r Retriever) Get(url string) string { return url + &quot;hi, cuzz...&quot;} 定义一个真正发送请求，有一个 Get 方法 package workimport ( &quot;net/http&quot; &quot;net/http/httputil&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) Get(url string) string { resp, err := http.Get(url) if err != nil { panic(err) } result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil { panic(err) } return string(result)} 测试 package mainimport ( &quot;awesomego/retriever/mock&quot; &quot;awesomego/retriever/work&quot; &quot;fmt&quot;)// 定义一个接口type Retriever interface { Get(url string) string}// 传入接口func download(r Retriever) string { return r.Get(&quot;http://blog.cuzz.site&quot;)}func main() { // 接口定义 // var mockRetriever Retriever // mockRetriever = mock.Retriever{} mockRetriever := mock.Retriever{} fmt.Println(download(mockRetriever)) workRetriever := work.Retriever{} fmt.Println(download(workRetriever))} 我们发现在接口是调用放定义的，结构体中的接口也是隐式的，结构体满足接口中的方法，就可以说这个结构体实现了这个接口。 接口的值类型在golang中，接口值是由两部分组成的，一部分是接口的类型，另一部分是该类型对应的值，我们称其为动态类型和动态值。 func main() { mockRetriever := mock.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, mockRetriever, mockRetriever) // mock.Retriever, {} workRetriever := work.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, workRetriever, workRetriever) // work.Retriever, { 0s}} 接口组合package main// 定义一个接口type Retriever interface { Get(url string) string}// 定义另一个接口type Poster interface { Post(url string, params map[string]string)}// 接口组合type RetrieverAndPoster interface { Retriever Poster // 也可以定义其他方法 AnotherMethod()}func main() {} 常用系统接口1、Stringer Stringer接口中的 string 相当与 Java #toString 方法 package workimport ( &quot;fmt&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) String() string { return fmt.Sprintf(&quot;UserAgent: %v, TimeOut: %v&quot;, r.UserAgent, r.TimeOut)} 测试 package mainimport ( &quot;awesomego/retriever/work&quot; &quot;fmt&quot; &quot;time&quot;)func main() { workRetriever := work.Retriever{&quot;Mozilla/5.0&quot;, time.Minute} fmt.Println(workRetriever) // UserAgent: Mozilla/5.0, TimeOut: 1m0s} 2、Reader type Reader interface { Read(p []byte) (n int, err error)} 3、Writer type Writer interface { Write(p []byte) (n int, err error)} 函数式编程 函数是一等公民：参数，变量，返回值都可以是函数 高级函数 闭包 package mainimport &quot;fmt&quot;// 定义一个 adder 函数, 没有参数, 返回值是一个函数func adder() func(int) int { sum := 0 return func(v int) int { sum += v return sum }}// 定义斐波那契数列func fibonacci() func() int{ a, b := 0, 1 return func() int { a, b = b, a + b fmt.Println(a) return a }}func main() { a := adder() for i := 0; i &lt; 10; i++ { fmt.Printf(&quot;0 + 1 + ... + %d = %d\\n&quot;, i, a(i)) } f := fibonacci() f() // 1 f() // 1 f() // 2 f() // 3 f() // 5} 资源管理与出错处理defer 调用你可以在 Go 函数中添加多个defer语句，当函数执行到最后时，这些 defer 语句会按照逆序执行（即最后一个defer语句将最先执行），最后该函数返回。特别是当你在进行一些打开资源的操作时，遇到错误需要提前返回，在返回前你需要关闭相应的资源，不然很容易造成资源泄露等问题。如下代码所示，我们一般写打开一个资源是这样操作的： func CopyFile(dst, src string) (w int64, err error) { srcFile, err := os.Open(src) if err != nil { return } defer srcFile.Close() dstFile, err := os.Create(dst) if err != nil { return } defer dstFile.Close() return io.Copy(dstFile, srcFile)} 错误处理错误处理是任何语言都需要考虑到的问题，而 Go 语言在错误处理上解决得更为完善，优雅的错误处理机制是 Go 语言的一大特点。 1、error Go 语言引入了一个错误处理的标准模式，即error接口，该接口定义如下： type error interface { Error() string} 对于大多数函数，如果要返回错误，可以将error作为多返回值的最后一个： func foo(param int)(ret int, err error) { ... } 调用时的代码： n, err := foo(0)if err != nil { // 错误处理} else { // 使用返回值n} 2、panic 停止当前函数执行 一直向上返回，执行每一层的 defer 如果没有遇见 recover，程序退出 3、recover 仅在 defer 中调用 获取 panic 的值 如果无法处理，可以重新 panic package mainimport ( &quot;fmt&quot;)func tryRecover() { // 匿名函数里 defer func() { r := recover() if err, ok := r.(error); ok { fmt.Println(&quot;Error occurred: &quot;, err) } else { panic(fmt.Sprintf(&quot;I don't know what to do: %v&quot;, r)) } }() a := 1 b := 0 fmt.Println(a / b) // runtime error: integer divide by zero // panic(errors.New(&quot;this is an error&quot;)) // panic(123) // 如果不是一个错误的话就, 再次 panic 出去}func main() { tryRecover() } 并发编程goroutine1、协程 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟器层面的多任务 多个协程可能在一个或者多个线程上运行 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func test() { // 此时, 不会输出, main 先退出了, 必须让 main sleep for i := 0; i &lt; 1000; i++ { // 匿名函数 go func(i int) { for { fmt.Printf(&quot;From %d\\n&quot;, i) } }(i) } time.Sleep(time.Millisecond)}func test2() { // 此时不会退出, 因为不能交出控制权 var arr [10]int for i := 0; i &lt; 10; i++ { // 匿名函数 go func(i int) { arr[i]++ }(i) } time.Sleep(time.Millisecond)}func main() { test() test2()} 2、go 语言中的调度器 协程可以相互通信 channelchannel是goroutine之间互相通讯的东西。类似我们 Unix 上的管道（可以在进程间传递消息），用来goroutine之间发消息和接收消息。其实，就是在做goroutine之间的内存共享。channel是类型相关的，也就是说一个channel只能传递一种类型的值，这个类型需要在channel声明时指定。 package mainimport ( &quot;fmt&quot; &quot;time&quot;)// 定义chanfunc defineChan() { // 声名一个传递int型的channel // var a chan int // 初始化一个int型channel a := make(chan int) // 从channel中获取 go func() { for { z := &lt;-a fmt.Println(z) } }() a &lt;- 1 time.Sleep(time.Millisecond)}// 定义带缓存chanfunc bufChan() { // 初始化一个int型channel a := make(chan int, 3) // 从channel中获取 go func() { for { //z, ok := &lt;-a //if !ok { // break //} //fmt.Println(z) // 或者使用这种, 确保发送完成 for z := range a { fmt.Println(z) } } }() a &lt;- 1 a &lt;- 2 a &lt;- 3 a &lt;- 4 close(a) // 关闭了的话, 就一直发送0 time.Sleep(time.Millisecond)}// 如何使用func chanDemo() { // 定义一个只能收数据的channel, 把数据放到channel中 var channels [10]chan&lt;- int for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i] &lt;- 'a' + i } time.Sleep(time.Millisecond)}func createWorker(i int) chan&lt;- int { c := make(chan int) go func() { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, &lt;-c) } }() return c}func main() { defineChan() bufChan() chanDemo()} 使用 Channel 等待任务结束package mainimport ( &quot;fmt&quot;)type worker struct { in chan int done chan bool // 使用done来通信确定完成}func chanDemo() { var channels [10]worker for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i].in &lt;- 'a' + i &lt;-channels[i].done // 等待channel完成 }}func createWorker(i int) worker { w := worker{ in: make(chan int), done: make(chan bool), } go func() { for in := range w.in { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, in) w.done &lt;- true } }() return w}func main() { chanDemo()} 使用 select 进行调度package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func selectDemo() { var c1, c2 chan int c1, c2 = createChan(), createChan() for { select { case n := &lt;-c1: fmt.Printf(&quot;from c1, val: %d\\n&quot;, n) case n := &lt;-c2: fmt.Printf(&quot;from c2, val: %d\\n&quot;, n) } }}func createChan() chan int { out := make(chan int) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) i++ out &lt;- i } }() return out}func main() { selectDemo()}","link":"/2019/10/11/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"title":"JVM 面试","text":"JVM 垃圾回收的时候如何确定垃圾？知道什么是 GC Roots ? 什么是垃圾 简单来说就是内存中已经不在被使用到的空间就是垃圾 要进行垃圾回收，如何判断一个对象是否可以被回收？ 引用计数法 枚举根节点做可达性分析 为了解决引用计数法的循环引用问题，Java 使用了可达性算法。 跟踪收集器采用的为集中式的管理方式，全局记录对象之间的引用状态，执行时从一些列GC Roots的对象做为起点，从这些节点向下开始进行搜索所有的引用链，当一个对象到GC Roots 没有任何引用链时，则证明此对象是不可用的。 图中，对象Object6、Object7、Object8虽然互相引用，但他们的GC Roots是不可到达的，所以它们将会被判定为是可回收的对象。 哪些对象可以作为 GC Roots 的对象： 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法去常量引用的对象 本地方法栈中 JNI (Native方法)引用的对象 你说你做过 JVM 调优和参数配置，请问如果盘点查看 JVM 系统默认值？JVM 的参数类型: 标配参数 -version -help X 参数（了解） -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 XX 参数 Boolean 类型：-XX：+ 或者 - 某个属性值（+ 表示开启，- 表示关闭） -XX:+PrintGCDetails：打印 GC 收集细节 -XX:-PrintGCDetails：不打印 GC 收集细节 -XX:+UseSerialGC：使用了串行收集器 -XX:-UseSerialGC：不使用了串行收集器 KV 设置类型：-XX:key=value -XX:MetaspaceSize=128m -XX:MaxTenuringThreshold=15 jinfo 举例，如何查看当前运行程序的配置 public class HelloGC { public static void main(String[] args) { System.out.println(&quot;hello GC...&quot;); try { Thread.sleep(Integer.MAX_VALUE); } catch (InterruptedException e) { e.printStackTrace(); } }} 我们可以使用 jps -l 命令，查出进程 id 1923 org.jetbrains.jps.cmdline.Launcher1988 sun.tools.jps.Jps1173 org.jetbrains.kotlin.daemon.KotlinCompileDaemon32077 com.intellij.idea.Main1933 com.cuzz.jvm.HelloGC32382 org.jetbrains.idea.maven.server.RemoteMavenServer 在使用 jinfo -flag PrintGCDetails 1933 命令查看 -XX:-PrintGCDetails 可以看出默认是不打印 GC 收集细节也可是使用jinfo -flags 1933 查看所以的参数 两个经典参数：-Xms 和 - Xmx（如 -Xms1024m） -Xms 等价于 -XX:InitialHeapSize -Xmx 等价于 -XX:MaxHeapSize 盘点家底查看 JVM 默认值 查看初始默认值：-XX:+PrintFlagsInitialcuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintFlagsInitial[Global flags] intx ActiveProcessorCount = -1 {product} uintx AdaptiveSizeDecrementScaleFactor = 4 {product} uintx AdaptiveSizeMajorGCDecayTimeScale = 10 {product} uintx AdaptiveSizePausePolicy = 0 {product} uintx AdaptiveSizePolicyCollectionCostMargin = 50 {product} uintx AdaptiveSizePolicyInitializingSteps = 20 {product} uintx AdaptiveSizePolicyOutputInterval = 0 {product} uintx AdaptiveSizePolicyWeight = 10 {product} ... 查看修改更新：-XX:+PrintFlagsFinalbool UsePSAdaptiveSurvivorSizePolicy = true {product}bool UseParNewGC = false {product}bool UseParallelGC := true {product}bool UseParallelOldGC = true {product}bool UsePerfData = true {product}bool UsePopCountInstruction = true {product}bool UseRDPCForConstantTableBase = false {C2 product} = 与 := 的区别是，一个是默认，一个是人物改变或者 jvm 加载时改变的参数 打印命令行参数(可以看默认垃圾回收器)：-XX:+PrintCommandLineFlagscuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintCommandLineFlags-XX:InitialHeapSize=128789376 -XX:MaxHeapSize=2060630016 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 你平时工作用过的 JVM 常用的基本配置参数有哪些？ -Xms 初始大小内存，默认为物理内存 1/64 等价于 -XX:InitialHeapSize -Xmx 最大分配内存，默认为物理内存的 1/4 等价于 -XX:MaxHeapSize -Xss 设置单个线程栈的大小，一般默认为 512-1024k 等价于 -XX:ThreadStackSize -Xmn 设置年轻代的大小 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小，持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:MetaspaceSize 设置元空间大小（元空间的本质和永久代类似，都是对 JVM 规范中的方法区的实现，不过元空间于永久代之间最大区别在于，元空间并不在虚拟中，而是使用本地内存，因此默认情况下，元空间的大小仅受本地内存限制） 元空间默认比较小，我们可以调大一点 -XX:+PrintGCDetails 输出详细 GC 收集日志信息 设置 JVM 参数为： -Xms10m -Xmx10m -XX:+PrintGCDetails -XX:SurvivorRatio 设置新生代中 eden 和 S0/S1 空间比例 默认 -XX:SurvivorRatio=8，Eden : S0 : S1 = 8 : 1 : 1 -XX:NewRatio 配置年轻代和老年代在堆结构的占比 默认 -XX:NewRatio=2 新生代占1，老年代占2，年轻代占整个堆的 1/3 -XX:MaxTenuringThreshold 设置垃圾最大年龄 强引用、软引用、弱引用和虚引用分别是什么？在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 强引用 我们平常典型编码Object obj = new Object()中的 obj 就是强引用，通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出 OutOfMemoryError 运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应强引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 软引用 软引用通过SoftReference类实现， 软引用的生命周期比强引用短一些。 只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即 JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null，否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 代码验证，我设置 JVM 参数为 -Xms10m -Xmx10m -XX:+PrintGCDetails public class SoftReferenceDemo { public static void main(String[] args) { Object obj = new Object(); SoftReference&lt;Object&gt; softReference = new SoftReference&lt;&gt;(obj); obj = null; try { // 分配 20 M byte[] bytes = new byte[20 * 1024 * 1024]; } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(&quot;软引用：&quot; + softReference.get()); } }} 发现当内存不够的时候就会被回收。 [GC (Allocation Failure) [PSYoungGen: 1234K-&gt;448K(2560K)] 1234K-&gt;456K(9728K), 0.0016748 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 448K-&gt;384K(2560K)] 456K-&gt;392K(9728K), 0.0018398 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 384K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;358K(7168K)] 392K-&gt;358K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0057246 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 358K-&gt;358K(9728K), 0.0006038 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;340K(7168K)] 358K-&gt;340K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0115080 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 软引用：nullException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.cuzz.jvm.SoftReferenceDemo.main(SoftReferenceDemo.java:21)Heap PSYoungGen total 2560K, used 98K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 4% used [0x00000000ffd00000,0x00000000ffd18978,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 340K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 4% used [0x00000000ff600000,0x00000000ff6552f8,0x00000000ffd00000) Metaspace used 3067K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K 弱引用 弱引用通过 WeakReference 类实现， 弱引用的生命周期比软引用短。 在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。 代码验证 public class WeakReferenceDemo { public static void main(String[] args) { Object obj = new Object(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj); System.out.println(obj); System.out.println(weakReference.get()); obj = null; System.gc(); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); }} 输出 java.lang.Object@1540e19djava.lang.Object@1540e19dGC之后....nullnull 引用队列 public class ReferenceQueueDemo { public static void main(String[] args) throws InterruptedException { Object obj = new Object(); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj, referenceQueue); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); obj = null; System.gc(); Thread.sleep(500); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); }} 会把该对象的包装类即weakReference放入到ReferenceQueue里面，我们可以从queue中获取到相应的对象信息，同时进行额外的处理。比如反向操作，数据清理等。 java.lang.Object@1540e19djava.lang.Object@1540e19djava.lang.ref.WeakReference@677327b6GC之后....nullnulljava.lang.ref.WeakReference@677327b6 虚引用 虚引用也叫幻象引用，通过PhantomReference类来实现，无法通过虚引用访问对象的任何属性或函数。 幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 请谈谈你对 OOM 的认识？ java.lang.StackOverflowError 在一个函数中调用自己就会产生这个错误 java.lang.OutOfMemoryError : Java heap space new 一个很大对象 java.lang.OutOfMemoryError : GC overhead limit exceeded 执行垃圾收集的时间比例太大， 有效的运算量太小，默认情况下,，如果GC花费的时间超过 **98%**， 并且GC回收的内存少于 **2%**， JVM就会抛出这个错误。 java.lang.OutOfMemoryError : Direct buffer memory配置参数：-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m public class DirectBufferDemo { public static void main(String[] args) { System.out.println(&quot;maxDirectMemory : &quot; + sun.misc.VM.maxDirectMemory() / (1024 * 1024) + &quot;MB&quot;); ByteBuffer byteBuffer = ByteBuffer.allocateDirect(6 * 1024 * 1024); }} 输出 maxDirectMemory : 5MB[GC (System.gc()) [PSYoungGen: 1315K-&gt;464K(2560K)] 1315K-&gt;472K(9728K), 0.0008907 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 464K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;359K(7168K)] 472K-&gt;359K(9728K), [Metaspace: 3037K-&gt;3037K(1056768K)], 0.0060466 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:694) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.cuzz.jvm.DirectBufferDemo.main(DirectBufferDemo.java:17)Heap PSYoungGen total 2560K, used 56K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0e170,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 359K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 5% used [0x00000000ff600000,0x00000000ff659e28,0x00000000ffd00000) Metaspace used 3068K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K java.lang.OutOfMemoryError : unable to create new native thread 创建线程数太多了 java.lang.OutOfMemoryError : Metaspace Java 8 之后的版本使用元空间（Metaspace）代替了永久代，元空间是方法区在 HotSpot 中的实现，它与持久代最大的区别是：元空间并不在虚拟机中的内存中而是使用本地内存。 元空间存放的信息： 虚拟机加载的类信息 常量池 静态变量 即时编译后的代码 具体的实现可以看看这个帖子：几种手动OOM的方式 GC 垃圾回收算法和垃圾收集器的关系？谈谈你的理解？ 四种 GC 垃圾回收算法 引用计数 复制回收 标记清除 标记整理 GC 算法是内存回收的方法论，垃圾收集其就是算法的落实的实现。 目前为止还没有完美的收集器的出现，更加没有万能的收集器，只是针对具体应用最适合的收集器，进行分代收集。 串行垃圾回收器（Serial） 它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，所以不适合服务环境。 并行垃圾回收器（Parallel） 多个垃圾收集线程并行工作，此时用户线程是暂停的，用于科学计算、大数据处理等弱交互场景。 并发垃圾回收器（CMS） 用户线程和垃圾收集线程同时执行（不一定是并行，可能是交替执行），不需要停顿用户线程，互联网公司多用它，适用对相应时间有要求的场景。 G1 垃圾回收器 G1 垃圾回收器将堆内存分割成不同的区域然后并发的对其进行垃圾回收。 怎么查看服务器默认垃圾收集器是哪个？生产是如何配置垃圾收集器？谈谈你对垃圾收集器的理解？ 怎么查看服务器默认垃圾收集器是哪个？ Java -XX:+PrintCommandLineFlags Java 的 GC 回收的类型主要有： UseSerialGC，UseParallelGC，UseConcMarkSweepGC，UseParNewGC，UseParallelOldGC，UseG1GC Java 8 以后基本不使用 Serial Old 垃圾收集器 参数说明 DefNew : Default New Generation Tenured : Old ParNew : Parallel New Generation PSYoungGen : Parallel Scavenge ParOldGen : Parallel Old Generation Server/Client 模式分别是什么意思 最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。 当虚拟机运行在-client模式的时候，使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级，代号为C2的编译器，C2比C1编译器编译的相对彻底，服务起来之后,性能更高。 所以通常用于做服务器的时候我们用服务端模式，如果你的电脑只是运行一下java程序，就客户端模式就可以了。当然这些都是我们做程序优化程序才需要这些东西的，普通人并不关注这些专业的东西了。其实服务器模式即使编译更彻底，然后垃圾回收优化更好，这当然吃的内存要多点相对于客户端模式。 新生代 串行 GC (Serial/ Serital Copying) 并行 GC (ParNew) 并行回收 GC (Parallel/ Parallel Scanvenge) 老年代 串行 GC (Serial Old/ Serial MSC) 并行 GC (Parallel Old/ Parallel MSC) 并发标记清除 GC (CMS) 是一种以获取最短回收停顿时间为目标的收集器，适合应用在互联网站或者 B/S 系统的服务器上，这个类应用尤其重视服务器的响应速度，希望系统停顿时间最短。 CMS 非常适合堆内存大、CPU 核数多的服务器端应用，也是 G1 出现之前大型应用首选收集器。 并发停顿比较少，并发指的是与用户线程一起执行。 过程 初始标记（initail mark）：只是标记一下 GC Roots 能直接关联的对象，速度很快，需要暂停所有的工作线程 并发标记（concurrent mark 和用户线程一起）：进行 GC Roots 的跟踪过程，和用户线程一起工作，不需要暂停工作线程。 重新标记（remark）：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 并发清除（concurrent sweep 和用户线程一起）：清除 GC 不可达对象，和用户线程一起工作，不需要暂停工作线程，基于标记结果，直接清除。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程和用户线程可以一起并发工作，所以总体来看 CMS 收集器的内存回收和用户线程是一起并发地执行。 优缺点 优点：并发收集停顿低 缺点：并发执行对 CPU 资源压力大，采用的标记清除算法会导致大量碎片 由于并发进行， CMS 在收集与应用线程会同时增加对堆内存的占用，也就是说，CMS 必须要在老年代堆用尽之前完成垃圾回收，否者 CMS 回收失败，将触发担保机制，串行老年代收集器将会以 STW 的方式进行一次 GC，从而造成较大的停顿时间。 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐渐耗尽，最后将不得不通过担保机制对堆内存进行压缩。CMS 也提供了参数 -XX:CMSFullGCsBeForeCompaction (默认0，即每次都进行内存整理) 来指定多少次 CMS 收集之后，进行一次压 垃圾收集器配置代码总结，配置新生代收集器，老年代收集器会自动配置上。 如何选择垃圾收集器 单 CPU 或者小内存，单机程序：-XX:UseSerialGC 多 CPU 需要最大吞吐量，如后台计算型应用：-XX:UseParallelGC 或者 -XX:UseParallelOldGC 多 CPU 追求低停顿时间，需要快速响应，如互联网应用：-XX:+UseConcMarkSweepGC G1 垃圾收集器你了解吗？以前收集器的特点 年轻代和老年代是各自独立且连续的内存块 年轻代收集器使用 eden + S0 + S1 进行复制算法 老年代收集必须扫描整个老年代区域 都是以尽可能的少而快速地执行 GC 为设计原则 G1 是什么 G1 是一种面向服务端的垃圾收集器，应用在多核处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集器的暂停时间要求。 像 CMS 收集器一样，能与应用程序线程并发执行，整理空闲空间更快，需要更多的时间来预测 GC 停顿时间，不希望牺牲大量的吞吐性能，不需要更大的 JAVA Heap。 G1 收集器的设计目的是取代 CMS 收集器，同时与 CMS 相比，G1 垃圾收集器是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。G1 的 Stop The World 更可控，G1 在停顿上添加了预测机制，用户可以指定期望的停顿时间。 G1 是在 2012 年才在 jdk.1.7u4 中可以呀用，在 jdk9 中将 G1 变成默认垃圾收集器来代替 CMS。它是以款面向服务应用的收集器。 主要改变是 Eden、Survivor 和 Tenured 等内存区域不再是连续的，而是变成了一个个大小一样的 region，每个 region 从 1M 到 32M 不等，一个 region 有可能属于 Eden、Survivor 或者 Tenured 内存区域。 G1的特点 G1 能充分利用多 CPU、多核环境硬件优势，尽量缩短 STW。 G1 整体采用标记-整理算法，局部是通过是通过复制算法，不会产生内存碎片。 宏观上看 G1 之中不在区分年轻代和老年代，被内存划分为多个独立的子区域。 G1 收集器里面讲整个的内存区域混合在一起，但其本身依然在小范围内要进行年轻代和老年代的区分。保留了新生代和老年代，但她们不在是物理隔离，而是一部分 Region 的集合且不需要 Region 是连续的，也就是说依然会采用不同的 GC 方式来处理不同的区域。 G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 Survivor to space 堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换。 底层原理 Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。 G1的内存结构和传统的内存空间划分有比较的不同。G1将内存划分成了多个大小相等的Region（默认是512K），Region逻辑上连续，物理内存地址不连续。同时每个Region被标记成E、S、O、H，分别表示Eden、Survivor、Old、Humongous。其中E、S属于年轻代，O与H属于老年代。 H表示Humongous。从字面上就可以理解表示大的对象（下面简称H对象）。当分配的对象大于等于Region大小的一半的时候就会被认为是巨型对象。H对象默认分配在老年代，可以防止GC的时候大对象的内存拷贝。通过如果发现堆内存容不下H对象的时候，会触发一次GC操作。 ** 参看：G1从入门到放弃 生产环境服务器变慢，诊断思路和性能评估谈谈？ 整机：top CPU：vmstat 内存：free 硬盘：df 磁盘IO：iostat 网络IO：ifstat 假如生产环境出现 CPU 过高，请谈谈你的分析思路和定位？ 先用 top 命令找出 CPU 占比最高的 ps -ef 或者 jps 进一步定位，得知是一个怎么样的一个后台程序 定位到具体的线程或代码 ps -mp 11111 -o THREAD,tid,time -m 显示所有的线程 -p 进程使用cpu的时间 -o 该参数后是用户自定义格式 将需要的线程 ID 转化为 16 进制格式 jstat &lt;进程ID&gt; | grep &lt;线程ID(16进制)&gt; -A60 对于 JDK 自带的 JVM 监控和性能分析工具用过哪些？一般机是怎么用到的？下一篇重点介绍。 参考链接 强引用、软引用、弱引用、幻象引用有什么区别？(评论) G1从入门到放弃","link":"/2019/05/10/JVM%E9%9D%A2%E8%AF%95/"},{"title":"Java 中的锁","text":"Java中的锁分类在读很多并发文章中，会提及各种各样锁如公平锁，乐观锁等等，这篇文章介绍各种锁的分类。介绍的内容如下： 公平锁/非公平锁 可重入锁/不可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 上面是很多锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计，下面总结的内容是对每个锁的名词进行一定的解释。 公平锁/非公平锁是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 对于 Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁最近正在阅读Java ReentrantLock源码，始终对可重入和不可重入概念理解不透彻，进行学习后记录在这里。 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 Java多线程的 wait() 方法和 notify() 方法。这两个方法是成对出现和使用的，要执行这两个方法，有一个前提就是，当前线程必须获其对象的monitor（俗称“锁”），否则会抛 IllegalMonitorStateException 异常，所以这两个方法必须在同步块代码里面调用。wait()：阻塞当前线程， notify()：唤起被wait()阻塞的线程。 手动实现一个可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 手动实现一个不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 可重入锁的概念和设计思想大体如此，Java 中的可重入锁 ReentrantLock 设计思路也是这样。 独享锁/共享锁是什么 独享锁是指该锁一次只能被一个线程所持有。 共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 互斥锁/读写锁上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock 读写锁在Java中的具体实现就是ReadWriteLock 乐观锁/悲观锁乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。 从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在Java中的使用，就是利用各种锁。 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap 而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。 但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁/轻量级锁/重量级锁偏向锁 在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中 CAS 记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 缺点： 同样的，如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。 不过这个副作用已经小的多。 如果需要，使用参数-XX:-UseBiasedLocking禁止偏向锁优化（默认打开）。 轻量级锁 自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。 顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将 Mark Word 中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。 当然，由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 重量级锁 内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。 偏向锁、轻量级锁、重量级锁分配和膨胀的详细过程见后。会涉及一些Mark Word与CAS的知识。 偏向锁、轻量级锁、重量级锁适用于不同的并发场景： 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。 重量级锁：有实际竞争，且锁竞争时间长。 另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。 如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。 自旋锁首先，内核态与用户态的切换上不容易优化。但通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。 如果锁的粒度小，那么锁的持有时间比较短（尽管具体的持有时间无法得知，但可以认为，通常有一部分锁能满足上述性质）。那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。具体如下： 当前线程竞争锁失败时，打算阻塞自己 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会 在自旋的同时重新竞争锁 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己 如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。 “锁的持有时间比较短“这一条件可以放宽。实际上，只要锁竞争的时间比较短（比如线程1快释放锁的时候，线程2才会来竞争锁），就能够提高自旋获得锁的概率。这通常发生在锁持有时间长，但竞争不激烈的场景中。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 典型的自旋锁实现的例子，可以参考自旋锁的实现 锁分配和膨胀过程 参考链接 Java中的锁分类 Java不可重入锁和可重入锁理解 浅谈偏向锁、轻量级锁、重量级锁","link":"/2019/02/13/Java%20%E4%B8%AD%E7%9A%84%E9%94%81/"},{"title":"Java 反射","text":"Reflection is a feature in the Java programming language. It allows an executing Java program to examine or “introspect” upon itself, and manipulate internal properties of the program. For example, it’s possible for a Java class to obtain the names of all its members and display them. The ability to examine and manipulate a Java class from within itself may not sound like very much, but in other programming languages this feature simply doesn’t exist. For example, there is no way in a Pascal, C, or C++ program to obtain information about the functions defined within that program. One tangible use of reflection is in JavaBeans, where software components can be manipulated visually via a builder tool. The tool uses reflection to obtain the properties of Java components (classes) as they are dynamically loaded. 类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载 就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接 验证：是否有正确的内部结构，并和其他类协调一致 准备：负责为类的静态成员分配内存，并设置默认初始化值 解析：将类的二进制数据中的符号引用替换为直接引用 初始化 对类的静态变量，静态代码块执行初始化操作 类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类 类加载器作用 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行 类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader 扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader 系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法 Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单） Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可） Class c3 = Class.forName(&quot;cn.cuzz.Person&quot;); 注意：第三种和前两种的区别 前两种你必须明确Person类型。 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了。 Person类public class Person { // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() { System.out.println(&quot;空参数构造方法&quot;); } public Person(String name) { this.name = name; System.out.println(&quot;带有String的构造方法&quot;); } // 私有的构造方法 private Person(String name, int age){ this.name = name; this.age = age; System.out.println(&quot;带有String，int的构造方法&quot;); } public Person(String name, int age, String address){ this.name = name; this.age = age; this.address = address; System.out.println(&quot;带有String, int, String的构造方法&quot;); } // 成员方法 // 没有返回值没有参数的方法 public void method1(){ System.out.println(&quot;没有返回值没有参数的方法&quot;); } // 没有返回值，有参数的方法 public void method2(String name){ System.out.println(&quot;没有返回值，有参数的方法 name= &quot;+ name); } // 有返回值，没有参数 public int method3(){ System.out.println(&quot;有返回值，没有参数的方法&quot;); return 123; } // 有返回值，有参数的方法 public String method4(String name){ System.out.println(&quot;有返回值，有参数的方法&quot;); return &quot;哈哈&quot; + name; } // 私有方法 private void method5(){ System.out.println(&quot;私有方法&quot;); } @Override public String toString() { return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;, address=&quot; + address+ &quot;]&quot;; }} 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的) package cn.cuzz;import java.lang.reflect.Constructor;public class Test { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException { // 获取Class对象 包名.类 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); }} 通过反射方式，获取构造方法，创建对象获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] }} 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有) package cn.cuzz;import java.lang.reflect.Field;public class Test3 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField(&quot;age&quot;); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField(&quot;address&quot;); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address }} 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 { public static void main(String[] args) throws IllegalAccessException, Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;); // 获取指定成员变量 // public String name Field nameField = c.getField(&quot;name&quot;); // public int age Field ageField = c.getField(&quot;age&quot;); // 赋值 nameField.set(obj, &quot;Cuzz&quot;); ageField.set(obj, 23); System.out.println(&quot;name = &quot;+ nameField.get(obj)); // name = Cuzz System.out.println(&quot;age = &quot;+ ageField.get(obj)); // age = 23 }} 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的) package cn.cuzz;import java.lang.reflect.Method;public class Test5 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod(&quot;method1&quot;, null); System.out.println(method); // public String method4(String name){ method = c.getMethod(&quot;method4&quot;, String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod(&quot;method5&quot;, null); System.out.println(method); }} 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true)) public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); // 获取指定的方法 Method m4 = c.getMethod(&quot;method4&quot;, String.class); // 执行找到的方法 Object result = m4.invoke(obj, &quot;2018/03/19&quot;); System.out.println(&quot;result = &quot; + result); // result = 哈哈2018/03/19 }} 反射练习下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素。 package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 { public static void main(String[] args) throws Exception, SecurityException { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(&quot;cuzz&quot;); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName(&quot;java.util.ArrayList&quot;); // 找到add()方法 Method addMethod = c.getMethod(&quot;add&quot;, Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] }} 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法 public class Test8 { public static void main(String[] args) throws Exception{ // IO流读取配置文件 FileReader r = new FileReader(&quot;config.properties&quot;); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty(&quot;className&quot;); String methodName = pro.getProperty(&quot;methodName&quot;); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); }} 配置文件 # className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work","link":"/2019/02/11/Java%20%E5%8F%8D%E5%B0%84/"},{"title":"Java8的深入与实战","text":"Lambda 表达式和函数式接口Lambda 表达式定义： Lambda: In programming languages such as Lisp, Python and Ruby lambda is an operator used to denote anonymous functions or closures, following the usage of lambda calculus. 为何需要使用 Lambda 表达式： 在 Java 中，我们无法将函数作为一个参数传递给一个方法，也无法声明一个返回一个函数的方法。 在 JavaScript 中，函数的参数是一个函数，返回值是另一个函数的情况是非常常见的，JavaScript 是一门典型的函数式语言。 我们通过一个例子来引入： /** * @Author: cuzz * @Date: 2019/8/11 14:55 * @Description: */public class Test1 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6); for (int i = 0; i &lt; list.size(); i++) { System.out.println(list.get(i)); } System.out.println(&quot;-----------------&quot;); for (int val : list) { System.out.println(val); } System.out.println(&quot;-----------------&quot;); list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 这是 3 种遍历集合的方式，第一就是简单的遍历，第二种是我们是常说的增强 for 循环遍历。第三种就是 Java 8 新增的方法，先看看 Consumer 这个接口。 package java.util.function;import java.util.Objects;@FunctionalInterfacepublic interface Consumer&lt;T&gt; { void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} 注解上是一个函数式接口，我们看看这个接口的作用。 package java.lang;import java.lang.annotation.*;/** * An informative annotation type used to indicate that an interface * type declaration is intended to be a &lt;i&gt;functional interface&lt;/i&gt; as * defined by the Java Language Specification. * * Conceptually, a functional interface has exactly one abstract * method. Since {@linkplain java.lang.reflect.Method#isDefault() * default methods} have an implementation, they are not abstract. If * an interface declares an abstract method overriding one of the * public methods of {@code java.lang.Object}, that also does * &lt;em&gt;not&lt;/em&gt; count toward the interface's abstract method count * since any implementation of the interface will have an * implementation from {@code java.lang.Object} or elsewhere. * * 有且只有一个抽象方法的接口，如果有重写 Object 中的方法，那也是可以的。 * * &lt;p&gt;Note that instances of functional interfaces can be created with * lambda expressions, method references, or constructor references. * * 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 * * &lt;p&gt;If a type is annotated with this annotation type, compilers are * required to generate an error message unless: * * &lt;ul&gt; * &lt;li&gt; The type is an interface type and not an annotation type, enum, or class. * &lt;li&gt; The annotated type satisfies the requirements of a functional interface. * &lt;/ul&gt; * * &lt;p&gt;However, the compiler will treat any interface meeting the * definition of a functional interface as a functional interface * regardless of whether or not a {@code FunctionalInterface} * annotation is present on the interface declaration. * * 编译器会对满足定义函数式接口的接口当做函数式接口，不管它有没有 @FunctionalInterface 注解声明。 * * @jls 4.3.2. The Class Object * @jls 9.8 Functional Interfaces * @jls 9.4.3 Interface Method Body * @since 1.8 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface {} 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 lambda 表达式：() -&gt; System.out.println(i) 方法引用：System.out::print 构造方法引用：new::ArrayList 用一个例子来说明什么是函数式接口。 @FunctionalInterfaceinterface Cons { void print(); String toString();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public void test(Cons func) { func.print(); } public static void main(String[] args) { Test2 test2 = new Test2(); test2.test(() -&gt; System.out.println(&quot;xxx&quot;)); Cons func = () -&gt; System.out.println(&quot;yyy&quot;); test2.test(func); System.out.println(func.getClass()); // 输出 class com.cuzz.Test2$$Lambda$2/2074407503 System.out.println(func.getClass().getSuperclass()); // 输出 class java.lang.Object }} 可以说明3点： 函数式接口只有一个非重写 Object 的抽象方法 lambda 表达式就是一个匿名类 对于一个函数式接口，我们并不关心这个抽象方法的名称。 从Consumer深入理解函数式接口和方法引用我们回到这个例子当中 public class Test1 { public static void main(String[] args) { list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 先看看 Iterable#forEach 这个方法，是 Iterable 这个接口这的默认方法，在 Java 8 中接口中是允许默认方法。对于 Iterable#forEach 是对每个元素执行给定的动作。 public interface Iterable&lt;T&gt; { /** * Returns an iterator over elements of type {@code T}. * * @return an Iterator. */ Iterator&lt;T&gt; iterator(); /** * Performs the given action for each element of the {@code Iterable} * until all elements have been processed or the action throws an * exception. Unless otherwise specified by the implementing class, * actions are performed in the order of iteration (if an iteration order * is specified). Exceptions thrown by the action are relayed to the * caller. * * 对每个元素执行给定的动作。 * * @implSpec * &lt;p&gt;The default implementation behaves as if: * &lt;pre&gt;{@code * for (T t : this) * action.accept(t); * }&lt;/pre&gt; * * @param action The action to be performed for each element * @throws NullPointerException if the specified action is null * @since 1.8 */ default void forEach(Consumer&lt;? super T&gt; action) { Objects.requireNonNull(action); for (T t : this) { action.accept(t); } } default Spliterator&lt;T&gt; spliterator() { return Spliterators.spliteratorUnknownSize(iterator(), 0); }} 看看 Consumer 是什么 package java.util.function;import java.util.Objects;/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, {@code Consumer} is expected * to operate via side-effects. * * 表示一个操作接受单一输入参数，无返回结果。 * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #accept(Object)}. * * @param &lt;T&gt; the type of the input to the operation * * @since 1.8 */@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); /** * Returns a composed {@code Consumer} that performs, in sequence, this * operation followed by the {@code after} operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the {@code after} operation will not be performed. * * @param after the operation to perform after this operation * @return a composed {@code Consumer} that performs in sequence this * operation followed by the {@code after} operation * @throws NullPointerException if {@code after} is null */ default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} lambda 表达式的作用： lambda 表达式为 Java 添加了缺失的函数式编程特性，使我们能将函数当做一等公民看待。 在将函数作为一等公民的语言中，lambda 表达式的类型是函数。但在 Java 中，lambda 表达式是对象，它们必须依附于一类特别的对象（函数式接口）； Lambda 表达式的深入对于 lambda 表达式需要根据上下文来推断，我们并不知道 () -&gt; {} 是什么，不知道对应的参数，方法是什么，只用通过前面的 Cons 定义才知道。 @FunctionalInterfaceinterface Cons1 { void print1();}@FunctionalInterfaceinterface Cons2 { void print2();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public static void main(String[] args) { Cons1 cons1 = () -&gt; {}; Cons2 cons2 = () -&gt; {}; System.out.println(cons1.getClass().getInterfaces()[0]); // interface com.cuzz.Cons1 System.out.println(cons2.getClass().getInterfaces()[0]); // interface com.cuzz.Cons2 }} 我们先看一个排序的例子： /** * @Author: cuzz * @Date: 2019/8/12 23:09 * @Description: 排序 */public class Test4 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); Collections.sort(list, (String s1, String s2) -&gt; { return s2.compareTo(s1); }); // 1 Collections.sort(list, (s1, s2) -&gt; s2.compareTo(s1)); // 2 }} 从 1 到 2 简化了很多，修饰符 String 和 return 都可以省略。Java Lambda 表达式是一种匿名函数，它没有声明方法，也没有访问修饰符、返回值和名字。 Lambda 表达式作用： 传递行为，而不仅仅是值 提升抽象层次 API 重用性好 更加灵活 Lambda 基本语法： Java 中的 Lambda 表达式基本语法 如：(argument) -&gt; {body} 省略类型：(arg1, arg2, ...) -&gt; {body} 有类型：(type1 arg1, type2 arg2, ...) -&gt; {body} Lambda 示例说明 (int a, int b) -&gt; {return a + b;} () -&gt; System.out.println(&quot;hello world&quot;) (String s) -&gt; {System.out.println(s);} () -&gt; 42 () -&gt; {return &quot;cuzz&quot;}; Lambda结构 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断，如：(int a) 与 (a) 效果相同 所有的参数需包含在圆括号内，参数之间用逗号相隔。如：(a, b) 或 (String a, int b float c) 空圆括号表示参数集为空，如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号可以省略，如：a -&gt; return a * a Lambda 表达式的主题可以包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号可以省略，匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，表达式必须使用花括号 Function直接先看源码 /** * Represents a function that accepts one argument and produces a result. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object)}. * * @param &lt;T&gt; the type of the input to the function * @param &lt;R&gt; the type of the result of the function * * @since 1.8 */@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); } default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); } /** * Returns a function that always returns its input argument. * * @param &lt;T&gt; the type of the input and output objects to the function * @return a function that always returns its input argument */ static &lt;T&gt; Function&lt;T, T&gt; identity() { return t -&gt; t; }} 可以看出 Function 有一个抽象方法和两个默认方法以及一个静态方法。 （1） Function#apply Stream#map 里就是接受一个 Function，对于 Function 意思就是从一个映射到另一个。下面例子就是把字符串映射到大写。对于 String::toUpperCase 使用的是方法引用。 /** * @Author: cuzz * @Date: 2019/8/11 23:13 * @Description: */public class Test3 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); list.stream().map(item -&gt; item.toUpperCase()).forEach(item -&gt; System.out.println(item)); list.stream().map(String::toUpperCase).forEach(System.out::println); Function&lt;String, String&gt; function = String::toUpperCase; System.out.println(function.getClass()); }} 我们看一个例子： /** * @Author: cuzz * @Date: 2019/8/13 0:08 * @Description: */public class FunctionTest { public static void main(String[] args) { FunctionTest function= new FunctionTest(); int res1 = function.compute(100, target -&gt; target * target); int res2 = function.compute(100, target -&gt; target + 1); System.out.println(res1); // 10000 System.out.println(res2); // 101 int res3 = function.pow(100); int res4 = function.addOne(100); System.out.println(res3); // 10000 System.out.println(res4); // 101 } public int compute(int a, Function&lt;Integer, Integer&gt; function) { return function.apply(a); } public int pow(int a) { return a * a; } public int addOne(int a) { return a + 1; }} 看看 #compute 这个方法，第二个参数传递的是行为，而不是具体的值。 我们本来要定义两个方法，pow 和 addOne 现在把这种行为传递进来。 （2）Function#compose 和 Function#andThen /** * Returns a composed function that first applies the {@code before} * function to its input, and then applies this function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of input to the {@code before} function, and to the * composed function * @param before the function to apply before this function is applied * @return a composed function that first applies the {@code before} * function and then applies this function * @throws NullPointerException if before is null * * @see #andThen(Function) */default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));}/** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null * * @see #compose(Function) */default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));} compose方法是一个默认方法，这个方法接收一个 function 作为参数，将参数 function 执行的结果作为参数给调用的 function，以此来实现两个function组合的功能。 andThen 方法也是接收一个 function 作为参数，与 compse 不同的是，先执行本身的 apply 方法，将执行的结果作为参数给参数中的 function。 /** * @Author: cuzz * @Date: 2019/8/20 23:59 * @Description: #compose and #andThen test */public class FunctionTest2 { public static void main(String[] args) { FunctionTest2 test = new FunctionTest2(); System.out.println(test.compute1(2, value -&gt; value * 2, value -&gt; value * value)); // 8 System.out.println(test.compute2(2, value -&gt; value * 2, value -&gt; value * value)); // 16 } public int compute1(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.compose(function2).apply(a); } public int compute2(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.andThen(function2).apply(a); }} 发现 compute1 是先执行第二个 Function 再执行第一，compute2 相反。 BiFunction先看源码 /** * Represents a function that accepts two arguments and produces a result. * This is the two-arity specialization of {@link Function}. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object, Object)}. * * @param &lt;T&gt; the type of the first argument to the function * @param &lt;U&gt; the type of the second argument to the function * @param &lt;R&gt; the type of the result of the function * * @see Function * @since 1.8 */@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u); /** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null */ default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t, U u) -&gt; after.apply(apply(t, u)); }} 我看一个例子 /** * @Author: cuzz * @Date: 2019/8/21 7:36 * @Description: */public class BiFunctionTest { public static void main(String[] args) { BiFunctionTest test = new BiFunctionTest(); // 加法 System.out.println(test.add(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a + b)); // 减法 System.out.println(test.subtract(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a - b)); } public int compute(int a, int b, BiFunction&lt;Integer, Integer, Integer&gt; biFunction) { return biFunction.apply(a, b); } public int add(int a, int b) { return a + b; } public int subtract(int a, int b) { return a - b; }} 以前我们定义一个四则运算需要需要先定义方法，现在通过 BiFunction 可以把这种行为传递进来。 Predicate（1）源码 /** * Represents a predicate (boolean-valued function) of one argument. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #test(Object)}. * * @param &lt;T&gt; the type of the input to the predicate * * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); /** * Returns a composed predicate that represents a short-circuiting logical * AND of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code false}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ANDed with this * predicate * @return a composed predicate that represents the short-circuiting logical * AND of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } /** * Returns a predicate that represents the logical negation of this * predicate. * * @return a predicate that represents the logical negation of this * predicate */ default Predicate&lt;T&gt; negate() { return (t) -&gt; !test(t); } /** * Returns a composed predicate that represents a short-circuiting logical * OR of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code true}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ORed with this * predicate * @return a composed predicate that represents the short-circuiting logical * OR of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); } /** * Returns a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)}. * * @param &lt;T&gt; the type of arguments to the predicate * @param targetRef the object reference with which to compare for equality, * which may be {@code null} * @return a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)} */ static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) { return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); }} （2）例子 以前我们根据不同的条件筛选数据需要些多个方法，现在只要先定义一个这种接受行为的方法。 /** * @Author: cuzz * @Date: 2019/8/21 23:35 * @Description: Predicate test */public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找奇数 test.findOdd(list); test.conditionFilter(list, i -&gt; i % 2 != 0); // 查找偶数 test.findEven(list); test.conditionFilter(list, i -&gt; i % 2 == 0); } public void conditionFilter(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) { for (int i : list) { if (predicate.test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findOdd(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 != 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findEven(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 == 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} （3）Predicate#and 和 Predicate#or public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找 大于 3 的奇数 test.conditionFilter2(list, i -&gt; i &gt; 3, i -&gt; i % 2 != 0); } public void conditionFilter2(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate1, Predicate&lt;Integer&gt; predicate2) { for (int i : list) { if (predicate1.and(predicate2).test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} Supplier（1）不接受参数，返回一个值。 /** * Represents a supplier of results. * * &lt;p&gt;There is no requirement that a new or distinct result be returned each * time the supplier is invoked. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #get()}. * * @param &lt;T&gt; the type of results supplied by this supplier * * @since 1.8 */@FunctionalInterfacepublic interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get();} （2）例子 /** * @Author: cuzz * @Date: 2019/8/22 23:32 * @Description: */public class SupplierTest { public static void main(String[] args) { Supplier&lt;Student&gt; supplier1 = () -&gt; new Student(); Supplier&lt;Student&gt; supplier2 = Student::new; }}@Dataclass Student { private String name = &quot;cuzz&quot;; private int age = 20;} Optional参考： 使用 Java 8 Optional 的正确姿势","link":"/2019/08/11/Java8%E7%9A%84%E6%B7%B1%E5%85%A5%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"title":"Netty 源码分析（一）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先看一个例子服务端MyServer 类 /** * @Author: cuzz * @Date: 2019/1/1 19:44 * @Description: */public class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} MyServerinitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:06 * @Description: */public class MyServerinitializer extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyServerHandler()); }} MyServerHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:23 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 客服端MyClient 类 /** * @Author: cuzz * @Date: 2019/1/1 20:31 * @Description: */public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new MyClientInitializer()); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }} MyClientInitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:40 * @Description: */public class MyClientInitializer extends ChannelInitializer&lt;SocketChannel&gt;{ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyClientHandler()); }} MyClientHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:42 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.writeAndFlush(&quot;from clinet: &quot; + UUID.randomUUID()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(&quot;来自客户端的连接！！！&quot;); }} 初始化EventLoopGroup创建一个 bossGroup 和 workGroup EventLoopGroup bossGroup = new NioEventLoopGroup();EventLoopGroup workGroup = new NioEventLoopGroup(); EventLoopGroup 翻译过来叫事件循环组，其本身就是一个死循环 bossGroup 是把接受连接，把连接转发给 workGroup ，workGroup 是真正完成用户请求处理的类 EventLoopGroup 是一个接口，在后面循环的过程中可以选择把 Channel 注册上 /** * Special {@link EventExecutorGroup} which allows registering {@link Channel}s that get * processed for later selection during the event loop. * */public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise);} NioEventLoopGroup// 他是一个基于NIO的选择器的对象 public class NioEventLoopGroup extends MultithreadEventLoopGroup { // 0 public NioEventLoopGroup() { this(0); } // 1 public NioEventLoopGroup(int nThreads) { this(nThreads, (Executor) null); } // 2 public NioEventLoopGroup(int nThreads, Executor executor) { this(nThreads, executor, SelectorProvider.provider()); }} MultithreadEventExecutorGroup最终会跳到MultithreadEventExecutorGroup 中的一个构造器中 protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { } // 1 if (executor == null) { executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); } children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { for (int j = 0; j &lt; i; j ++) { children[j].shutdownGracefully(); } for (int j = 0; j &lt; i; j ++) { EventExecutor e = children[j]; try { while (!e.isTerminated()) { e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); } } catch (InterruptedException interrupted) { // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; } } } } } chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() { @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception { if (terminatedChildren.incrementAndGet() == children.length) { terminationFuture.setSuccess(null); } } }; for (EventExecutor e: children) { e.terminationFuture().addListener(terminationListener); } Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); } ThreadPerTaskExecutor代码1中，executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());，跟进去 public final class ThreadPerTaskExecutor implements Executor { private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.threadFactory = threadFactory; } @Override public void execute(Runnable command) { threadFactory.newThread(command).start(); }} 这里用到了工厂方法和命令模式，通过传入一个command调用工厂方法 Executorpublic interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);} 这是在java.util.concurrent 下的一个接口，最主要的实现方式把一个task传入，新建一个线程运行 class ThreadPerTaskExecutor implements Executor { public void execute(Runnable r) { new Thread(r).start(); }} 也可以通过一系列的限制，比如序列化等一下操作 class SerialExecutor implements Executor { final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); final Executor executor; Runnable active; SerialExecutor(Executor executor) { this.executor = executor; } public synchronized void execute(final Runnable r) { tasks.offer(new Runnable() { public void run() { try { r.run(); } finally { scheduleNext(); } } }); if (active == null) { scheduleNext(); } } protected synchronized void scheduleNext() { if ((active = tasks.poll()) != null) { executor.execute(active); } }} 其中非常常用用的几个实现如：ExecutorService，ThreadPoolExecutor 下面是官方文档 The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors.The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors. 回顾一下 MyServer 中启动的代码 try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync();} finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully();} ServerBootstrappublic class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { ... } ServerBootstrap 是 Bootstrap子类，容易的地启动一个 ServerChannel ServerChannel接受一个即将到来的连接，创建子 Channel /** * A {@link Channel} that accepts an incoming connection attempt and creates * its child {@link Channel}s by accepting them. {@link ServerSocketChannel} is * a good example. */public interface ServerChannel extends Channel { // This is a tag interface.} 其有很多实现的子类，其中 NioServerSocketChannel 是我们比较关注的 方法链bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); .group(bossGroup, workGroup) 我们把 bossGroup 和 workGroup 传入进去，由于是方法链，肯定返回本身，跟踪下去 /** * Set the {@link EventLoopGroup} for the parent (acceptor) and the child (client). These * {@link EventLoopGroup}'s are used to handle all the events and IO for {@link ServerChannel} and * {@link Channel}'s. */public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup); if (childGroup == null) { throw new NullPointerException(&quot;childGroup&quot;); } if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; return this;} 这个步，就是给 bossGroup 和 workGroup 赋值给 ServerBootstrap 的实例 .channel(NioServerSocketChannel.class) 方法，接受的是一个 class 对象，一般接受 class 对象大多数与反射有关系 /** * The {@link Class} which is used to create {@link Channel} instances from. * You either use this or {@link #channelFactory(io.netty.channel.ChannelFactory)} if your * {@link Channel} implementation has no no-args constructor. */public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));} 进入 channelFactory 方法 /** * {@link io.netty.channel.ChannelFactory} which is used to create {@link Channel} instances from * when calling {@link #bind()}. This method is usually only used if {@link #channel(Class)} * is not working for you because of some more complex needs. If your {@link Channel} implementation * has a no-args constructor, its highly recommend to just use {@link #channel(Class)} for * simplify your code. */@SuppressWarnings({ &quot;unchecked&quot;, &quot;deprecation&quot; })public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) { return channelFactory((ChannelFactory&lt;C&gt;) channelFactory);} 如果有无参数的构造方法推荐使用，这样可以简化代码 Q：为什么必须要有无参数构造方法呢？ A : 一般来说，获取一个实例如下生成，所以必须有无参数构造方法 Class class = Class.forName(className);Object object = class.newInstance(); // 只能调用无参构造函数 我们在来看看 NioServerSocketChannel A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses NIO selector based implementation to accept new connections. .childHandler(new MyServerinitializer()); 设置用于请求的 Handler /** * Set the {@link ChannelHandler} which is used to serve the request for the {@link Channel}'s. */public ServerBootstrap childHandler(ChannelHandler childHandler) { if (childHandler == null) { throw new NullPointerException(&quot;childHandler&quot;); } this.childHandler = childHandler; return this;} 这里其实有 handler 和 childHandler 一个是给 bossGroup 使用的，一个是给 workGroup 使用的 启动ChannelFuture channelFuture = bootstrap.bind(8899).sync(); ChannelFutureChannelFuture 先是继承了自己提供的 Future ，自身的 Future 又继承 java.util.concurrent.Future&lt;V&gt; ，我们先看看 JUC 中 Future 和 FutureTask JUC.Future看看其中几个主要的方法，从方法名也知道是做什么的 public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} 文档： A Future represents the result of an asynchronous computation. Methods are provided to check if the computation is complete, to wait for its completion, and to retrieve the result of the computation. The result can only be retrieved using method get when the computation has completed, blocking if necessary until it is ready. Cancellation is performed by the cancel method. Additional methods are provided to determine if the task completed normally or was cancelled. Once a computation has completed, the computation cannot be cancelled. If you would like to use a Future for the sake of cancellability but not provide a usable result, you can declare types of the form Future&lt;?&gt; and return null as a result of the underlying task. 使用： interface ArchiveSearcher { String search(String target); }class App { ExecutorService executor = ... ArchiveSearcher searcher = ... void showSearch(final String target) throws InterruptedException { Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); } }); displayOtherThings(); // do other things while searching try { displayText(future.get()); // use future } catch (ExecutionException ex) { cleanup(); return; } }} JUC.FutureTask The FutureTask class is an implementation of Future that implements Runnable, and so may be executed by an Executor. For example, the above construction with submit could be replaced by: FutureTask&lt;String&gt; future = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); }});executor.execute(future); 可以通过 Executor 的实例去执行，最后再从 future 中获取 Netty.Futurepublic interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; { boolean isSuccess(); boolean isCancellable(); Throwable cause(); /** * Adds the specified listener to this future. The * specified listener is notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listener is notified immediately. */ Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Adds the specified listeners to this future. The * specified listeners are notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listeners are notified immediately. */ Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); /** * Removes the first occurrence of the specified listener from this future. * The specified listener is no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listener is not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Removes the first occurrence for each of the listeners from this future. * The specified listeners are no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listeners are not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 等待Future完成 Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); @Override boolean cancel(boolean mayInterruptIfRunning);} 我们主要看看 xxListener 方法，一后缀为 Listener 使用了观察者模式 它比 JUC.Future 更厉害的是就因为这个 Listener ，虽然 JUC.Future 可以调用 get() 方法，获取异步结果，但是我们不知道什么时候去调用，调用早了就堵塞在那里；而 Netty.Future 使用了观察者模式，当完成时会自动触发 ChannelFuture我们回到 ChannelFuture ，都重写了 Netty.Future 中的方法，返回值是 Future 的子类，java5或者以前，必须一样，java7以后可以不同，但是必须是父类返回值的派生类 public interface ChannelFuture extends Future&lt;Void&gt; { /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); 文档： io.netty.channelpublic interface ChannelFutureextends Future The result of an asynchronous Channel I/O operation. All I/O operations in Netty are asynchronous. It means any I/O calls will return immediately with no guarantee that the requested I/O operation has been completed at the end of the call. Instead, you will be returned with a ChannelFuture instance which gives you the information about the result or status of the I/O operation. A ChannelFuture is either uncompleted or completed. When an I/O operation begins, a new future object is created. The new future is uncompleted initially - it is neither succeeded, failed, nor cancelled because the I/O operation is not finished yet. If the I/O operation is finished either successfully, with failure, or by cancellation, the future is marked as completed with more specific information, such as the cause of the failure. Please note that even failure and cancellation belong to the completed state. +---------------------------+ | Completed successfully | +---------------------------+ +----&gt; isDone() = true |+--------------------------+ | | isSuccess() = true || Uncompleted | | +===========================++--------------------------+ | | Completed with failure || isDone() = false | | +---------------------------+| isSuccess() = false |----+----&gt; isDone() = true || isCancelled() = false | | | cause() = non-null || cause() = null | | +===========================++--------------------------+ | | Completed by cancellation | | +---------------------------+ +----&gt; isDone() = true | | isCancelled() = true | +---------------------------+ Various methods are provided to let you check if the I/O operation has been completed, wait for the completion, and retrieve the result of the I/O operation. It also allows you to add ChannelFutureListeners so you can get notified when the I/O operation is completed. 推荐使用监听器而不是等待的方法 // BAD - NEVER DO THIS@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.awaitUninterruptibly(); // Perform post-closure operation // ...}// GOOD@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { // Perform post-closure operation // ... } });} 不要混淆连接超时和等待超时 // BAD - NEVER DO THISBootstrap b = ...;ChannelFuture f = b.connect(...);f.awaitUninterruptibly(10, TimeUnit.SECONDS);if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { // You might get a NullPointerException here because the future // might not be completed yet. f.cause().printStackTrace();} else { // Connection established successfully}// GOODBootstrap b = ...;// Configure the connect timeout option.b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000);ChannelFuture f = b.connect(...);f.awaitUninterruptibly();// Now we are sure the future is completed.assert f.isDone();if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { f.cause().printStackTrace();} else { // Connection established successfully} bind()方法当我们调用 bind 方法时，才真正的启动服务器 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 通过一些判断最终到 doBind 方法上 private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; }} initAndRegister()方法这个主要是初始化和注册，比较复杂，后续在分析 加油！！！","link":"/2019/01/03/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Netty 源码分析（三）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. addLast 方法io.netty.channel.DefaultChannelPipeline#addLast @Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // 是把 ChannelHandlerContext 添加进去 // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } callHandlerAdded0(newCtx); return this;} AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系 这篇文章写的很清楚 https://blog.csdn.net/u010853261/article/details/54574440 ChannelHandlerContext每个ChannelHandler被添加到ChannelPipeline后，都会创建一个ChannelHandlerContext并与之创建的ChannelHandler关联绑定。ChannelHandlerContext允许ChannelHandler与其他的ChannelHandler实现进行交互。ChannelHandlerContext不会改变添加到其中的ChannelHandler，因此它是安全的 下图显示了ChannelHandlerContext、ChannelHandler、ChannelPipeline的关系： 最后我们看到 private void addLast0(AbstractChannelHandlerContext newCtx) { AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;} 我们的双向链表链表维护的是 ChannelHandlerContext 对象，而ChannelHandlerContext 包装了 ChannelHandler 我们回到 addLast 方法上 p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); }}); 进入 ChannelInitializer 类中，我们看 #initChannel 方法，说这个方法当 Channel 注册时会被调用，一旦掉用完就会被移除 ChannelPipeline，这是因为只需要把里面封装的 Handler 添加到 ChannelPipeline，因为他本身就不一个 Handler io.netty.channel.ChannelInitializerprotected abstract void initChannel(C ch) This method will be called once the Channel was registered. After the method returns this instance will be removed from the ChannelPipeline of the Channel. 下面是移除代码 private boolean initChannel(ChannelHandlerContext ctx) throws Exception { if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) { // Guard against re-entrance. try { initChannel((C) ctx.channel()); } catch (Throwable cause) { // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); } finally { remove(ctx); } return true; } return false;}private void remove(ChannelHandlerContext ctx) { try { ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { pipeline.remove(this); } } finally { initMap.remove(ctx); }} ChannelHandlerContext.attr(..) == Channel.attr(..)https://netty.io/wiki/new-and-noteworthy-in-4.1.html Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute ‘KEY_X’ via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory. To address this issue, we decided to keep only one map per Channel internally. AttributeMap always uses AttributeKey as its key. AttributeKey ensures uniqueness between each key, and thus there’s no point of having more than one attribute map per Channel. As long as a user defines its own AttributeKey as a private static final field of his or her ChannelHandler, there will be no risk of duplicate keys. 注意：现在这两个关联的是一个Map callHandlerCallbackLater 我们回到 #addLast 方法上，这个时候是还没有注册的，进入这个 #callHandlerCallbackLater 方法，把稍后调用 Handler 回调，封装成一个 task private void callHandlerCallbackLater(AbstractChannelHandlerContext ctx, boolean added) { assert !registered; PendingHandlerCallback task = added ? new PendingHandlerAddedTask(ctx) : new PendingHandlerRemovedTask(ctx); PendingHandlerCallback pending = pendingHandlerCallbackHead; if (pending == null) { pendingHandlerCallbackHead = task; } else { // Find the tail of the linked-list. while (pending.next != null) { pending = pending.next; } pending.next = task; }} 注册我们回到io.netty.bootstrap.AbstractBootstrap#initAndRegister final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } 前面的初始化初始化已经有一点的了解，现在我来看注册，这里有#config，#group 和 #register 这三个方法，我们一个一个分析 ChannelFuture regFuture = config().group().register(channel); config 方法/** * Returns the {@link AbstractBootstrapConfig} object that can be used to obtain the current config * of the bootstrap. */public abstract AbstractBootstrapConfig&lt;B, C&gt; config(); 返回了一个 ServerbootstrapConfig 对象 group 方法/** * Returns the configured {@link EventLoopGroup} or {@code null} if non is configured yet. */@SuppressWarnings(&quot;deprecation&quot;)public final EventLoopGroup group() { return bootstrap.group();} 返回一个 NioEventLoopGroup 对象，这个时候返回的是一个调用的是他的父类MultithreadEventLoopGroup的 register 方法io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel) 最终会调用 io.netty.channel.SingleThreadEventLoop#register(io.netty.channel.Channel) 的注册方法 我们来看看这个类 io.netty.channel.SingleThreadEventLoop io.netty.channelpublic abstract class SingleThreadEventLoopextends SingleThreadEventExecutorimplements EventLoopAbstract base class for EventLoops that execute all its submitted tasks in a single thread. io.netty.channel.AbstractChannel.AbstractUnsafe#register @Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(&quot;eventLoop&quot;); } if (isRegistered()) { promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); return; } if (!isCompatible(eventLoop)) { promise.setFailure( new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); return; } AbstractChannel.this.eventLoop = eventLoop; // 如果是当前线程就让它执行 if (eventLoop.inEventLoop()) { register0(promise); // 如果不是的话就放到线程池中注册 } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } }} 先理解一下线程 Netty 中的线程模型 一个 EventLoopGroup 当中会包含多个 EventLoop 一个 EventLoop 在它的整个生命周期当中都只会与唯一一个 Thread 进行绑定 所有 EventLoop 所处理的各种 I/O 事件都是将在他所关联的那个 Thread 上进行处理 一个 Channel 在它的整个生命周期中只会注册在一个 EventLoop 上 一个 EventLoop 在运行过程中，会被分配给一或者多个 Channel 重要结论： 在Netty 中 Channel 的实现是线程安全的，基于此，我们可以存储一个 Channel 的引用，并且在需要向远程端点发送数据时，通过这个引用来调用 Channel 相应的方法，即便是当时有很多线程都在使用它也不会出现多线程的问题，而且消息一点会按照这个顺序发送出去 我们在业务开发中，不要将执行耗时的任务放入到 EventLoop 的执行队列中，因为它会堵塞该线程的所有Channel 上的其它执行任务，如果我们需要进行阻塞调用或则是耗时操作，那么我们需要使用一个专门的EventExectutor(业务线程池) 通常会有两种实现方式： 在 ChannelHandler 的回调方法中，使用自己定义的业务线程池，这样就可以实现异步调用 借助于 Netty 提供的向 ChannelPipeline 添加ChannelHandler是调用的addLast方法来传递 EventExecutorGroup 说明：如果addLast(handler)的方法是由I/O线程所执行的，如果addLast(eventExectutorGroup, handler)的方法，那么就是由参数中的group的线程组来执行 io.netty.channel.AbstractChannel.AbstractUnsafe#register0 private void register0(ChannelPromise promise) { try { // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; doRegister(); // 这个方法 neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); }} io.netty.channel.nio.AbstractNioChannel#doRegister 看到 doXxx 开头的方法就知道是认真工作的 @Overrideprotected void doRegister() throws Exception { boolean selected = false; for (;;) { try { selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } }} 与我们前面写的 NIO 逻辑是一样的 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); syncpublic class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, false) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} 我们回到我们编写的 Server 中，需要绑定，之后需要调用 #sync 表示这个方法需要同步，要不然还没绑定完成就返回了 ChannelFuture ，里面的结果或者状态是还没有完成的，加了 #sync 就能保证完成 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 在我们正常开发是流程就会停在下面，就卡住了 channelFuture.channel().closeFuture().sync(); 当我们调用关闭就会到 finally 中，会执行优雅关闭 到此我们启动过程基本分析完了","link":"/2019/01/16/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Netty 源码分析（五）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ReferenceCountedio.netty.util.ReferenceCounted 引用计数文档 public interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. 我们看看其中的方法 public interface ReferenceCounted { /** * Returns the reference count of this object. If {@code 0}, it means this object has been deallocated. */ int refCnt(); /** * Increases the reference count by {@code 1}. */ ReferenceCounted retain(); /** * Increases the reference count by the specified {@code increment}. */ ReferenceCounted retain(int increment); /** * Records the current access location of this object for debugging purposes. * If this object is determined to be leaked, the information recorded by this operation will be provided to you * via {@link ResourceLeakDetector}. This method is a shortcut to {@link #touch(Object) touch(null)}. */ ReferenceCounted touch(); /** * Records the current access location of this object with an additional arbitrary information for debugging * purposes. If this object is determined to be leaked, the information recorded by this operation will be * provided to you via {@link ResourceLeakDetector}. */ ReferenceCounted touch(Object hint); /** * Decreases the reference count by {@code 1} and deallocates this object if the reference count reaches at * {@code 0}. * * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated */ boolean release(); /** * Decreases the reference count by the specified {@code decrement} and deallocates this object if the reference * count reaches at {@code 0}. * * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated */ boolean release(int decrement);} AbstractReferenceCountedByteBufio.netty.buffer.AbstractReferenceCountedByteBuf 我们先来看两个比较重要的方法，retain() 和 release() 方法 retain()io.netty.buffer.AbstractReferenceCountedByteBuf#retain() retain() 方法可以使引用计数加一 @Overridepublic ByteBuf retain() { return retain0(1);}@Overridepublic ByteBuf retain(int increment) { return retain0(checkPositive(increment, &quot;increment&quot;));}private ByteBuf retain0(int increment) { for (;;) { int refCnt = this.refCnt; final int nextCnt = refCnt + increment; // 如果 refCnt = 0 的时候 nextCont = increment，就就应该被回收 // Ensure we not resurrect (which means the refCnt was 0) and also that we encountered an overflow. if (nextCnt &lt;= increment) { throw new IllegalReferenceCountException(refCnt, increment); } // 这里使用到了自旋锁 if (refCntUpdater.compareAndSet(this, refCnt, nextCnt)) { break; } } return this;} java.util.concurrent.atomic.AtomicIntegerFieldUpdater public abstract class AtomicIntegerFieldUpdaterextends ObjectA reflection-based utility that enables atomic updates to designated volatile int fields of designated classes. This class is designed for use in atomic data structures in which several fields of the same node are independently subject to atomic updates.Note that the guarantees of the compareAndSet method in this class are weaker than in other atomic classes. Because this class cannot ensure that all uses of the field are appropriate for purposes of atomic access, it can guarantee atomicity only with respect to other invocations of compareAndSet and set on the same updater. AtomicIntegerFieldUpdater要点的总结： 更新器必须是int类型的变量，不能是其他包装类型 更新器的更新必须是volatile类型的变量，确保线程之间的共享变量时的立即可见性 变量不能是static的，必须是实例变量，因为Unsafe.objectFieldOffset() 方法不支持静态变量（CAS操作本质是通过对象实例的偏移来直接进行赋值） 更新器只能修改它可见范围内的变量，因为更新器是通过反射来得到这个变量，如果变量不可见就会报错 如果更新的变量时包装类型，那么可以使用AtomicReferenceFieldUpdater来进行更新 java.util.concurrent.atomic.AtomicIntegerFieldUpdater#compareAndSet public abstract boolean compareAndSet(T obj, int expect, int update)Atomically sets the field of the given object managed by this updater to the given updated value if the current value == the expected value. This method is guaranteed to be atomic with respect to other calls to compareAndSet and set, but not necessarily with respect to other changes in the field.Parameters:obj - An object whose field to conditionally setexpect - the expected valueupdate - the new value 一个不安全的更新 /** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest { public static void main(String[] args) { Person person = new Person(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(person.age++ + &quot; &quot;); // 1 6 7 5 4 2 3 1 8 9 }).start(); } }}class Person{ int age = 1;} 使用AtomicIntegerFieldUpdater /** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest { public static void main(String[] args) { AtomicIntegerFieldUpdater&lt;Person&gt; fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Person.class, &quot;age&quot;); Person person = new Person(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(fieldUpdater.getAndIncrement(person) + &quot; &quot;); // 1 4 3 2 5 6 7 10 9 8 }).start(); } }}class Person{ volatile int age = 1;} 大概有以下两种字段适合用Atomic*FieldUpdater: 大多数用到这个字段的代码是在读取字段的值, 但仍然有通过CAS更新字段值的需求. 这个时候用AtomicInteger的话每个直接读取这个字段的地方都要多一次.get()调用, 用volatile又满足不了需求, 所以就用到了AtomicIntegerFieldUpdater 这个字段所属的类会被创建大量的实例对象, 如果用AtomicInteger, 每个实例里面都要创建AtomicInteger对象, 从而多出内存消耗. 比如一个链表类的Node, 用AtomicReference保存next显然是不合适的. 原文：https://blog.csdn.net/u012415542/article/details/80646605 private static final AtomicIntegerFieldUpdater&lt;AbstractReferenceCountedByteBuf&gt; refCntUpdater = AtomicIntegerFieldUpdater.newUpdater(AbstractReferenceCountedByteBuf.class, &quot;refCnt&quot;); Reference counted objects引用计数文档：Reference counted objects Netty 处理器重要概念 Netty 的处理器可以分为两类：入站处理器和出站处理器 入站处理器的顶层是 ChannelnboundHandler，出站处理器的顶层是 ChannelOutboundHandler 数据处理时常用的各种解码器本质上都是处理器 编解码器：无论我们向网络中写入的数据是什么类型，数据在网络中传递时，其都是以字节流的形式呈现，将数据有原本的字节流的操作成为编码（encode），将数据有字节转化为它原本的格式或是其它的操作成为解码（decode），编码统一称为（codec） 编码：本质上是一种出站处理器，因此，编码一定是一种 ChannelOutboundHandler 解码：本质上是一种入站处理器，因此，解码一定是一种 ChannelInboundHandler 在 Netty 中，编码器通常以 xxxEncoder命名；解码器通常以xxxDecoder命名 编写一个Long类型的解码器编写一个解码器在客服端与服务端传输一个 Long 型的数据，Netty 为我们提供了 ByteToMessageDecoder io.netty.handler.codec.ByteToMessageDecoder io.netty.handler.codecpublic abstract class ByteToMessageDecoderextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which decodes bytes in a stream-like fashion from one ByteBuf to an other Message type. For example here is an implementation which reads all readable bytes from the input ByteBuf and create a new ByteBuf. public class SquareDecoder extends ByteToMessageDecoder { @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { out.add(in.readBytes(in.readableBytes())); } } Frame detectionGenerally frame detection should be handled earlier in the pipeline by adding a DelimiterBasedFrameDecoder, FixedLengthFrameDecoder, LengthFieldBasedFrameDecoder, or LineBasedFrameDecoder.If a custom frame decoder is required, then one needs to be careful when implementing one with ByteToMessageDecoder. Ensure there are enough bytes in the buffer for a complete frame by checking ByteBuf.readableBytes(). If there are not enough bytes for a complete frame, return without modifying the reader index to allow more bytes to arrive.To check for complete frames without modifying the reader index, use methods like ByteBuf.getInt(int). One MUST use the reader index when using methods like ByteBuf.getInt(int). For example calling in.getInt(0) is assuming the frame starts at the beginning of the buffer, which is not always the case. Use in.getInt(in.readerIndex()) instead.PitfallsBe aware that sub-classes of ByteToMessageDecoder MUST NOT annotated with @Sharable.Some methods such as ByteBuf.readBytes(int) will cause a memory leak if the returned buffer is not released or added to the out List. Use derived buffers like ByteBuf.readSlice(int) to avoid leaking memory. MyByteToLongDecoder /** * @Author: cuzz * @Date: 2019/1/22 12:16 * @Description: */public class MyByteToLongDecoder extends ByteToMessageDecoder{ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;decode invoked!&quot;); System.out.println(in.readableBytes()); if (in.readableBytes() &gt;= 8) { out.add(in.readLong()); } }} MyLongToByteEncoder /** * @Author: cuzz * @Date: 2019/1/22 12:23 * @Description: */public class MyLongToByteEncoder extends MessageToByteEncoder&lt;Long&gt;{ @Override protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception { System.out.println(&quot;encoder invoked!&quot;); System.out.println(msg); out.writeLong(msg); }} 重要结论： 无论是编码器还是解码器，其所接收的消息类型必须要与待处理的参数保持一致，否则该编码器或则解码器不会被执行 在解码器进行数据解码时，一定要记得判断缓冲（ByteBuf）中的数据是否足够，否则将会产生一些问题 ReplayingDecoder文档：https://netty.io/4.1/api/io/netty/handler/codec/ReplayingDecoder.html 如果我们使用这个继承这个编码器，他会自动帮我判断是否可读，代码也简单，简化了我们的判断 public class MyByteToLongDecoder2 extends ReplayingDecoder&lt;Void&gt; { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;MyByteToLongDecoder2 decode invoked!&quot;); out.add(in.readLong()); }} LengthFieldBasedFrameDecoderio.netty.handler.codec.LengthFieldBasedFrameDecoder 文档：https://netty.io/4.1/api/io/netty/handler/codec/LengthFieldBasedFrameDecoder.html 这是一个常用语自定义协议的解码器 TCP 粘包拆包如果我写的自定义协议没有对粘包和拆包做特殊处理的话就会产生粘包和拆包现象 粘包、拆包发生原因发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。粘包、拆包解决办法通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 作者：wxy941011来源：CSDN原文：https://blog.csdn.net/wxy941011/article/details/80428470版权声明：本文为博主原创文章，转载请附上博文链接！ 自定义协议解决粘包和拆包一个 Person 协议类 /** * @Author: cuzz * @Date: 2019/1/22 16:00 * @Description: 这是一个关于 Person 的协议 */public class PersonProtocol { private int length; private byte[] content; public int getLength() { return length; } public void setLength(int length) { this.length = length; } public byte[] getContent() { return content; } public void setContent(byte[] content) { this.content = content; }} 解码处理器 /** * @Author: cuzz * @Date: 2019/1/22 16:04 * @Description: */public class MyPersonDecoder extends ReplayingDecoder&lt;Void&gt;{ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;MyPersonDecoder decode invoked!&quot;); // Gets a 32-bit integer at the current {@code readerIndex} // and increases the {@code readerIndex} by {@code 4} in this buffer. int length = in.readInt(); byte[] content = new byte[length]; // Transfers this buffer's data to the specified destination starting at // the current {@code readerIndex} and increases the {@code readerIndex} // by the number of the transferred bytes (= {@code dst.length} in.readBytes(content); // 把内容添加到协议中 PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(length); personProtocol.setContent(content); out.add(personProtocol); }} 编码处理器 /** * @Author: cuzz * @Date: 2019/1/22 16:12 * @Description: */public class MyPersonEncoder extends MessageToByteEncoder&lt;PersonProtocol&gt;{ @Override protected void encode(ChannelHandlerContext ctx, PersonProtocol msg, ByteBuf out) throws Exception { System.out.println(&quot;MyPersonEncoder encoder invoked!&quot;); // 消息头 out.writeInt(msg.getLength()); // 消息体 out.writeBytes(msg.getContent()); }} 服务端 /** * @Author: cuzz * @Date: 2019/1/22 16:39 * @Description: */public class MyServer { public static void main(String[] args) throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyServerHandler()); } }); ChannelFuture channelFuture = serverBootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); } }}/** * @Author: cuzz * @Date: 2019/1/22 16:16 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;{ private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception { int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println(&quot;服务端接收到的数据：&quot;); System.out.println(&quot;长度：&quot; + length); System.out.println(&quot;内容：&quot; + new String(content, Charset.forName(&quot;utf-8&quot;))); System.out.println(&quot;服务器接收到的消息数量：&quot; + (++this.count)); PersonProtocol personProtocol = new PersonProtocol(); String resp = &quot;hello, world&quot;; personProtocol.setLength(resp.getBytes(&quot;utf-8&quot;).length); personProtocol.setContent(resp.getBytes(&quot;utf-8&quot;)); ctx.writeAndFlush(personProtocol); }} 客服端 public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyClientHandler()); } }); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }}/** * @Author: cuzz * @Date: 2019/1/22 16:25 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;{ private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception { int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println(&quot;客户端接收的消息：&quot;); System.out.println(&quot;消息的长度：&quot; + length); System.out.println(&quot;消息的内容：&quot; + new String(content, Charset.forName(&quot;utf-8&quot;))); System.out.println(&quot;客户端接收到的消息数量：&quot; + (++count)); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { for (int i = 0; i &lt; 10; i++) { String messageToBeSend = &quot;send form client&quot;; PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(messageToBeSend.getBytes(&quot;utf-8&quot;).length); personProtocol.setContent(messageToBeSend.getBytes(&quot;utf-8&quot;)); ctx.writeAndFlush(personProtocol); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 总结这里关于 Netty 的这五篇分析都是看的圣思园张龙老师的课程自己所写下的笔记，自己对 Netty 有了简单的认识，也对 NIO 有了更深的了解，最主要的学会看英文文档，看官方文档很重要，不要惧怕，慢慢的就感觉还是文档写的最清楚，最有价值。老师还提到需要多记录，因此我也把一些重要的知识点记录下来，方便以后查找。当然以后还要加强学习，多看看 Netty 官方文档和例子，加强练习。","link":"/2019/01/22/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89/"},{"title":"Netty 源码分析（四）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ChannelPromiseio.netty.channel.ChannelPromise 前面我们分析了 ChannelFuture ，看看ChannelPromise 的作用 /** * Special {@link ChannelFuture} which is writable. */public interface ChannelPromise extends ChannelFuture, Promise&lt;Void&gt; { ... } 这是一个可以写入的 ChannelFuture ，我先看看 Promise 这个类 Promiseio.netty.util.concurrent.Promise public interface Promise&lt;V&gt; extends Future&lt;V&gt; { /** * Marks this future as a success and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setSuccess(V result); /** * Marks this future as a success and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a success. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean trySuccess(V result); /** * Marks this future as a failure and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setFailure(Throwable cause); /** * Marks this future as a failure and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a failure. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean tryFailure(Throwable cause); /** * Make this future impossible to cancel. * * @return {@code true} if and only if successfully marked this future as uncancellable or it is already done * without being cancelled. {@code false} if this future has been cancelled already. */ boolean setUncancellable(); @Override Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; await() throws InterruptedException; @Override Promise&lt;V&gt; awaitUninterruptibly(); @Override Promise&lt;V&gt; sync() throws InterruptedException; @Override Promise&lt;V&gt; syncUninterruptibly();} JDK 所提供的的 Future 只能通过手工的方式检查执行结果，而这个操作是会阻塞的；Netty 则对 ChannelFutre 进行了增强，通过 ChannelFutureListener 以回调的方式来获取执行结果，去除了手工检查阻塞的操作，值得注意的是，ChannelFutrureListener 的 operationComplete 方法是由I/O线程执行的，因此要注意的是不要在这里执行耗时操作，否则需要通过另外的线程或线程池来执行 ChannelInboundHandlerAdapterio.netty.channel.ChannelInboundHandlerAdapter io.netty.channelpublic class ChannelInboundHandlerAdapterextends ChannelHandlerAdapter implements ChannelInboundHandlerAbstract base class for ChannelInboundHandler implementations which provide implementations of all of their methods. This implementation just forward the operation to the next ChannelHandler in the ChannelPipeline. Sub-classes may override a method implementation to change this. Be aware that messages are not released after the channelRead(ChannelHandlerContext, Object) method returns automatically. If you are looking for a ChannelInboundHandler implementation that releases the received messages automatically, please see SimpleChannelInboundHandler. 这里使用了适配器模式 ChannelInboundHandlerio.netty.channel.ChannelInboundHandler /** * {@link ChannelHandler} which adds callbacks for state changes. This allows the user * to hook in to state changes easily. */public interface ChannelInboundHandler extends ChannelHandler { /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered with its {@link EventLoop} */ void channelRegistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was unregistered from its {@link EventLoop} */ void channelUnregistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} is now active */ void channelActive(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered is now inactive and reached its * end of lifetime. */ void channelInactive(ChannelHandlerContext ctx) throws Exception; /** * Invoked when the current {@link Channel} has read a message from the peer. */ void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; /** * Invoked when the last message read by the current read operation has been consumed by * {@link #channelRead(ChannelHandlerContext, Object)}. If {@link ChannelOption#AUTO_READ} is off, no further * attempt to read an inbound data from the current {@link Channel} will be made until * {@link ChannelHandlerContext#read()} is called. */ void channelReadComplete(ChannelHandlerContext ctx) throws Exception; /** * Gets called if an user event was triggered. */ void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; /** * Gets called once the writable state of a {@link Channel} changed. You can check the state with * {@link Channel#isWritable()}. */ void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; /** * Gets called if a {@link Throwable} was thrown. */ @Override @SuppressWarnings(&quot;deprecation&quot;) void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;} SimpleChannelInboundHandlerio.netty.channel.SimpleChannelInboundHandler 我们在写自己的 Handler 的时候长会继承这个 SimpleChannelInboundHandler public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 我们看看这个文档 io.netty.channelpublic abstract class SimpleChannelInboundHandlerextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which allows to explicit only handle a specific type of messages. For example here is an implementation which only handle String messages. public class StringHandler extends SimpleChannelInboundHandler&lt;String&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String message) throws Exception { System.out.println(message); }} Be aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.Forward compatibility notice 我们可以通过泛型指定消息类型 @Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { boolean release = true; try { if (acceptInboundMessage(msg)) { @SuppressWarnings(&quot;unchecked&quot;) I imsg = (I) msg; channelRead0(ctx, imsg); } else { release = false; ctx.fireChannelRead(msg); } } finally { if (autoRelease &amp;&amp; release) { // 把这个消息计数减一，当减为0就丢弃 ReferenceCountUtil.release(msg); } }}/** * &lt;strong&gt;Please keep in mind that this method will be renamed to * {@code messageReceived(ChannelHandlerContext, I)} in 5.0.&lt;/strong&gt; * * Is called for each message of type {@link I}. * * @param ctx the {@link ChannelHandlerContext} which this {@link SimpleChannelInboundHandler} * belongs to * @param msg the message to handle * @throws Exception is thrown if an error occurred */protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception; 给我们强制转换为特定的类型，再调用 channelRead0 方法，这是一个抽象方法，需要我们自己去实现 ReferenceCountedio.netty.util.ReferenceCounted io.netty.utilpublic interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. ctx.channel().write()和ctx.write()的区别在 Netty 中有两种发消息的方式，可以直接写到 Channel 中，也可以写到与 ChannelHandler 所关联的那个 ChannelHandlerContext 中，对于 ctx.channel().write() 方式来说，消息会从 ChannelPipeline 的末尾开始流动，对于 ctx.write() 来说，消息将从 ChannelPipeline 中的下一个 ChannelHandler 开始流动 这篇博客个解释了 https://blog.csdn.net/FishSeeker/article/details/78447684 结论： ChannelHandlerContext 与 ChannelHandler 之间的关联绑定关系是永远不会发生改变的，因此对其进行缓存时没有任何问题的 对于与 Channel 的同名方法来说， ChannelHandlerContext 的方法将会产生更短的事件流，所以我们因该在可能的情况下利用这个特性来提升性能 Java NIONIO 总结使用 NIO 进行文件读取所涉及的步骤： 从 FileInputStream 对象获取到 Channel 对象 创建 Buffer 将数据从 Channel 中读取到Buffer中 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity flip() 方法： 将 limit 值设置为当前的 position 将 position 设置 0 clear() 方法： 将 limit 设置为capacity 将 position 设置为0 compact() 方法： 将所有未读的数据复制到 buffer 起始的位置处 将 position 设置为最后一个未读元素的后面 将 limit 设置为 capacity 现在buffer 就准备好了，但是不会覆盖未读的数据 Java NIO中，关于DirectBuffer，HeapBuffer的疑问？ DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 答案： https://www.zhihu.com/question/57374068/answer/152691891 Java NIO中的direct buffer（主要是DirectByteBuffer）其实是分两部分的： Java | native |DirectByteBuffer | malloc'd[ address ] -+-&gt; [ data ] | 其中 DirectByteBuffer 自身是一个Java对象，在Java堆中；而这个对象中有个long类型字段address，记录着一块调用 malloc() 申请到的native memory。 所以回到题主的问题： \\1. DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ DirectByteBuffer 自身是（Java）堆内的，它背后真正承载数据的buffer是在（Java）堆外——native memory中的。这是 malloc() 分配出来的内存，是用户态的。 \\2. FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 题主看的是OpenJDK的 sun.nio.ch.IOUtil.write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) 的实现对不对： static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException{ if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try { bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) { // now update src src.position(pos + n); } return n; } finally { Util.offerFirstTemporaryDirectBuffer(bb); }} 这里其实是在迁就OpenJDK里的HotSpot VM的一点实现细节。 HotSpot VM里的GC除了CMS之外都是要移动对象的，是所谓“compacting GC”。 如果要把一个Java里的 byte[] 对象的引用传给native代码，让native代码直接访问数组的内容的话，就必须要保证native代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。 可惜HotSpot VM出于一些取舍而决定不实现单个对象层面的object pinning，要pin的话就得暂时禁用GC——也就等于把整个Java堆都给pin住。HotSpot VM对JNI的Critical系API就是这样实现的。这用起来就不那么顺手。 所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的I/O可能是一个很慢的操作。 于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的native memory去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生GC的，虽然实现方式跟JNI的Critical系API不太一样。（具体来说是 Unsafe.copyMemory() 是HotSpot VM的一个intrinsic方法，中间没有safepoint所以GC无法发生）。 然后数据被拷贝到native memory之后就好办了，就去做真正的I/O，把 DirectByteBuffer 背后的native memory地址传给真正做I/O的函数。这边就不需要再去访问Java对象去读写要做I/O的数据了。 ByteBuf文档：https://netty.io/4.1/api/index.html 我们看第一个例子 public class ByteBufTest01 { public static void main(String[] args) { final ByteBuf buffer = Unpooled.buffer(10); for (int i = 0, index = 120; i &lt; 10; i++) { buffer.writeByte(index + i); } for (int i = 0; i &lt; 10; i++) { System.out.println(buffer.getByte(i)); } }} 输出： 120121122123124125126127-128-127 我们来看看这个方法的文档 /** * Sets the specified byte at the current {@code writerIndex} * and increases the {@code writerIndex} by {@code 1} in this buffer. * The 24 high-order bits of the specified value are ignored. * * @throws IndexOutOfBoundsException * if {@code this.writableBytes} is less than {@code 1} */public abstract ByteBuf writeByte(int value); 虽然传入的一个 int 值，可是它会丢弃高位的 24 bit，我们知道 int 是 4 字节（32 bit），丢弃 3 字节 （24 bit），就保留到 1 字节（8 bit） 我们要看下一个例子 public class ByteBufTest02 { public static void main(String[] args) { ByteBuf byteBuf = Unpooled.copiedBuffer(&quot;hello world&quot;, Charset.forName(&quot;utf-8&quot;)); // 判断是否为堆缓存，如果是堆缓存，返回true if (byteBuf.hasArray()) { byte[] bytes = byteBuf.array(); System.out.println(new String(bytes, Charset.forName(&quot;utf-8&quot;))); System.out.println(byteBuf); System.out.println(byteBuf.arrayOffset()); // 可读字节第一偏移量 System.out.println(byteBuf.readerIndex()); System.out.println(byteBuf.writerIndex()); System.out.println(byteBuf.capacity()); } }} 输出： hello world UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 11, cap: 33)001133 ridx 表示读的 index，widx 表示写的 index 我们来看看复合 Buffer public class ByteBufTest03 { public static void main(String[] args) { // 新建一个复合 buffer CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer(); ByteBuf heapBuf = Unpooled.buffer(10); ByteBuf directBuf = Unpooled.directBuffer(8); compositeByteBuf.addComponent(heapBuf); compositeByteBuf.addComponent(directBuf); compositeByteBuf.forEach(System.out::println); // 输出 // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 0, cap: 10)) // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 0, cap: 8)) }} Netty 提供的 3 种缓冲区heap buffer（堆缓冲区）： 这是最常见的类型，ByteBuf 将数据存储到 JVM 的堆空间中，并且将实际的数据放到 byte 数组中来实现的 优点：由于数据是存储在 JVM 的堆中，因此可以快速的创建和快速的释放，并且它提供了 直接访问内部字节数组的方法 缺点：每次读写数据时，都需要先将数据复制到直接缓冲中再进行网络传输 direct buffer（直接缓冲区）： 在堆之外直接分配内存空间，直接缓冲区并不会占用堆的容量空间，因为他是有操作系统在本地内存进行的数据分配 优点：在使用 Socket 进行数据传输时，性能非常好，因为数据直接位于操作系统的本地内存中，所以不需要从 JVM 将数据复制到直接缓冲区 缺点：因为 Direct Buffer 是直接在操作系统内存中的，所以内存空间分配与释放要比堆空间更加复杂，而且速度要慢一些 Netty 通过提供内存池来解决这个问题，直接缓冲区并不支持通过字节数组的方式来访问数据 重点：对于后端的业务消息的编解码来说，推荐使用 HeapByteBuf；对于 I/O 通信的读写缓冲区，我们推荐使用 DirectBytebuf composite buffer（符合缓冲区）： 复合缓冲区实际上是将多个缓冲区实例组合起来，并向外提供一个统一视图。像是一个缓冲区的 List JDK 的 ByteBuffer 与 Netty 的 ByteBuf 之间的差异比对 Netty 的 ByteBuf 采用了读写分离的策略（readerIndex 和 writeerIndex），一个初始化（里面尚未有任何数据）的 ByteBuf 的 readerIndex 与 writerIndex 的值都为0 当数索引与写索引处于同一个位置时，如果我们继续读取，那么就会抛出 IndexOutOfBoundsException 对于ByteBuf 的任何读写操作都会分别单独维护读索引和写索引，MaxCapacity 最大的容量默认为Integer.MAX_VALUE JDK 的 ByteBuffer的缺点： final byte[] hb; 这是JDK的ByteBuffer对象中用于储存的对象声明，可以看到，其字节数组布尔声明为final的，也就是长度是固定不变的，一旦分配好后就不能动态扩容与收缩，而且当储存的数据字节很大时就很有可能出现IndexOutOfBoundsException，如果要预防着个异常，那就需要再储存之前完全确定好待储存的字节的大小，如果ByteBuffer的空间不足，我们只有一种解决方案，那就是创建新的ByteBuffer对象，然后再将之前的ByteBuffer中的数据复制过去，这一切操作都需要由开发者自己来手动完成的 ByteBuffer 只使用一个position 指针来标识位置信息，在进行读写切换时就需要调用flip方法或则是rewind 方法，使用很不方便 Netty 的 ByteBuf 的优点： 储存字节的数组是动态的，其最大值默认是Integer.MAX_VALUE，这里的动态性是体现在write方法中的，write方法执行会判断buffer容量，如果不足则会自动扩容 ByteBuf的读写索引是完成分开的，使用起来很方便 // io.netty.buffer.AbstractByteBuf#writeByte @Override public ByteBuf writeByte(int value) { ensureWritable0(1); // 会先判断是否够写入一个字节 _setByte(writerIndex++, value); return this; }// io.netty.buffer.AbstractByteBuf#ensureWritable0// 会自动扩容 final void ensureWritable0(int minWritableBytes) { ensureAccessible(); if (minWritableBytes &lt;= writableBytes()) { return; } if (minWritableBytes &gt; maxCapacity - writerIndex) { throw new IndexOutOfBoundsException(String.format( &quot;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s&quot;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); }","link":"/2019/01/19/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Spring注解驱动开发（一）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 组件注册@Configuration和@Bean的注入1、使用xml方式 我们一起注入一个bean使用xml来配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;person&quot; class=&quot;com.cuzz.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;cuzz&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 我可以使用ClassPathXmlApplicationContext来获取 /** * @Author: cuzz * @Date: 2018/9/23 10:48 * @Description: */public class MainTest { public static void main(String[] args) { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;); // 用id获取 Person bean = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(bean); }} 输出Person(name=cuzz, age=18) 2、使用注解的方式 编写一个配置类 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 可以通过AnnotationConfigApplicationContext来获取，并且获取id /** * @Author: cuzz * @Date: 2018/9/23 10:59 * @Description: */public class MainTest { public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Person person = (Person) context.getBean(Person.class); System.out.println(person); String[] names = context.getBeanNamesForType(Person.class); for (String name: names) { System.out.println(name); } }} 输出 Person(name=vhsj, age=16)person01 由于给bean添加一个一个value，可以改变默认id 组件注册@ComponentScan1、使用xml 只要标注了注解就能扫描到如： @Controller @Service @Repository @Component &lt;context:component-scan base-package=&quot;com.cuzz&quot;&gt;&lt;/context:component-scan&gt; 2、注解 在配置类中添加 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;) // 指定包public class MainConfig { } 添加controller、service等 测试 /** * @Author: cuzz * @Date: 2018/9/23 13:03 * @Description: */public class IOCTest { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } }} 输出结果 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookControllerbookDaobookServiceperson01 可以看出添加@Controller @Service @Repository @C omponent注解的都可以扫描到 还可以指定添加某些类，和排除某些类，进入ComponentScan注解中有下面两个方法 ComponentScan.Filter[] includeFilters() default {};ComponentScan.Filter[] excludeFilters() default {};includeFilters = Filter[] ：指定扫描的时候只需要包含哪些组件excludeFilters = Filter[] ：指定扫描的时候按照什么规则排除那些组件 配置类，排除Controller @Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;, excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {Controller.class})})public class MainConfig {} 运行测试方法，可以得出没有Controller类的 org.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaobookServiceperson01 自定义TypeFilter指定过滤规则 第一和第二比较常用 FilterType.ANNOTATION：按照注解FilterType.ASSIGNABLE_TYPE：按照给定的类型；FilterType.ASPECTJ：使用ASPECTJ表达式FilterType.REGEX：使用正则指定FilterType.CUSTOM：使用自定义规则 新建一个MyTypeFilte类实现TypeFilter接口 /** * @Author: cuzz * @Date: 2018/9/23 15:03 * @Description: */public class MyTypeFilter implements TypeFilter{ /** * metadataReader：读取到的当前正在扫描的类的信息 * metadataReaderFactory:可以获取到其他任何类信息的 */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { // 获取当前类注解的信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); // 获取当前类资源（类的路径） Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println(&quot;---&gt;&quot;+className); // 这些类名中包含er就返回true if(className.contains(&quot;er&quot;)){ return true; } return false; }} 使用自定义注解记得需要关闭默认过滤器useDefaultFilters = false /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration @ComponentScan(value = &quot;com.cuzz&quot;, includeFilters = @ComponentScan.Filter(type = FilterType.CUSTOM, classes = MyTypeFilter.class), useDefaultFilters = false)public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 测试 ---&gt;com.cuzz.AppTest---&gt;com.cuzz.bean.MainTest---&gt;com.cuzz.config.IOCTest---&gt;com.cuzz.config.MainTest---&gt;com.cuzz.App---&gt;com.cuzz.bean.Person---&gt;com.cuzz.config.MyTypeFilter---&gt;com.cuzz.controller.BookController---&gt;com.cuzz.dao.BookDao---&gt;com.cuzz.sevice.BookServiceorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig // 不是扫描的 person // 这个是在bean中myTypeFilter // 有erbookController // 有erbookService // 有erperson01 // 这个是在bean中 组件注册@Scope设置作用域Spring的bean默认是单例的 @Testpublic void test02() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } Object bean = applicationContext.getBean(&quot;person&quot;); Object bean2 = applicationContext.getBean(&quot;person&quot;); System.out.println(bean == bean2); // 输出true} Scope的四个范围 ConfigurableBeanFactory#SCOPE_PROTOTYPE // 多实例 每次获取时创建对象，不会放在ioc容器中ConfigurableBeanFactory#SCOPE_SINGLETON // 单实例 ioc容器启动是创建对象，以后从容器中获取WebApplicationContext#SCOPE_REQUEST // web同一次请求创建一个实例WebApplicationContext#SCOPE_SESSION // web同一个session创建一个实例 如果我们把Scope修改 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: */@Configurationpublic class MainConfig2 { @Scope(value = &quot;prototype&quot;) @Bean public Person person() { return new Person(&quot;vhuj&quot;, 25); }} 则测试输出false 组件注册@Lazy-bean懒加载懒加载 懒加载的是针对单实例Bean，默认是在容器启动的时创建的，我们可以设置懒加载容器启动是不创建对象，在第一次使用（获取）Bean创建对象，并初始化 测试 先给添加一个@Lazy注解 @Configurationpublic class MainConfig2 { @Lazy @Bean public Person person() { System.out.println(&quot;给容器中添加Person...&quot;); return new Person(&quot;vhuj&quot;, 25); }} 编写一个测试方法 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); System.out.println(&quot;ioc容器创建完成...&quot;); Object bean = applicationContext.getBean(&quot;person&quot;);} 输出 ioc容器创建完成...给容器中添加Person... 添加一个@Lazy是在第一次获取时，创建对象，以后获取就不需要创建了，直接从容器中获取，因为它是单实例 组件注册@Conditional按条件注册按照一定条件进行判断，满足条件给容器中注册Bean 编写自己的Condition类 如果系统是windows，给容器中注入”bill” 如果系统是linux，给容器中注入”linus” 编写WindowCondition类并重写matches方法 /** * @Author: cuzz * @Date: 2018/9/23 20:30 * @Description: 判断是否是windows */ public class WindowCondition implements Condition{ /** * @param context 判断条件 * @param metadata 注释信息 * @return boolean */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); if (property.contains(&quot;Windows&quot;)) { return true; } return false; } } context有以下方法 // 能获取ioc使用的beanfactoryConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// 能获取到类加载器ClassLoader classLoader = context.getClassLoader();// 获取到环境变量Environment environment = context.getEnvironment();// 获取到Bean定义的注册类BeanDefinitionRegistry registry = context.getRegistry(); 配置类 添加Bean添加Condition条件 @Configurationpublic class MainConfig2 { @Conditional({WindowCondition.class}) @Bean(&quot;bill&quot;) public Person person01() { return new Person(&quot;Bill Gates&quot;, 60); } @Conditional({LinuxCondition.class}) @Bean(&quot;linux&quot;) public Person person02() { return new Person(&quot;linus&quot;, 45); }} 测试 @Testpublic void test04() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取环境变量 ConfigurableEnvironment environment = applicationContext.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); System.out.println(property); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } // key 是id Map&lt;String, Person&gt; map = applicationContext.getBeansOfType(Person.class); System.out.println(map);} 发现只有“bill”这个Bean被注入 Windows 7org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2bill{bill=Person(name=Bill Gates, age=60)} 组件注册@Improt给容器中快速导入一个组件@Import导入 @Import可以导入第三方包，或则自己写的类，比较方便，Id默认为全类名 比如我们新建一个类 /** * @Author: cuzz * @Date: 2018/9/23 21:08 * @Description: */public class Color {} 我们只需要在配置类添加一个@Import把这个类导入 @Import({Color.class})@Configurationpublic class MainConfig2 {} ImportSelector接口导入的选择器 返回导入组件需要的全类名的数组 public interface ImportSelector { /** * Select and return the names of which class(es) should be imported based on * the {@link AnnotationMetadata} of the importing @{@link Configuration} class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);} 编写一个MyImportSelector类实现ImportSelector接口 /** * @Author: cuzz * @Date: 2018/9/23 21:15 * @Description: */public class MyImportSelector implements ImportSelector{ // 返回值就导入容器组件的全类名 // AnnotationMetadata:当前类标注的@Import注解类的所有注解信息 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { return new String[] {&quot;com.cuzz.bean.Car&quot;}; }} 在配置类中，通过@Import导入 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class})@Configurationpublic class MainConfig2 {} 测试结果，com.cuzz.bean.Car注入了 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car ImportBeanDefinitionRegistrar接口选择器 public interface ImportBeanDefinitionRegistrar { /** * Register bean definitions as necessary based on the given annotation metadata of * the importing {@code @Configuration} class. * &lt;p&gt;Note that {@link BeanDefinitionRegistryPostProcessor} types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to {@code @Configuration} * class processing. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);} 编写一个ImportBeanDefinitionRegistrar实现类 /** * @Author: cuzz * @Date: 2018/9/23 21:29 * @Description: */public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { /** * @param importingClassMetadata 当前类的注解信息 * @param registry 注册类 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 查询容器 boolean b = registry.containsBeanDefinition(&quot;com.cuzz.bean.Car&quot;); // 如果有car, 注册一个汽油类 if (b == true) { // 需要添加一个bean的定义信息 RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Petrol.class); // 注册一个bean, 指定bean名 registry.registerBeanDefinition(&quot;petrol&quot;, rootBeanDefinition); } }} 配置类 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})@Configurationpublic class MainConfig2 {} 测试结果，出现了petrol org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car petrol 组件注册使用FactoryBean注册组件编写一个ColorFactoryBean类 /** * @Author: cuzz * @Date: 2018/9/23 21:55 * @Description: Spring定义的工厂Bean */public class ColorFactoryBean implements FactoryBean&lt;Color&gt; { // 返回一个Color对象 @Override public Color getObject() throws Exception { return new Color(); } @Override public Class&lt;?&gt; getObjectType() { return Color.class; } // 是否为单例 @Override public boolean isSingleton() { return true; }} 注入到容器中 @Beanpublic ColorFactoryBean colorFactoryBean() { return new ColorFactoryBean();} 测试 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass());} 输出，发现此时的bean调用的方法是getObjectType方法 colorFactoryBean的类型是: class com.cuzz.bean.Color 如果需要获取BeanFactory本身，可以在id前面加一个“&amp;”标识 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass()); Object bean2 = applicationContext.getBean(&quot;&amp;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean2.getClass());} 此时输出 colorFactoryBean的类型是: class com.cuzz.bean.ColorcolorFactoryBean的类型是: class com.cuzz.bean.ColorFactoryBean 总结给容器中注册组件： 包扫描 + 组件组件（@Controller / @Service / @Repository / @Component） @Bean[导入第三方包组件] @Import[快速给容器中导入一个组件] @Import（要导入到容器中的组件），容器中就会自动注册这个组件，id 默认是全类名 ImportSelector，返回需要导入的组件的全类名数组 ImportBeanDefinitionRegistrar，手动注册bean到容器中 使用 Spring 提供的 FactoryBean （工厂Bean） 默认获取到的是工厂 bean 调用的 getObject 创建的对象 要获取工厂 Bean 本身，我们需要个 id 前面加一个 &amp; 符号，如 &amp;colorFactoryBean","link":"/2018/09/23/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Dubbo SPI源码分析","text":"对于一个优秀的框架需要很好的扩展性，给出一个接口，自己可以给出默认实现，同时也允许其他人实现拓展。即“对扩展开放，对修改封闭”的原则。Dubbo 采用微内核+插件的方式来实现，微内核架构中，内核通常采用 Factory、IoC、OSGi 等方式管理插件生命周期，Dubbo 最终决定采用 SPI 机制来加载插件，Dubbo SPI 参考 JDK 原生的 SPI 机制，进行了性能优化以及功能增强。 我们来看看 SPI 定义： Service Provider Interface (SPI) is an API intended to be implemented or extended by a third party. It can be used to enable framework extension and replaceable components. JDK SPIJDK SPI 最比较常见的在访问数据库会使用到java.sql.Driver这个接口，不同的数据库产商会有不同的实现，JDK SPI机制可以为某个接口寻找服务实现。 JDK SPI 机制我们先看一个例子，模拟连接数据库，先定义一个 Driver 接口。 package com.cuzz.api;public interface Driver { void connect(String url);} 然后不同的产商有不同的实现，以 mysql 和 oracle 两个实现。 package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/services 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 JDK SPI 需要读取的配置文件，具体内容如下： com.cuzz.mysql.MysqlDrivercom.cuzz.oracle.OracleDriver 加载配置： public class Main { public static void main(String[] args) { // Java spi 机制 ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); System.out.println(serviceLoader); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while (iterator.hasNext()) { Driver driver = iterator.next(); driver.connect(&quot;localhost:3306&quot;); } }} 运行结果： java.util.ServiceLoader[com.cuzz.api.Driver]connect mysql: localhost:3306connect oracle: localhost:3306 JDK SPI 源码分析我们从ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class);定位到ServiceLoader构造方法中的java.util.ServiceLoader#reload方法 // 前缀private static final String PREFIX = &quot;META-INF/services/&quot;;// The class or interface representing the service being loadedprivate final Class&lt;S&gt; service;// The class loader used to locate, load, and instantiate providersprivate final ClassLoader loader;// The access control context taken when the ServiceLoader is createdprivate final AccessControlContext acc;// Cached providers, in instantiation order// 缓存private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();// The current lazy-lookup iterator// 懒加载迭代器private LazyIterator lookupIterator;public void reload() { providers.clear(); lookupIterator = new LazyIterator(service, loader);} 重点看看这个 LazyIterator 类，这是一个内部类，主要以懒加载形式实现。Iterator 这个接口需要实现 Iterator#hasNext 方法和 Iterator#next 方法，hasNext方法调用了LazyIterator#hasNextService，而next方法调用LazyIterator#nextService。 private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; // 像这样的URL file:/Users/cuzz/Projects/Java/dubbo/cuzz-demo/cuzz-demo-spi/target/classes/META-INF/services/com.cuzz.api.Driver Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } // 第一次获取，config 为空开始加载文件 if (configs == null) { try { // 获取文件名 META-INF/services/com.cuzz.api.Driver String fullName = PREFIX + service.getName(); // 加载配置路径 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } // 解析文件 pending = parse(service, configs.nextElement()); } // 把实现类的名称记录下来 com.cuzz.mysql.MysqlDriver nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); // 存一个备份 String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { // 通过反射获取该实现类 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }} 最后我们来 ServiceLoader#iterator 这个方法是怎么实现的，主要是先走缓存，在走懒加载。 public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); } public S next() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } };} JDK SPI 在 JDBC 中的应用当我们引入mysql 驱动时候，在 META-INF/services 目录下，有一个 java.sql.Driver 文件，内容如下。 om.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 当我们要链接 JDBC 会通过 DriverManager驱动管理来连接。 String url = &quot;jdbc:mysql://localhost:3306/demo?useSSL=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;;String username = &quot;root&quot;;String pwd = &quot;12345&quot;;Connection conn = DriverManager.getConnection(url, username, pwd); DriverManager类的静态方法在 JVM加载类的时候会执行，执行 loadInitialDrivers 方法。 private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;); } private static void loadInitialDrivers() { // 看看系统属性是否配置了jdbc.drivers String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } // If the driver is packaged as a Service Provider, load it. // Get all the drivers through the classloader // exposed as a java.sql.Driver.class service. // ServiceLoader.load() replaces the sun.misc.Providers() AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // JDK SPI 方式加载并实例化 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); /* Load these drivers, so that they can be instantiated. * It may be the case that the driver class may not be there * i.e. there may be a packaged driver with the service class * as implementation of java.sql.Driver but the actual class * may be missing. In that case a java.util.ServiceConfigurationError * will be thrown at runtime by the VM trying to locate * and load the service. * * Adding a try catch block to catch those runtime errors * if driver not available in classpath but it's * packaged as service and that service is there in classpath. */ try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } // 配置了jdbc.dirvers属性通过反射实例化 String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 实例化 java.sql.Driver 接口实现类，在MySQL提供的，会吧自己注册到 DriverManager 中。 package com.mysql.jdbc;import java.sql.SQLException;public class Driver extends NonRegisteringDriver implements java.sql.Driver { // Register ourselves with the DriverManager static { try { // 注册到DriverManager的CopyOnWriteArrayList中 java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can't register driver!&quot;); } }} 最后调用 DriverManager#getConnection 从注册中获取连接。 // Worker method called by the public getConnection() methods.private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException { // 循环从注册中获取，获取到一个就返回。 for(DriverInfo aDriver : registeredDrivers) { try { Connection con = aDriver.driver.connect(url, info); if (con != null) { // Success! println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName()); return (con); } } catch (SQLException ex) { if (reason == null) { reason = ex; } } }} JDK SPI 的缺点 虽然ServiceLoader也算是使用的延迟加载，但是基本只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果你并不想用某些实现类，它也被加载并实例化了，这就造成了浪费。 获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 Dubbo SPIDubbo SPI 对 JDK SPI 进行了扩展，由原来的提供者类的全限定名列表改成了 K-V 形式，如果 SPI 配置文件中定义了多个实现类，而我们只需要使用其中一个实现类时，就会生成不必要的对象，除此之外 Dubbo 对 JDK SPI 做了三个方面的扩展： 方便获取扩展实现：JDK SPI仅仅通过接口类名获取所有实现，而 ExtensionLoader 则通过接口类名和key值获取一个实现。 IOC依赖注入功能：Adaptive实现，就是生成一个代理类，这样就可以根据实际调用时的一些参数动态决定要调用的类了。 采用装饰器模式进行功能增强，自动包装实现，这种实现的类一般是自动激活的，常用于包装类，比如：Protocol的两个实现类：ProtocolFilterWrapper、ProtocolListenerWrapper。 Dubbo 按照 SPI 配置文件的用途，将其分成了三类目录。 META-INF/services/ 目录：该目录下的 SPI 配置文件用来兼容 JDK SPI 。 META-INF/dubbo/ 目录：该目录用于存放用户自定义 SPI 配置文件。 META-INF/dubbo/internal/ 目录：该目录用于存放 Dubbo 内部使用的 SPI 配置文件。 Dubbo SPI 机制定义一个接口，用 @SPI 标识表示是 Dubbo SPI。 @SPIpublic interface Driver { void connect(String url);} 实现类： package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/dubbo 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 Dubbo SPI 需要读取的配置文件，与JDK SPI 不一样是KV形式，具体内容如下： mysqlDriver=com.cuzz.mysql.MysqlDriveroracleDriver=com.cuzz.oracle.OracleDriver 获取实现类： public class App { public static void main(String[] args) { Driver driver = ExtensionLoader.getExtensionLoader(Driver.class).getExtension(&quot;mysqlDriver&quot;); driver.connect(&quot;localhost:3306&quot;); }} 输出： connect mysql: localhost:3306 Dubbo SPI 主流程我们先从获取 ExtensLoader 实例开始，ExtensionLoader#getExtensionLoader /** * Dubbo 中一个扩展接口对应一个 ExtensionLoader 实例，该集合缓存了全部 ExtensionLoader 实例， * 其中的 Key 为扩展接口，Value 为加载其扩展实现的 ExtensionLoader 实例。 */private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;&gt;(64);public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) { if (type == null) { throw new IllegalArgumentException(&quot;Extension type == null&quot;); } // 必须为接口 if (!type.isInterface()) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an interface!&quot;); } // 必须有@SPI接口 if (!withExtensionAnnotation(type)) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an extension, because it is NOT annotated with @&quot; + SPI.class.getSimpleName() + &quot;!&quot;); } // 从缓存中获取 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) { // 如果已经存在 key 就不往 map 中添加 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); // ---&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); } return loader;} 接着看看 ExtensionLoader#ExtensionLoader 构造方法，如果 type 不为 ExtensionFactory.class 初始化拓展适配器。 /*** 表示拓展类实例工厂，可以通过工厂创建实例*/private final ExtensionFactory objectFactory;private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} 获取拓展实现类，ExtensionLoader#getExtension /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现对象之间的映射关系。*/private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;&gt;();public T getExtension(String name) { if (StringUtils.isEmpty(name)) { throw new IllegalArgumentException(&quot;Extension name == null&quot;); } // @SPI中value有值，如@SPI(&quot;dubbo&quot;) 默认获取 key 为 dubbo 的 Extension if (&quot;true&quot;.equals(name)) { return getDefaultExtension(); } // getOrCreateHolder()方法中封装了查找cachedInstances缓存的逻辑 final Holder&lt;Object&gt; holder = getOrCreateHolder(name); Object instance = holder.get(); if (instance == null) { synchronized (holder) { // 双重锁防止并发 instance = holder.get(); if (instance == null) { instance = createExtension(name); // ---&gt; holder.set(instance); } } } return (T) instance;}private Holder&lt;Object&gt; getOrCreateHolder(String name) { Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) { cachedInstances.putIfAbsent(name, new Holder&lt;&gt;()); holder = cachedInstances.get(name); } return holder;} ExtensionLoader#createExtension 方法中完成了 SPI 配置文件的查找以及相应扩展实现类的实例化，同时还实现了自动装配以及自动 Wrapper 包装等功能。 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); // ---&gt; 1 if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容. Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} Dubbo SPI 获取拓展类ExtensionLoader#getExtensionClasses /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现类之间的映射关系。cachedNames 集合的反向关系缓存。*/private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;&gt;();private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() { // 先从缓存中获取 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) { synchronized (cachedClasses) { classes = cachedClasses.get(); if (classes == null) { // 加载类 classes = loadExtensionClasses(); // ---&gt; cachedClasses.set(classes); } } } return classes;} ExtensionLoader#loadExtensionClasses /*** synchronized in getExtensionClasses*/private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() { // 只能有一个默认值 cacheDefaultExtensionName(); // 加载的扩展名与扩展实现类之间的映射关系 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;&gt;(); for (LoadingStrategy strategy : strategies) { loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); // ---&gt; loadDirectory(extensionClasses, strategy.directory(), type.getName().replace(&quot;org.apache&quot;, &quot;com.alibaba&quot;), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); } return extensionClasses;}private void cacheDefaultExtensionName() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation == null) { return; } String value = defaultAnnotation.value(); // 只能有一个车默认值，这种 @SPI(&quot;dubbo,http&quot;) 就会报错 if ((value = value.trim()).length() &gt; 0) { String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) { throw new IllegalStateException(&quot;More than 1 default extension name on extension &quot; + type.getName() + &quot;: &quot; + Arrays.toString(names)); } if (names.length == 1) { cachedDefaultName = names[0]; } }} ExtensionLoader#loadDirectory private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type, boolean extensionLoaderClassLoaderFirst, boolean overridden, String... excludedPackages) { String fileName = dir + type; try { Enumeration&lt;java.net.URL&gt; urls = null; ClassLoader classLoader = findClassLoader(); // try to load from ExtensionLoader's ClassLoader first if (extensionLoaderClassLoaderFirst) { ClassLoader extensionLoaderClassLoader = ExtensionLoader.class.getClassLoader(); if (ClassLoader.getSystemClassLoader() != extensionLoaderClassLoader) { urls = extensionLoaderClassLoader.getResources(fileName); } } if (urls == null || !urls.hasMoreElements()) { if (classLoader != null) { urls = classLoader.getResources(fileName); } else { urls = ClassLoader.getSystemResources(fileName); } } // 循环获取 if (urls != null) { while (urls.hasMoreElements()) { java.net.URL resourceURL = urls.nextElement(); loadResource(extensionClasses, classLoader, resourceURL, overridden, excludedPackages); // ---&gt; } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, description file: &quot; + fileName + &quot;).&quot;, t); }} ExtensionLoader#loadResource private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL, boolean overridden, String... excludedPackages) { try { // 必须 utf-8 格式 try (BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null) { final int ci = line.indexOf('#'); if (ci &gt;= 0) { // 去掉注释 line = line.substring(0, ci); } line = line.trim(); if (line.length() &gt; 0) { try { String name = null; int i = line.indexOf('='); if (i &gt; 0) { name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); } // 没有被排除外 if (line.length() &gt; 0 &amp;&amp; !isExcluded(line, excludedPackages)) { loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name, overridden); // ---&gt; } } catch (Throwable t) { IllegalStateException e = new IllegalStateException(&quot;Failed to load extension class (interface: &quot; + type + &quot;, class line: &quot; + line + &quot;) in &quot; + resourceURL + &quot;, cause: &quot; + t.getMessage(), t); exceptions.put(line, e); } } } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, class file: &quot; + resourceURL + &quot;) in &quot; + resourceURL, t); }} ExtensionLoader#loadClass private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name, boolean overridden) throws NoSuchMethodException { if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(&quot;Error occurred when loading extension class (interface: &quot; + type + &quot;, class line: &quot; + clazz.getName() + &quot;), class &quot; + clazz.getName() + &quot; is not subtype of interface.&quot;); } // 处理Adaptive注解，若存在则将该实现类保存至cachedAdaptiveClass属性 if (clazz.isAnnotationPresent(Adaptive.class)) { cacheAdaptiveClass(clazz, overridden); } // 是否为包装类，是包装类缓存到 cachedWrapperClasses Set中 else if (isWrapperClass(clazz)) { cacheWrapperClass(clazz); } else { clazz.getConstructor(); if (StringUtils.isEmpty(name)) { name = findAnnotationName(clazz); if (name.length() == 0) { throw new IllegalStateException(&quot;No such extension name for the class &quot; + clazz.getName() + &quot; in the config &quot; + resourceURL); } } // key可以为多个，如：mysqlDriver,mysqlDriver2=com.cuzz.mysql.MysqlDriver String[] names = NAME_SEPARATOR.split(name); if (ArrayUtils.isNotEmpty(names)) { // 缓存到 cachedActivates 属性中 cacheActivateClass(clazz, names[0]); for (String n : names) { // 缓存了该 ExtensionLoader 加载的扩展实现类与扩展名之间的映射关系。 cacheName(clazz, n); // 加载的扩展名与扩展实现类之间的映射关系 saveInExtensionClass(extensionClasses, clazz, n, overridden); } } }}private void cacheAdaptiveClass(Class&lt;?&gt; clazz, boolean overridden) { if (cachedAdaptiveClass == null || overridden) { cachedAdaptiveClass = clazz; } else if (!cachedAdaptiveClass.equals(clazz)) { throw new IllegalStateException(&quot;More than 1 adaptive class found: &quot; + cachedAdaptiveClass.getName() + &quot;, &quot; + clazz.getName()); }} Dubbo SPI 的自动包装和自动注入回到前面我们分析ExtensionLoader#createExtension方法，现在我们重点关注 ExtensionLoader#injectExtension 方法 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // ---&gt; // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容。 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { // 遍历所有的包装类，包装类需要有一个参数类被包装类型的构造器。 for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} ExtensionLoader#injectExtension private T injectExtension(T instance) { if (objectFactory == null) { return instance; } try { for (Method method : instance.getClass().getMethods()) { // 判断是否为set方法 if (!isSetter(method)) { continue; } // 如果有 @DisableInject 注解也不注入 if (method.getAnnotation(DisableInject.class) != null) { continue; } // 获取参数类型，如果是基本类型也忽略 Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) { continue; } try { // 根据 Setter 方法获取属性名 String property = getSetterProperty(method); // 加载这个类，并实例化 Object object = objectFactory.getExtension(pt, property); if (object != null) { // 反射注入 method.invoke(instance, object); } } catch (Exception e) { logger.error(&quot;Failed to inject via method &quot; + method.getName() + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e); } } } catch (Exception e) { logger.error(e.getMessage(), e); } return instance;} Dubbo SPI 的 @Adaptive 注解与适配器在dubbo扩展中，适配器模式被广泛使用，其作用在于为同一扩展类型下的多个扩展实现的调用提供路由功能，如指定优先级等。dubbo提供了两种方式来生成扩展适配器： 静态代码形式的默认适配器：这些类会被Adaptive注解修饰，且一个接口只能有一个这样的静态适配器。这种形式仅应用于一些特殊的接口，如：AdaptiveCompiler、AdaptiveExtensionFactory这两个适配器，ExtensionLoader需要依赖它们来工作，所以使用了这种特殊的构建方式。 动态代码适配器：实际上其余的接口都是使用动态适配器，ExtensionLoader 根据接口定义动态生成一段适配器代码，并构建这个动态类的实例。这个时候接口中的一些方法具有 Adaptive 标记，它提供了一些用于查找具体 Extension 的key，如果这些方法中有URL类型的参数，则会依次在url中查找这些key对应的value，再以此为 name 确定要使用的 Extension。如果没有从url中找到该参数，则会使用 SPI 注解中的默认值 name 进行构建。 我们回到构造方法中ExtensionLoader#getAdaptiveExtension private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} ExtensionLoader#getAdaptiveExtension public T getAdaptiveExtension() { // 先从缓存中获取 Object instance = cachedAdaptiveInstance.get(); if (instance == null) { if (createAdaptiveInstanceError != null) { throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); } synchronized (cachedAdaptiveInstance) { instance = cachedAdaptiveInstance.get(); if (instance == null) { try { // 创建 instance = createAdaptiveExtension(); // ---&gt; 1 cachedAdaptiveInstance.set(instance); } catch (Throwable t) { createAdaptiveInstanceError = t; throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + t.toString(), t); } } } } return (T) instance;}private T createAdaptiveExtension() { try { // 注入属性 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); // ---&gt; 2 } catch (Exception e) { throw new IllegalStateException(&quot;Can't create adaptive extension &quot; + type + &quot;, cause: &quot; + e.getMessage(), e); }}private Class&lt;?&gt; getAdaptiveExtensionClass() { getExtensionClasses(); if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } return cachedAdaptiveClass = createAdaptiveExtensionClass(); // ---&gt; 3}private Class&lt;?&gt; createAdaptiveExtensionClass() { // 创建适配器类，并继承 type 接口 String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); // ---&gt; 4 ClassLoader classLoader = findClassLoader(); // ExtensionLoader再调用默认的JavassitCompiler进行编译和类加载 org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader);} ExtensionLoader#createAdaptiveExtensionClass 以 Transsporter为例子 @SPI(&quot;netty&quot;) public interface Transporter { @Adaptive({Constants.SERVER_KEY, Constants.TRANSPORTER_KEY}) RemotingServer bind(URL url, ChannelHandler handler) throws RemotingException; @Adaptive({Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY}) Client connect(URL url, ChannelHandler handler) throws RemotingException; } Dubbo 会生成一个 Transporter$Adaptive 适配器类，该类继承了 Transporter 接口： public class Transporter$Adaptive implements Transporter { public org.apache.dubbo.remoting.Client connect(URL arg0, ChannelHandler arg1) throws RemotingException { // 必须传递URL参数 if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg0; // 确定扩展名，优先从URL中的client参数获取，其次是transporter参数 // 这两个参数名称由@Adaptive注解指定，最后是@SPI注解中的默认值 String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if (extName == null) throw new IllegalStateException(&quot;...&quot;); // 通过ExtensionLoader加载Transporter接口的指定扩展实现 Transporter extension = (Transporter) ExtensionLoader .getExtensionLoader(Transporter.class) .getExtension(extName); return extension.connect(arg0, arg1); } ... // 省略bind()方法 } Dubbo SPI 的 @Activate注解与自动激活特性这里以 Dubbo 中的 Filter 为例说明自动激活特性的含义，org.apache.dubbo.rpc.Filter 接口有非常多的扩展实现类，在一个场景中可能需要某几个 Filter 扩展实现类协同工作，而另一个场景中可能需要另外几个实现类一起工作。这样，就需要一套配置来指定当前场景中哪些 Filter 实现是可用的，这就是 @Activate 注解要做的事情。 @Activate 注解标注在扩展实现类上，有 group、value 以及 order 三个属性。 group 属性：修饰的实现类是在 Provider 端被激活还是在 Consumer 端被激活。 value 属性：修饰的实现类只在 URL 参数中出现指定的 key 时才会被激活。 order 属性：用来确定扩展实现类的排序。 如 Filter 接口和实现类： @SPIpublic interface Filter { Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException;1}@Activate(group = Constants.PROVIDER)public class TimeoutFilter implements Filter { ...}@Activate(group = {Constants.PROVIDER, Constants.CONSUMER})public class MonitorFilter implements Filter { ...} 首先来关注 getActivateExtension() 方法的参数：url 中包含了配置信息，values 是配置中指定的扩展名，group 为 Provider 或 Consumer。 public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) { List&lt;T&gt; activateExtensions = new ArrayList&lt;&gt;(); // values配置就是扩展名 List&lt;String&gt; names = values == null ? new ArrayList&lt;&gt;(0) : asList(values); if (!names.contains(REMOVE_VALUE_PREFIX + DEFAULT_KEY)) {// ---1 getExtensionClasses(); // 触发cachedActivates等缓存字段的加载 for (Map.Entry&lt;String, Object&gt; entry : cachedActivates.entrySet()) { String name = entry.getKey(); // 扩展名 Object activate = entry.getValue(); // @Activate注解 String[] activateGroup, activateValue; if (activate instanceof Activate) { // @Activate注解中的配置 activateGroup = ((Activate) activate).group(); activateValue = ((Activate) activate).value(); } else { continue; } if (isMatchGroup(group, activateGroup) // 匹配group // 没有出现在values配置中的，即为默认激活的扩展实现 &amp;&amp; !names.contains(name) // 通过&quot;-&quot;明确指定不激活该扩展实现 &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name) // 检测URL中是否出现了指定的Key &amp;&amp; isActive(activateValue, url)) { // 加载扩展实现的实例对象，这些都是激活的 activateExtensions.add(getExtension(name)); } } // 排序 --- 2 activateExtensions.sort(ActivateComparator.COMPARATOR); } List&lt;T&gt; loadedExtensions = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; names.size(); i++) { // ---3 String name = names.get(i); // 通过&quot;-&quot;开头的配置明确指定不激活的扩展实现，直接就忽略了 if (!name.startsWith(REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name)) { if (DEFAULT_KEY.equals(name)) { if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合前面 activateExtensions.addAll(0, loadedExtensions); loadedExtensions.clear(); } } else { loadedExtensions.add(getExtension(name)); } } } if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合后面 activateExtensions.addAll(loadedExtensions); } return activateExtensions; } 总结本文总结了 JDK SPI 和 Dubbo SPI 机制和原理，参考了很多文章，以下几点需要值得注意： JDK SPI 需要对加载实例化所有的推展对象，而 Dubbo SPI 根据 KV 形式，只需要实例化需要的拓展。 Dubbo SPI 对 JDK SPI 拓展了自动注入、自动注入以及自动激活等特性。 参考 Dubbo官网-Dubbo SPI Dubbo SPI 精析 Dubbo源码解读全集 聊聊Dubbo（五）：核心源码-SPI扩展 Dubbo源码分析（五）ExtensionLoader","link":"/2020/08/26/Dubbo%20SPI%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java 并发编程","text":"请谈谈你对 volatile 的理解volatile 是 Java 虚拟机提供的轻量级的同步机制 保证可见性 禁止指令排序 不保证原子性 JMM（Java 内存模型） JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JMM 同步规定 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。 首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 内存模型图 三大特性： 可见性 原子性 有序性 （1）可见性，如果不加 volatile 关键字，则主线程会进入死循环，加 volatile 则主线程能够退出，说明加了 volatile 关键字变量，当有一个线程修改了值，会马上被另一个线程感知到，当前值作废，从新从主内存中获取值。对其他线程可见，这就叫可见性。 /** * @Author: cuzz * @Date: 2019/4/16 21:29 * @Description: 可见性代码实例 */public class VolatileDemo { public static void main(String[] args) { Data data = new Data(); new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; coming...&quot;); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } data.addOne(); // 调用 System.out.println(Thread.currentThread().getName() + &quot; updated...&quot;); }).start(); while (data.a == 0) { // looping } System.out.println(Thread.currentThread().getName() + &quot; job is done...&quot;); }}class Data { // int a = 0; volatile int a = 0; void addOne() { this.a += 1; }} （2）原子性，发现下面输出不能得到 20000。 public class VolatileDemo { public static void main(String[] args) { // test01(); test02(); } // 测试原子性 private static void test02() { Data data = new Data(); for (int i = 0; i &lt; 20; i++) { new Thread(() -&gt; { for (int j = 0; j &lt; 1000; j++) { data.addOne(); } }).start(); } // 默认有 main 线程和 gc 线程 while (Thread.activeCount() &gt; 2) { Thread.yield(); } System.out.println(data.a); }}class Data { volatile int a = 0; void addOne() { this.a += 1; }} （3）有序性 计算机在执行程序时，为了提高性能，编译器个处理器常常会对指令做重排，一般分为以下 3 种 编译器优化的重排 指令并行的重排 内存系统的重排 单线程环境里面确保程序最终执行的结果和代码执行的结果一致 处理器在进行重排序时必须考虑指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证用的变量能否一致性是无法确定的，结果无法预测 代码示例 public class ReSortSeqDemo { int a = 0; boolean flag = false; public void method01() { a = 1; // flag = true; // ----线程切换---- flag = true; // a = 1; } public void method02() { if (flag) { a = a + 3; System.out.println(&quot;a = &quot; + a); } }} 如果两个线程同时执行，method01 和 method02 如果线程 1 执行 method01 重排序了，然后切换的线程 2 执行 method02 就会出现不一样的结果。 禁止指令排序 volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性） 由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 线程安全性保证 工作内存与主内存同步延迟现象导致可见性问题 可以使用 synchronzied 或 volatile 关键字解决，它们可以使用一个线程修改后的变量立即对其他线程可见 对于指令重排导致可见性问题和有序性问题 可以利用 volatile 关键字解决，因为 volatile 的另一个作用就是禁止指令重排序优化 你在哪些地方用到过 volatile？单例 多线程环境下可能存在的安全问题，发现构造器里的内容会多次输出 @NotThreadSafepublic class Singleton01 { private static Singleton01 instance = null; private Singleton01() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton01 getInstance() { if (instance == null) { instance = new Singleton01(); } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton01.getInstance()); } executorService.shutdown(); }} 双重锁单例 public class Singleton02 { private static volatile Singleton02 instance = null; private Singleton02() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton02 getInstance() { if (instance == null) { synchronized (Singleton01.class) { if (instance == null) { instance = new Singleton02(); } } } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton02.getInstance()); } executorService.shutdown(); }} 如果没有加 volatile 就不一定是线程安全的，原因是指令重排序的存在，加入 volatile 可以禁止指令重排。原因是在于某一个线程执行到第一次检测，读取到的 instance 不为 null 时，instance 的引用对象可能还没有完成初始化。instance = new Singleton() 可以分为以下三步完成。 memory = allocate(); // 1.分配对象空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null 步骤 2 和步骤 3 不存在依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种优化是允许的，发生重排。 memory = allocate(); // 1.分配对象空间instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null，但对象还没有初始化完成instance(memory); // 2.初始化对象 所以不加 volatile 返回的实例不为空，但可能是未初始化的实例 CAS 你知道吗？CAS 底层原理？谈谈对 UnSafe 的理解？public class CASDemo { public static void main(String[] args) { AtomicInteger atomicInteger = new AtomicInteger(666); // 获取真实值，并替换为相应的值 boolean b = atomicInteger.compareAndSet(666, 2019); System.out.println(b); // true boolean b1 = atomicInteger.compareAndSet(666, 2020); System.out.println(b1); // false atomicInteger.getAndIncrement(); }} getAndIncrement()方法 /*** Atomically increments by one the current value.** @return the previous value*/public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1);} 引出一个问题：UnSafe 类是什么？我们先看看AtomicInteger 就使用了Unsafe 类。 public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取下面 value 的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; // ...} Unsafe类： Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。 变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 CAS 是什么？ CAS 的全称 Compare-And-Swap，它是一条 CPU 并发。 它的功能是判断内存某一个位置的值是否为预期，如果是则更改这个值，这个过程就是原子的。 CAS 并发原体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。 分析一下 getAndAddInt 这个方法 // unsafe.getAndAddIntpublic final int getAndAddInt(Object obj, long valueOffset, long expected, int val) { int temp; do { temp = this.getIntVolatile(obj, valueOffset); // 获取快照值 } while (!this.compareAndSwap(obj, valueOffset, temp, temp + val)); // 如果此时 temp 没有被修改，就能退出循环，否则重新获取 return temp;} CAS 的缺点？ 循环时间长开销很大 如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。 只能保证一个共享变量的原子操作 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性。 引出 ABA 问题 原子类 AtomicInteger 的 ABA 问题谈一谈？原子更新引用知道吗？原子引用 public class AtomicReferenceDemo { public static void main(String[] args) { User cuzz = new User(&quot;cuzz&quot;, 18); User faker = new User(&quot;faker&quot;, 20); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(cuzz); System.out.println(atomicReference.compareAndSet(cuzz, faker)); // true System.out.println(atomicReference.get()); // User(userName=faker, age=20) }} ABA 问题是怎么产生的 /** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo { private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }).start(); new Thread(() -&gt; { // 保证上面线程先执行 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicReference.compareAndSet(100, 2019); System.out.println(atomicReference.get()); // 2019 }).start(); }} 当有一个值从 A 改为 B 又改为 A，这就是 ABA 问题。 时间戳原子引用 package com.cuzz.thread;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo2 { private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); }).start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(b); // false System.out.println(atomicStampedReference.getReference()); // 100 }).start(); }} 我们先保证两个线程的初始版本为一致，后面修改是由于版本不一样就会修改失败。 我们知道 ArrayList 是线程不安全，请编写一个不安全的案例并给出解决方案？故障现象 public class ContainerDemo { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 100; i++) { new Thread(() -&gt; { list.add(random.nextInt(10)); System.out.println(list); }).start(); } }} 发现报 java.util.ConcurrentModificationException 导致原因 并发修改导致的异常 解决方案 new Vector(); Collections.synchronizedList(new ArrayList&lt;&gt;()); new CopyOnWriteArrayList&lt;&gt;(); 优化建议 在读多写少的时候推荐使用 CopeOnWriteArrayList 这个类 java 中锁你知道哪些？请手写一个自旋锁？1、公平和非公平锁 是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 2、可重入锁和不可重入锁 是什么 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 代码实现 可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 测试 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 3、自旋锁 是指定尝试获取锁的线程不会立即堵塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上线文切换的消耗，缺点就是循环会消耗 CPU。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 4、独占锁（写锁）/共享锁（读锁） 是什么 独占锁：指该锁一次只能被一个线程持有 共享锁：该锁可以被多个线程持有 对于 ReentrantLock 和 synchronized 都是独占锁；对与 ReentrantReadWriteLock 其读锁是共享锁而写锁是独占锁。读锁的共享可保证并发读是非常高效的，读写、写读和写写的过程是互斥的。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 CountDownLatch、CyclicBarrier 和Semaphore 使用过吗？1、CountDownLatch 让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒。CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，调用线程会被堵塞，其他线程调用 countDown 方法会将计数减一（调用 countDown 方法的线程不会堵塞），当计数其值变为零时，因调用 await 方法被堵塞的线程会被唤醒，继续执行。 假设我们有这么一个场景，教室里有班长和其他6个人在教室上自习，怎么保证班长等其他6个人都走出教室在把教室门给关掉。 public class CountDownLanchDemo { public static void main(String[] args) { for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...班长把门给关了，离开了教室...5 离开了教室...4 离开了教室... 发现班长都没有等其他人理他教室就把门给关了，此时我们就可以使用 CountDownLatch 来控制 public class CountDownLanchDemo { public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...4 离开了教室...5 离开了教室...班长把门给关了，离开了教室... 2、CyclicBarrier 我们假设有这么一个场景，每辆车只能坐个人，当车满了，就发车。 public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -&gt; { System.out.println(&quot;车满了，开始出发...&quot;); }); for (int i = 0; i &lt; 8; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 开始上车...&quot;); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } }} 输出结果 Thread-0 开始上车...Thread-1 开始上车...Thread-3 开始上车...Thread-4 开始上车...车满了，开始出发...Thread-5 开始上车...Thread-7 开始上车...Thread-2 开始上车...Thread-6 开始上车...车满了，开始出发... 3、Semaphore 假设我们有 3 个停车位，6 辆车去抢 public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { try { semaphore.acquire(); // 获取一个许可 System.out.println(Thread.currentThread().getName() + &quot; 抢到车位...&quot;); Thread.sleep(3000); System.out.println(Thread.currentThread().getName() + &quot; 离开车位&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); // 释放一个许可 } }).start(); } }} 输出 Thread-1 抢到车位...Thread-2 抢到车位...Thread-0 抢到车位...Thread-2 离开车位Thread-0 离开车位Thread-3 抢到车位...Thread-1 离开车位Thread-4 抢到车位...Thread-5 抢到车位...Thread-3 离开车位Thread-5 离开车位Thread-4 离开车位 堵塞队列你知道吗？1、阻塞队列有哪些 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）对元素进行排序。 LinkedBlokcingQueue：是一个基于链表结构的阻塞队列，此队列按 FIFO（先进先出）对元素进行排序，吞吐量通常要高于 ArrayBlockingQueue。 SynchronousQueue：是一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlokcingQueue。 2、什么是阻塞队列 阻塞队列，顾名思义，首先它是一个队列，而一个阻塞队列在数据结构中所起的作用大致如图所示： 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。 当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。 核心方法 方法\\行为 抛异常 特定的值 阻塞 超时 插入方法 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除方法 poll()、remove(o) take() poll(timeout, timeunit) 检查方法 element() peek() 行为解释： 抛异常：如果操作不能马上进行，则抛出异常 特定的值：如果操作不能马上进行，将会返回一个特殊的值，一般是 true 或者 false 阻塞：如果操作不能马上进行，操作会被阻塞 超时：如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是 true 或者 false 插入方法： add(E e)：添加成功返回true，失败抛 IllegalStateException 异常 offer(E e)：成功返回 true，如果此队列已满，则返回 false put(E e)：将元素插入此队列的尾部，如果该队列已满，则一直阻塞 删除方法： remove(Object o) ：移除指定元素,成功返回true，失败返回false poll()：获取并移除此队列的头元素，若队列为空，则返回 null take()：获取并移除此队列头元素，若没有元素则一直阻塞 检查方法： element() ：获取但不移除此队列的头元素，没有元素则抛异常 peek() :获取但不移除此队列的头；若队列为空，则返回 null 3、SynchronousQueue SynchronousQueue，实际上它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移出队列。 public class SynchronousQueueDemo { public static void main(String[] args) { SynchronousQueue&lt;Integer&gt; synchronousQueue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; { try { synchronousQueue.put(1); Thread.sleep(3000); synchronousQueue.put(2); Thread.sleep(3000); synchronousQueue.put(3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(() -&gt; { try { Integer val = synchronousQueue.take(); System.out.println(val); Integer val2 = synchronousQueue.take(); System.out.println(val2); Integer val3 = synchronousQueue.take(); System.out.println(val3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }} 4、使用场景 生产者消费者模式 线程池 消息中间件 synchronized 和 Lock 有什么区别？ 原始结构 synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。 Lock 是具体类（java.util.concurrent.locks.Lock）是 api 层面的锁。 使用方法 synchronized 不需要用户手动去释放锁，当 synchronized 代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock 则需要用户手动的释放锁，若没有主动释放锁，可能导致出现死锁的现象，lock() 和 unlock() 方法需要配合 try/finally 语句来完成。 等待是否可中断 synchronized 不可中断，除非抛出异常或者正常运行完成。 ReentrantLock 可中断，设置超时方法 tryLock(long timeout, TimeUnit unit)，lockInterruptibly() 放代码块中，调用 interrupt() 方法可中断。 加锁是否公平 synchronized 非公平锁 ReentrantLock 默认非公平锁，构造方法中可以传入 boolean 值，true 为公平锁，false 为非公平锁。 锁可以绑定多个 Condition synchronized 没有 Condition。 ReentrantLock 用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个线程要么唤醒全部线程。 线程池使用过吗？谈谈对 ThreadPoolExector 的理解？为什使用线程池，线程池的优势？ 线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，那么超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点为： 线程复用 控制最大并发数量 管理线程 主要优点 降低资源消耗，通过重复利用已创建的线程来降低线程创建和销毁造成的消耗。 提高相应速度，当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性，线程是稀缺资源，如果无限制的创建，不仅仅会消耗系统资源，还会降低体统的稳定性，使用线程可以进行统一分配，调优和监控。 创建线程的几种方式 继承 Thread 实现 Runnable 接口 实现 Callable public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { // 在 FutureTask 中传入 Callable 的实现类 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { return 666; } }); // 把 futureTask 放入线程中 new Thread(futureTask).start(); // 获取结果 Integer res = futureTask.get(); System.out.println(res); }} 线程池如果使用？ 架构说明 编码实现 Executors.newSingleThreadExecutor()：只有一个线程的线程池，因此所有提交的任务是顺序执行 Executors.newCachedThreadPool()：线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除 Executors.newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待 Executors.newScheduledThreadPool()：用来调度即将执行的任务的线程池 Executors.newWorkStealingPool()： newWorkStealingPool适合使用在很耗时的操作，但是newWorkStealingPool不是ThreadPoolExecutor的扩展，它是新的线程池类ForkJoinPool的扩展，但是都是在统一的一个Executors类中实现，由于能够合理的使用CPU进行对任务操作（并行操作），所以适合使用在很耗时的任务中 ThreadPoolExecutor ThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务。 线程池的几个重要参数介绍？ 参数 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过 corePoolSize 数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true) 使得核心线程有效时间 TimeUnit keepAliveTime 时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 说说线程池的底层工作原理？ 重点讲解： 其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。 当设置allowCoreThreadTimeOut(true) 时，线程池中 corePoolSize 线程空闲时间达到 keepAliveTime 也将关闭。 线程池用过吗？生产上你如何设置合理参数？线程池的拒绝策略你谈谈？ 是什么 等待队列已经满了，再也塞不下新的任务，同时线程池中的线程数达到了最大线程数，无法继续为新任务服务。 拒绝策略 AbortPolicy：处理程序遭到拒绝将抛出运行时 RejectedExecutionException CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 DiscardPolicy：不能执行的任务将被删除 DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 你在工作中单一的、固定数的和可变的三种创建线程池的方法，你用哪个多，超级大坑？ 如果读者对Java中的阻塞队列有所了解的话，看到这里或许就能够明白原因了。 Java中的BlockingQueue主要有两种实现，分别是ArrayBlockingQueue 和 LinkedBlockingQueue。 ArrayBlockingQueue是一个用数组实现的有界阻塞队列，必须设置容量。 LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。 这里的问题就出在：不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。也就是说，如果我们不设置LinkedBlockingQueue的容量的话，其默认容量将会是Integer.MAX_VALUE。 而newFixedThreadPool中创建LinkedBlockingQueue时，并未指定容量。此时，LinkedBlockingQueue就是一个无边界队列，对于一个无边界队列来说，是可以不断的向队列中加入任务的，这种情况下就有可能因为任务过多而导致内存溢出问题。 上面提到的问题主要体现在newFixedThreadPool和newSingleThreadExecutor两个工厂方法上，并不是说newCachedThreadPool和newScheduledThreadPool这两个方法就安全了，这两种方式创建的最大线程数可能是Integer.MAX_VALUE，而创建这么多线程，必然就有可能导致OOM。 你在工作中是如何使用线程池的，是否自定义过线程池使用？ 自定义线程池 public class ThreadPoolExecutorDemo { public static void main(String[] args) { Executor executor = new ThreadPoolExecutor(2, 3, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); }} 合理配置线程池你是如果考虑的？ CPU 密集型 CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。 IO 密集型 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 。 也可以使用公式：CPU 核数 / (1 - 阻塞系数)；其中阻塞系数在 0.8 ～ 0.9 之间。 死锁编码以及定位分析产生死锁的原因 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种相互等待的现象，如果无外力的干涉那它们都将无法推进下去，如果系统的资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。 代码 public class DeadLockDemo { public static void main(String[] args) { String lockA = &quot;lockA&quot;; String lockB = &quot;lockB&quot;; DeadLockDemo deadLockDemo = new DeadLockDemo(); Executor executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; deadLockDemo.method(lockA, lockB)); executor.execute(() -&gt; deadLockDemo.method(lockB, lockA)); } public void method(String lock1, String lock2) { synchronized (lock1) { System.out.println(Thread.currentThread().getName() + &quot;--获取到：&quot; + lock1 + &quot;; 尝试获取：&quot; + lock2); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (lock2) { System.out.println(&quot;获取到两把锁!&quot;); } } }} 解决 jps -l 命令查定位进程号 28519 org.jetbrains.jps.cmdline.Launcher32376 com.intellij.idea.Main28521 com.cuzz.thread.DeadLockDemo27836 org.jetbrains.kotlin.daemon.KotlinCompileDaemon28591 sun.tools.jps.Jps jstack 28521 找到死锁查看 2019-05-07 00:04:15Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode):&quot;Attach Listener&quot; #13 daemon prio=9 os_prio=0 tid=0x00007f7acc001000 nid=0x702a waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE// ...Found one Java-level deadlock:=============================&quot;pool-1-thread-2&quot;: waiting to lock monitor 0x00007f7ad4006478 (object 0x00000000d71f60b0, a java.lang.String), which is held by &quot;pool-1-thread-1&quot;&quot;pool-1-thread-1&quot;: waiting to lock monitor 0x00007f7ad4003be8 (object 0x00000000d71f60e8, a java.lang.String), which is held by &quot;pool-1-thread-2&quot;Java stack information for the threads listed above:===================================================&quot;pool-1-thread-2&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60b0&gt; (a java.lang.String) - locked &lt;0x00000000d71f60e8&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$1(DeadLockDemo.java:21) at com.cuzz.thread.DeadLockDemo$$Lambda$2/2074407503.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;pool-1-thread-1&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60e8&gt; (a java.lang.String) - locked &lt;0x00000000d71f60b0&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$0(DeadLockDemo.java:20) at com.cuzz.thread.DeadLockDemo$$Lambda$1/558638686.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 最后发现一个死锁。 后续JVM 面试 参考链接 Java内存模型-volatile","link":"/2019/04/16/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"title":"Netty 源码分析（二）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先来看一个NIO网络编程服务端/** * @Author: cuzz * @Date: 2019/1/7 15:39 * @Description: */public class NioServer { // 储存客户端连接 private static Map&lt;String, SocketChannel&gt; clientMap = new HashMap&lt;&gt;(); public static void main(String[] args) throws IOException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); ServerSocket serverSocket = serverSocketChannel.socket(); serverSocket.bind(new InetSocketAddress(8899)); Selector selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { try { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); selectionKeys.forEach(selectionKey -&gt; { try { if (selectionKey.isAcceptable()) { // 可以读 read(selector, selectionKey); } else if (selectionKey.isReadable()) { // 可以写 write(selector, selectionKey); } } catch (IOException e) { e.printStackTrace(); } }); selectionKeys.clear(); // 别忘了清空 } catch (Exception e) { e.printStackTrace(); } } } private static void write(Selector selector, SelectionKey selectionKey) throws IOException{ SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(512); int read = client.read(byteBuffer); if (read &gt; 0) { byteBuffer.flip(); Charset charset = Charset.forName(&quot;utf-8&quot;); String receiveMessage = String.valueOf(charset.decode(byteBuffer).array()); System.out.println(client + &quot;: &quot; + receiveMessage); String key = null; for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) { if (entry.getValue() == client) { key = entry.getKey(); break; } } for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) { SocketChannel value = entry.getValue(); ByteBuffer writeBuffer = ByteBuffer.allocate(1024); writeBuffer.put((key + &quot; :&quot; + receiveMessage).getBytes()); writeBuffer.flip(); value.write(writeBuffer); } } } private static void read(Selector selector, SelectionKey selectionKey) throws IOException{ ServerSocketChannel server = (ServerSocketChannel) selectionKey.channel(); System.out.println(server); SocketChannel client = server.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); String key = UUID.randomUUID().toString(); // 保存客户端 clientMap.put(key, client); }} 客服端/** * @Author: cuzz * @Date: 2019/1/8 17:10 * @Description: */public class NioClient { public static void main(String[] args){ try { SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); Selector selector = Selector.open(); socketChannel.register(selector, SelectionKey.OP_CONNECT); socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,8899)); while (true) { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys ) { if (selectionKey.isConnectable()) { SocketChannel client = (SocketChannel) selectionKey.channel(); if (client.isConnectionPending()) { client.finishConnect(); System.out.println(client); ByteBuffer writeBuffer = ByteBuffer.allocate(512); writeBuffer.put((LocalDateTime.now() + &quot; 连接成功&quot;).getBytes()); writeBuffer.flip(); client.write(writeBuffer); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(() -&gt; { while (true) { InputStreamReader inputStreamReader = new InputStreamReader(System.in); BufferedReader bf = new BufferedReader(inputStreamReader); String message = bf.readLine(); ByteBuffer buffer = ByteBuffer.allocate(512); buffer.put(message.getBytes()); buffer.flip(); client.write(buffer); } }); } client.register(selector, SelectionKey.OP_READ); } else if (selectionKey.isReadable()) { SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int read = client.read(byteBuffer); if (read &gt; 0) { String message = new String(byteBuffer.array()); System.out.println(message); } } } selectionKeys.clear(); } } catch (Exception e) { e.printStackTrace(); } }} 代码还是比较复杂的，Netty 内部就是把这些细节给封装起来了 Reactor模式翻译过来为反应器模式，可以先看看由 Doug Lea 写的 Scalable IO in Java ，更好的理解 Netty 的设计模式 还有一篇博客也写得很好，介绍相关理论模型，使用场景，基本组件、整体架构， 这可能是目前最透彻的Netty原理架构解析 Netty 那些事儿 ——— Reactor模式详解 Netty Reactor 工作架构图 bind() 方法前面通过 .channel(NioServerSocketChannel.class) 是为了通过反射创建一个 NioServerSocketChannel 对象 NioServerSocketChannel使用反射创建 NioServerSocketChannel 肯定是通过无参数构造器，在调用 newSocket(DEFAULT_SELECTOR_PROVIDER) 所以这是一个静态方法，返回一个 ServerSocketChannel /** * A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses * NIO selector based implementation to accept new connections. */public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel { private static final ChannelMetadata METADATA = new ChannelMetadata(false, 16); private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); private static ServerSocketChannel newSocket(SelectorProvider provider) { try { /** * Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in * {@link SelectorProvider#provider()} which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href=&quot;https://github.com/netty/netty/issues/2308&quot;&gt;#2308&lt;/a&gt;. */ return provider.openServerSocketChannel(); } catch (IOException e) { throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); } } private final ServerSocketChannelConfig config; /** * Create a new instance */ public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); } /** * Create a new instance using the given {@link SelectorProvider}. */ public NioServerSocketChannel(SelectorProvider provider) { this(newSocket(provider)); } /** * Create a new instance using the given {@link ServerSocketChannel}. */ public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); } ...} AbstractNioChannel我们回到调用的这个构造方法上 public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 一直调用父类，把 SelectionKey.OP_ACCEPT 设置上，还有设置非堵塞，是不出是很熟悉，这都是对 NIO 进行封装 io.netty.channel.nio.AbstractNioChannel#AbstractNioChannel protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { ... }} 再调用父类，就是设置 Id 和创建管道 io.netty.channel.AbstractChannel protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} NioServerSocketChannelConfig我们在回到这个构造方法上，我们重点来看看这个， NioServerSocketChannelConfig 这是一个配置类，Netty 的各种各样的信息都是体现在这个里面 public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 把自己和刚开始创建的 NIOSocketChannel 的 ServerSocket 对象传入进去 io.netty.channel.DefaultChannelConfig public DefaultChannelConfig(Channel channel) { this(channel, new AdaptiveRecvByteBufAllocator());} 传了一个 AdaptiveRecvByteBufAllocator 翻译过来可以叫可适配的接受字节缓冲适配器 AdaptiveRecvByteBufAllocatorio.netty.channel.AdaptiveRecvByteBufAllocator 文档： The RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.It gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction. 构造方法，默认是1024，最小是63，最大是65536 /** * Creates a new predictor with the default parameters. With the default * parameters, the expected buffer size starts from {@code 1024}, does not * go down below {@code 64}, and does not go up above {@code 65536}. */public AdaptiveRecvByteBufAllocator() { this(DEFAULT_MINIMUM, DEFAULT_INITIAL, DEFAULT_MAXIMUM);} 我们在看看里面的内部类 private final class HandleImpl extends MaxMessageHandle { private final int minIndex; private final int maxIndex; private int index; private int nextReceiveBufferSize; private boolean decreaseNow; public HandleImpl(int minIndex, int maxIndex, int initial) { this.minIndex = minIndex; this.maxIndex = maxIndex; index = getSizeTableIndex(initial); nextReceiveBufferSize = SIZE_TABLE[index]; } @Override public int guess() { return nextReceiveBufferSize; } private void record(int actualReadBytes) { if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) { if (decreaseNow) { index = Math.max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } else { decreaseNow = true; } } else if (actualReadBytes &gt;= nextReceiveBufferSize) { index = Math.min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } } @Override public void readComplete() { record(totalBytesRead()); }} 其父亲 MaxMessageHandle 中，根据记录中的分配，计算出下一次分配的内存 @Overridepublic ByteBuf allocate(ByteBufAllocator alloc) { return alloc.ioBuffer(guess());} 根据系统的支持返回是堆内内存还是堆外内存 @Overridepublic ByteBuf ioBuffer(int initialCapacity) { if (PlatformDependent.hasUnsafe()) { return directBuffer(initialCapacity); } return heapBuffer(initialCapacity);} Pipeline我们回到前面管道的创建 io.netty.channel.AbstractChannel protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} io.netty.channel.DefaultChannelPipeline#DefaultChannelPipeline protected DefaultChannelPipeline(Channel channel) { this.channel = ObjectUtil.checkNotNull(channel, &quot;channel&quot;); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;} 这里维护了一个上下文，并且把 Channel 对象赋值给自己，所以 Channel 和 Pipeline 是相互引用的 ChannelPipelineio.netty.channel.ChannelPipeline 文档： A list of ChannelHandlers which handles or intercepts inbound events and outbound operations of a Channel. ChannelPipeline implements an advanced form of the Intercepting Filter pattern to give a user full control over how an event is handled and how the ChannelHandlers in a pipeline interact with each other. Creation of a pipeline Each channel has its own pipeline and it is created automatically when a new channel is created. How an event flows in a pipeline The following diagram describes how I/O events are processed by ChannelHandlers in a ChannelPipeline typically. An I/O event is handled by either a ChannelInboundHandler or a ChannelOutboundHandler and be forwarded to its closest handler by calling the event propagation methods defined in ChannelHandlerContext, such as ChannelHandlerContext.fireChannelRead(Object) and ChannelHandlerContext.write(Object). I/O Request via Channel or ChannelHandlerContext |+---------------------------------------------------+---------------+| ChannelPipeline | || \\|/ || +---------------------+ +-----------+----------+ || | Inbound Handler N | | Outbound Handler 1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler N-1 | | Outbound Handler 2 | || +----------+----------+ +-----------+----------+ || /|\\ . || . . || ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|| [ method call] [method call] || . . || . \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 2 | | Outbound Handler M-1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 1 | | Outbound Handler M | || +----------+----------+ +-----------+----------+ || /|\\ | |+---------------+-----------------------------------+---------------+ | \\|/+---------------+-----------------------------------+---------------+| | | || [ Socket.read() ] [ Socket.write() ] || || Netty Internal I/O Threads (Transport Implementation) |+-------------------------------------------------------------------+ An inbound event is handled by the inbound handlers in the bottom-up direction as shown on the left side of the diagram. An inbound handler usually handles the inbound data generated by the I/O thread on the bottom of the diagram. The inbound data is often read from a remote peer via the actual input operation such as SocketChannel.read(ByteBuffer). If an inbound event goes beyond the top inbound handler, it is discarded silently, or logged if it needs your attention. An outbound event is handled by the outbound handler in the top-down direction as shown on the right side of the diagram. An outbound handler usually generates or transforms the outbound traffic such as write requests. If an outbound event goes beyond the bottom outbound handler, it is handled by an I/O thread associated with the Channel. The I/O thread often performs the actual output operation such as SocketChannel.write(ByteBuffer) For example, let us assume that we created the following pipeline: ChannelPipeline p = ...;p.addLast(&quot;1&quot;, new InboundHandlerA());p.addLast(&quot;2&quot;, new InboundHandlerB());p.addLast(&quot;3&quot;, new OutboundHandlerA());p.addLast(&quot;4&quot;, new OutboundHandlerB());p.addLast(&quot;5&quot;, new InboundOutboundHandlerX()); In the example above, the class whose name starts with Inbound means it is an inbound handler. The class whose name starts with Outbound means it is a outbound handler. In the given example configuration, the handler evaluation order is 1, 2, 3, 4, 5 when an event goes inbound. When an event goes outbound, the order is 5, 4, 3, 2, 1. On top of this principle, ChannelPipeline skips the evaluation of certain handlers to shorten the stack depth: 3 and 4 don’t implement ChannelInboundHandler, and therefore the actual evaluation order of an inbound event will be: 1, 2, and 5. 1 and 2 don’t implement ChannelOutboundHandler, and therefore the actual evaluation order of a outbound event will be: 5, 4, and 3. If 5 implements both ChannelInboundHandler and ChannelOutboundHandler, the evaluation order of an inbound and a outbound event could be 125 and 543 respectively. Forwarding an event to the next handler As you might noticed in the diagram shows, a handler has to invoke the event propagation methods in ChannelHandlerContext to forward an event to its next handler. Those methods include: Inbound event propagation methods ChannelHandlerContext.fireChannelRegistered() hannelHandlerContext.fireChannelActive() ChannelHandlerContext.fireChannelRead(Object) ChannelHandlerContext.fireChannelReadComplete() ChannelHandlerContext.fireExceptionCaught(Throwable) ChannelHandlerContext.fireUserEventTriggered(Object) ChannelHandlerContext.fireChannelWritabilityChanged() ChannelHandlerContext.fireChannelInactive() ChannelHandlerContext.fireChannelUnregistered() Outbound event propagation methods: ChannelHandlerContext.bind(SocketAddress, ChannelPromise) ChannelHandlerContext.connect(SocketAddress, SocketAddress, ChannelPromise) ChannelHandlerContext.write(Object, ChannelPromise) ChannelHandlerContext.flush() ChannelHandlerContext.read() ChannelHandlerContext.disconnect(ChannelPromise) ChannelHandlerContext.close(ChannelPromise) ChannelHandlerContext.deregister(ChannelPromise) and the following example shows how the event propagation is usually done: public class MyInboundHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) { System.out.println(&quot;Connected!&quot;); ctx.fireChannelActive(); }}public class MyOutboundHandler extends ChannelOutboundHandlerAdapter { @Override public void close(ChannelHandlerContext ctx, ChannelPromise promise) { System.out.println(&quot;Closing ..&quot;); ctx.close(promise); }} Building a pipeline (重点) A user is supposed to have one or more ChannelHandlers in a pipeline to receive I/O events (e.g. read) and to request I/O operations (e.g. write and close). For example, a typical server will have the following handlers in each channel’s pipeline, but your mileage may vary depending on the complexity and characteristics of the protocol and business logic: Protocol Decoder - translates binary data (e.g. ByteBuf) into a Java object. Protocol Encoder - translates a Java object into binary data. Business Logic Handler - performs the actual business logic (e.g. database access). and it could be represented as shown in the following example: static final EventExecutorGroup group = new DefaultEventExecutorGroup(16);...ChannelPipeline pipeline = ch.pipeline();pipeline.addLast(&quot;decoder&quot;, new MyProtocolDecoder());pipeline.addLast(&quot;encoder&quot;, new MyProtocolEncoder());// Tell the pipeline to run MyBusinessLogicHandler's event handler methods// in a different thread than an I/O thread so that the I/O thread is not blocked by// a time-consuming task.// If your business logic is fully asynchronous or finished very quickly, you don't// need to specify a group.pipeline.addLast(group, &quot;handler&quot;, new MyBusinessLogicHandler()); 注：可以使用重载这个方法添加一个事件循环组 group 去执行耗时的任务，获取在 MyBusinessLogicHandler 中把耗时部分异步处理，这样就不会堵塞 IO 线程 Thread safety A ChannelHandler can be added or removed at any time because a ChannelPipeline is thread safe. For example, you can insert an encryption handler when sensitive information is about to be exchanged, and remove it after the exchange. 对于传统的过滤器如 SpringMVC 比如我们配置了 Filter1 Filter2 Filter3 过滤器，请求和返回都要经过滤器这3个过滤器，而管道可以选择的其中某些作为请求的过滤器，一些作为返回的过滤器，不一定要一样，入站的处理器专门处理入站的，出站的处理器专门处理出站的 init() 方法io.netty.bootstrap.ServerBootstrap#init @Overridevoid init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ...} ChannelOption类图 io.netty.channelpublic class ChannelOptionextends AbstractConstant&lt;ChannelOption&gt; A ChannelOption allows to configure a ChannelConfig in a type-safe way. Which ChannelOption is supported depends on the actual implementation of ChannelConfig and may depend on the nature of the transport it belongs to. Type parameters: - the type of the value which is valid for the ChannelOption ChannelOption &lt;T&gt; 主要维护 TCP/IP 的一些底层的设定，T 表示值的类型 ChannelOption 继承了 AbstractConstant， AbstractConstant 有是 Constant 的一个基本的实现 io.netty.util.Constant io.netty.utilpublic interface Constant&lt;T extends Constant&gt;extends Comparable A singleton which is safe to compare via the == operator. Created and managed by ConstantPool. Type parameters: - the type of objects that this object may be compared to 我们可以知道这个常量是由 ConstantPool 来维持的，我看看他是怎么起作用的 io.netty.util.ConstantPool public abstract class ConstantPool&lt;T extends Constant&lt;T&gt;&gt; { private final ConcurrentMap&lt;String, T&gt; constants = PlatformDependent.newConcurrentHashMap(); private final AtomicInteger nextId = new AtomicInteger(1); /** * Shortcut of {@link #valueOf(String) valueOf(firstNameComponent.getName() + &quot;#&quot; + secondNameComponent)}. */ public T valueOf(Class&lt;?&gt; firstNameComponent, String secondNameComponent) { if (firstNameComponent == null) { throw new NullPointerException(&quot;firstNameComponent&quot;); } if (secondNameComponent == null) { throw new NullPointerException(&quot;secondNameComponent&quot;); } return valueOf(firstNameComponent.getName() + '#' + secondNameComponent); } /** * Returns the {@link Constant} which is assigned to the specified {@code name}. * If there's no such {@link Constant}, a new one will be created and returned. * Once created, the subsequent calls with the same {@code name} will always return the previously created one * (i.e. singleton.) * * @param name the name of the {@link Constant} */ public T valueOf(String name) { checkNotNullAndNotEmpty(name); return getOrCreate(name); } /** * Get existing constant by name or creates new one if not exists. Threadsafe * * @param name the name of the {@link Constant} */ private T getOrCreate(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } return constant; } /** * Returns {@code true} if a {@link AttributeKey} exists for the given {@code name}. */ public boolean exists(String name) { checkNotNullAndNotEmpty(name); return constants.containsKey(name); } /** * Creates a new {@link Constant} for the given {@code name} or fail with an * {@link IllegalArgumentException} if a {@link Constant} for the given {@code name} exists. */ public T newInstance(String name) { checkNotNullAndNotEmpty(name); return createOrThrow(name); } /** * Creates constant by name or throws exception. Threadsafe * * @param name the name of the {@link Constant} */ private T createOrThrow(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } throw new IllegalArgumentException(String.format(&quot;'%s' is already in use&quot;, name)); } private static String checkNotNullAndNotEmpty(String name) { ObjectUtil.checkNotNull(name, &quot;name&quot;); if (name.isEmpty()) { throw new IllegalArgumentException(&quot;empty name&quot;); } return name; } protected abstract T newConstant(int id, String name); @Deprecated public final int nextId() { return nextId.getAndIncrement(); }} 我们先看这个创建方法 /** * Get existing constant by name or creates new one if not exists. Threadsafe * * @param name the name of the {@link Constant} */private T getOrCreate(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } return constant;} 这里使用了双重检验机制，这个常量池保存的值是一个 T extends Constant&lt;T&gt; 包装过后的 io.netty.util.ConstantPool#newConstant 新建一个常量是由子类完成的，我们回到 ChannelOption 类中，**ChannelOption 是不保存值的，只是维护键的包装** AttributeKeyio.netty.util.AttributeKey io.netty.utilpublic final class AttributeKeyextends AbstractConstant&lt;AttributeKey&gt; Key which can be used to access Attribute out of the AttributeMap. Be aware that it is not be possible to have multiple keys with the same name. Type parameters: - the type of the Attribute which can be accessed via this AttributeKey. 与 ChannelOption 很相似，AttributeMap ，AttributeKey ，Attribute 相当一个 Map，key 和 value /** * Holds {@link Attribute}s which can be accessed via {@link AttributeKey}. * * Implementations must be Thread-safe. */public interface AttributeMap { /** * Get the {@link Attribute} for the given {@link AttributeKey}. This method will never return null, but may return * an {@link Attribute} which does not have a value set yet. */ &lt;T&gt; Attribute&lt;T&gt; attr(AttributeKey&lt;T&gt; key); /** * Returns {@code} true if and only if the given {@link Attribute} exists in this {@link AttributeMap}. */ &lt;T&gt; boolean hasAttr(AttributeKey&lt;T&gt; key);} 主要维护的是业务数据，可以在程序运行中动态的往里面添加数据和获取数据 ChannelInitializerio.netty.bootstrap.ServerBootstrap#init 回到 init 方法上 @Overridevoid init(Channel channel) throws Exception { ChannelPipeline p = channel.pipeline(); ... p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } });} 获取管道添加了一个 ChannelInitializer 实例，先看看这个类 io.netty.channel.ChannelInitializer io.netty.channel@Sharablepublic abstract class ChannelInitializerextends ChannelInboundHandlerAdapter A special ChannelInboundHandler which offers an easy way to initialize a Channel once it was registered to its EventLoop. Implementations are most often used in the context of Bootstrap.handler(ChannelHandler) , ServerBootstrap.handler(ChannelHandler) and ServerBootstrap.childHandler(ChannelHandler) to setup the ChannelPipeline of a Channel. public class MyChannelInitializer extends ChannelInitializer { public void initChannel(Channel channel) { channel.pipeline().addLast(&quot;myHandler&quot;, new MyHandler()); }}ServerBootstrap bootstrap = ...;...bootstrap.childHandler(new MyChannelInitializer());... Be aware that this class is marked as ChannelHandler.Sharable and so the implementation must be safe to be re-used. Type parameters: - A sub-type of Channel addLast() 方法io.netty.channel.DefaultChannelPipeline#addLast @Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } callHandlerAdded0(newCtx); return this;} AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系。 加油！！！","link":"/2019/01/15/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"深入理解 synchronized 关键字","text":"如果某一个资源被多个线程共享，为了避免因为资源抢占导致资源数据错乱，我们需要对线程进行同步，那么synchronized就是实现线程同步的关键字，是用来保证被锁定了代码同一时间只能有一个线程执行，那么synchronized关键字的实现原理是怎样的呢？ 先给出一张图，看看 synchronized 这个关键字有多复杂，先看看能看懂多少，如果看不太懂，希望看完本文能真正理解 synchronized 关键字和这张图。 synchronized 用法synchronized 在用法上可以分为如下四种：普通方法、对象、静态方法和类。 1、普通方法 public synchronized void method() {} 2、对象 public void method() { synchronized(obj) { }} 3、静态方法 public static synchronized void method() {} 4、类 public static void method() { synchronized(Obj.class) { }} 但是我们要知道，syncnronized 锁的并不是代码块而是对象，锁静态方法也是锁住这个类。 synchronized 特性 原子性 可见性 有序性 可重入性 synchronized 实现原理字节码通过查看字节码来看看 synchronized 在字节码程度实现。 1、先看看在 synchronized 修饰在方法上 public synchronized void method() {} 我们进入到编译后的 classes 目录下，找到对应的类，使用 javap -v XX.class public synchronized void method(); descriptor: ()V flags: (0x0021) ACC_PUBLIC, ACC_SYNCHRONIZED // 注意这个 Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this Lcom/cuzz/syn/Test; 我们发现在 flags 上有一个 ACC_SYNCHRONIZED 标识。 2、对象上 public void method() { synchronized(obj) { }} 反编译结果，在字节码成面上有 monitorenter 和 monitorexit，其中后面一个 monitorexit 表示异常退出。 public void method(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: getfield #3 4: dup 5: astore_1 6: monitorenter // ---&gt; 进入 7: aload_1 8: monitorexit // ---&gt; 退出 9: goto 17 12: astore_2 13: aload_1 14: monitorexit // ---&gt; 异常退出 15: aload_2 16: athrow 17: return montor1、monitorenter JVM 规范中描述 Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows: If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor. If the thread already owns the monitor associated with objectref， it reenters the monitor， incrementing its entry count. If another thread already owns the monitor associated with objectref， the thread blocks until the monitor’s entry count is zero， then tries again to gain ownership. 2、monitorexit JVM 规范中描述 The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref. The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero， the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so. 小结通过 javap 反汇编我们看到 synchronized 使用编程了 monitorentor 和 monitorexit 两个指令： 每个锁对象都会关联一个 monitor （监视器它才是真正的锁对象）。 它内部有两个重要的成员变量 owner 会保存获得锁的线程，recursions 会保存线程获得锁的次数。 当执行到 monitorenter 时，recursions 会+1；当执行到 monitorexit 时，recursions会-1，当计数器减到 0 时这个线程就会释放锁。 同步方法在反汇编后，会增加 ACC_SYNCHRONIZED 修饰，会隐式调用 monitorenter 和 monitorexit。在执行同步方法前会调用 monitorenter，在执行完同步方法后会调用 monitorexit。 深入 JVM 源码monitor 监视锁先下载 JVM 源码， https://github.com/openjdk/jdk 导入 CLion 中，切到 1.8 tag 上。 在HotSpot虚拟机中，monitor 是由 ObjectMonitor 实现的。其源码是用 C++ 来实现的，位于HotSpot虚 拟机源码 ObjectMonitor.hpp 文件中(src/share/vm/runtime/objectMonitor.hpp)。ObjectMonitor 主要数据结构如下: ObjectMonitor() { _header = NULL; _count = 0; // 用来记录该对象被线程获取锁的次数 _waiters = 0, _recursions = 0; // 线程的重入次数 _object = NULL; // 储存改monitor的对象 _owner = NULL; // 标识拥有该monitor的线程 _WaitSet = NULL; // 处于wait状态的线程，会加入到其中 _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; // 多线程竞争锁的单向列表 FreeNext = NULL ; _EntryList = NULL ; // 处于等待锁block状态的线程，会加入该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;} 关键属性解释： _owner：初始时为NULL，当有线程占有该monitor时，owner标记为该线程的唯一标识。当线程释放monitor时，owner又恢复为NULL，owner是一个临界资源，JVM是通过CAS操作来保证其线程安全的。 _cxq：竞争队列，所有请求锁的线程首先会被放在这个队列中（单向链表）。_cxq是一个临界资 源，JVM通过CAS原子指令来修改_cxq队列。修改前_cxq的旧值填入了node的next字段，_cxq指向新值(新线程)。因此_cxq是一个后进先出的栈。 _EntryList：_cxq队列中有资格成为候选资源的线程会被移动到该队列中。 _WaitSet：因为调用wait方法而被阻塞的线程会被放在该队列中。 具体过程： 当多个线程同时访问该方法，那么这些线程会先被放进_EntryList队列，此时线程处于blocking状态 当一个线程获取到了实例对象的监视器（monitor）锁，那么就可以进入running状态，执行方法，此时，ObjectMonitor对象_owner指向当前线程，_count加1表示当前对象锁被一个线程获取 当running状态的线程调用wait()方法，那么当前线程释放monitor对象，进入waiting状态，ObjectMonitor对象的_owner变为null，同时线程进入_WaitSet队列，直到有线程调用notify()方法唤醒该线程，则该线程重新获取monitor对象进入_Owner区 如果当前线程执行完毕，那么也释放monitor对象，进入waiting状态，ObjectMonitor对象的_owner变为 null ObjectMonitor 的数据结构中包含：_owner、_WaitSet 和 _EntryList，它们之间的关系转换可以用下图表示: 每一个 Java 对象都可以与一个监视器 monitor 关联，我们可以把它理解成为一把锁，当一个线程想要执行一段被 synchronized 圈起来的同步方法或者代码块时，该线程得先获取到 synchronized 修饰的对象对应的monitor。 我们的 Java 代码里不会显示地去创造这么一个monitor对象，我们也无需创建，事实上可以这么理解： monitor并不是随着对象创建而创建的。 我们是通过synchronized修饰符告诉 JVM 需要为我们的某个对象创建关联的monitor对象。 每个线程都存在两个ObjectMonitor 对象列表，分别为free和used列表。 同时JVM中也维护着global locklist。 当线程需要ObjectMonitor对象时，首先从线程自身的free表中申请，若存在则使用，若不存在则从global list中申请。 monitor 竞争在字节码上 monitorenter，最终会调用 InterpreterRuntime.cpp IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) { Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); } Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), &quot;must be NULL or an object&quot;); // 是否使用偏向锁 if (UseBiasedLocking) { // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); } else { ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); } assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), &quot;must be NULL or an object&quot;);#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END 最终调用 ObjectMonitor::enter 方法 void ATTR ObjectMonitor::enter(TRAPS) { // The following code is ordered to check the most common cases first // and to reduce RTS-&gt;RTO cache line upgrades on SPARC and IA32 processors. Thread * const Self = THREAD ; void * cur ; // _owner为NULL表示无锁 // 通过CAS操作吧monitor的_owner字段设置为当前线程 // 这个会根据不同的操作系统有不同的实现如果是Linux，则在atomic_linux_x86.inline.hpp中 // 返回旧值 cur = Atomic::cmpxchg_ptr (Self, &amp;_owner, NULL) ; // 设置成功 if (cur == NULL) { // Either ASSERT _recursions == 0 or explicitly set _recursions = 0. assert (_recursions == 0 , &quot;invariant&quot;) ; assert (_owner == Self, &quot;invariant&quot;) ; // CONSIDER: set or assert OwnerIsThread == 1 return ; } // 线程重入，_recursions++ if (cur == Self) { // TODO-FIXME: check for integer overflow! BUGID 6557169. _recursions ++ ; return ; } // 如果当前线程是第一次进入该monitor,设置_recursions为1，_owner为当前线程 // 当前线程是之前持有轻量级锁的线程。由轻量级锁膨胀且第一次调用enter方法，那cur是指向Lock Record的指针 if (Self-&gt;is_lock_owned ((address)cur)) { assert (_recursions == 0, &quot;internal state error&quot;); _recursions = 1 ; // Commute owner from a thread-specific on-stack BasicLockObject address to // a full-fledged &quot;Thread *&quot;. _owner = Self ; OwnerIsThread = 1 ; return ; } ... // 在调用系统的同步操作之前，先尝试自旋获得锁 if (Knob_SpinEarly &amp;&amp; TrySpin (Self) &gt; 0) { ... //自旋的过程中获得了锁，则直接返回 Self-&gt;_Stalled = 0 ; return ; } // 通过自旋执行ObjectMonitor::EnterI方法等待锁的释放 for (;;) { jt-&gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() // or java_suspend_self() EnterI (THREAD) ; if (!ExitSuspendEquivalent(jt)) break ; // // We have acquired the contended monitor, but while we were // waiting another thread suspended us. We don't want to enter // the monitor while suspended because that would surprise the // thread that suspended us. // _recursions = 0 ; _succ = NULL ; exit (Self) ; jt-&gt;java_suspend_self(); } Self-&gt;set_current_pending_monitor(NULL);} 代码具体逻辑： 通过CAS尝试吧monItor的_owner设置为当前线程 如果设置之前的_owner指向当前线程，说明线程再次进入monitor，为重入锁，_recursions++，记录重入得次数 如果当前线程是第一次进入monitor，设置_recursions为1，_owner为当前线程，改线程获得锁 如果获得锁失败，则等待锁的释放 monitor 等待竞争失败等待调用的是ObjectMonitor对象的EnterI方法。 void ATTR ObjectMonitor::EnterI (TRAPS) { Thread * Self = THREAD ; ... // 尝试获得锁 if (TryLock (Self) &gt; 0) { ... return ; } DeferredInitialize () ; // 自旋 if (TrySpin (Self) &gt; 0) { ... return ; } ... // 将线程封装成node节点中 ObjectWaiter node(Self) ; Self-&gt;_ParkEvent-&gt;reset() ; node._prev = (ObjectWaiter *) 0xBAD ; node.TState = ObjectWaiter::TS_CXQ ; // 将node节点插入到_cxq队列的头部，cxq是一个单向链表 ObjectWaiter * nxt ; for (;;) { node._next = nxt = _cxq ; if (Atomic::cmpxchg_ptr (&amp;node, &amp;_cxq, nxt) == nxt) break ; // CAS失败的话 再尝试获得锁，这样可以降低插入到_cxq队列的频率 if (TryLock (Self) &gt; 0) { ... return ; } } // SyncFlags默认为0，如果没有其他等待的线程，则将_Responsible设置为自己 if ((SyncFlags &amp; 16) == 0 &amp;&amp; nxt == NULL &amp;&amp; _EntryList == NULL) { Atomic::cmpxchg_ptr (Self, &amp;_Responsible, NULL) ; } TEVENT (Inflated enter - Contention) ; int nWakeups = 0 ; int RecheckInterval = 1 ; for (;;) { // 线程在被挂起前再尝试一次，看能不能获得到锁 if (TryLock (Self) &gt; 0) break ; assert (_owner != Self, &quot;invariant&quot;) ; ... // park self if (_Responsible == Self || (SyncFlags &amp; 1)) { // 当前线程是_Responsible时，调用的是带时间参数的park TEVENT (Inflated enter - park TIMED) ; Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; // Increase the RecheckInterval, but clamp the value. RecheckInterval *= 8 ; if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; } else { //否则直接调用park挂起当前线程 TEVENT (Inflated enter - park UNTIMED) ; Self-&gt;_ParkEvent-&gt;park() ; } if (TryLock(Self) &gt; 0) break ; ... if ((Knob_SpinAfterFutile &amp; 1) &amp;&amp; TrySpin (Self) &gt; 0) break ; ... // 在释放锁时，_succ会被设置为EntryList或_cxq中的一个线程 if (_succ == Self) _succ = NULL ; // Invariant: after clearing _succ a thread *must* retry _owner before parking. OrderAccess::fence() ; } // 走到这里说明已经获得锁了 assert (_owner == Self , &quot;invariant&quot;) ; assert (object() != NULL , &quot;invariant&quot;) ; // 将当前线程的node从cxq或EntryList中移除 UnlinkAfterAcquire (Self, &amp;node) ; if (_succ == Self) _succ = NULL ; if (_Responsible == Self) { _Responsible = NULL ; OrderAccess::fence(); } ... return ;} 当线程被唤醒时，会从挂起点继续执行，通过ObjectMonitor::TryLock尝试获取锁。 int ObjectMonitor::TryLock (Thread * Self) { for (;;) { void * own = _owner ; if (own != NULL) return 0 ; if (Atomic::cmpxchg_ptr (Self, &amp;_owner, NULL) == NULL) { // Either guarantee _recursions == 0 or set _recursions = 0. assert (_recursions == 0, &quot;invariant&quot;) ; assert (_owner == Self, &quot;invariant&quot;) ; // CONSIDER: set or assert that OwnerIsThread == 1 return 1 ; } // The lock had been free momentarily, but we lost the race to the lock. // Interference -- the CAS failed. // We can either return -1 or retry. // Retry doesn't make as much sense because the lock was just acquired. if (true) return -1 ; }} 上面代码具体流程： 将当前线程插入到cxq队列的队首 然后park当前线程 当被唤醒后再尝试获得锁 monitor 释放当某个持有锁的线程执行完同步代码块时，会进行锁的释放，给其它线程机会执行同步代码，在 HotSpot中，通过退出monitor的方式实现锁的释放，并通知被阻塞的线程，具体实现位于 ObjectMonitor的exit方法中。 void ATTR ObjectMonitor::exit(TRAPS) { Thread * Self = THREAD ; ... // 看看_recursions 是否为0 if (_recursions != 0) { _recursions--; // this is simple recursive enter TEVENT (Inflated exit - recursive) ; return ; } // Invariant: after setting Responsible=null an thread must execute // a MEMBAR or other serializing instruction before fetching EntryList|cxq. if ((SyncFlags &amp; 4) == 0) { _Responsible = NULL ; } for (;;) { assert (THREAD == _owner, &quot;invariant&quot;) ; guarantee (_owner == THREAD, &quot;invariant&quot;) ; ObjectWaiter * w = NULL ; int QMode = Knob_QMode ; // QMode = 2:直接绕过EntryList队列，从_cxq队列中获取线程用于竞争锁 if (QMode == 2 &amp;&amp; _cxq != NULL) { w = _cxq ; assert (w != NULL, &quot;invariant&quot;) ; assert (w-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; ExitEpilog (Self, w) ; return ; } // Qmode = 3: _cxq队列插入EntryList尾部 if (QMode == 3 &amp;&amp; _cxq != NULL) { w = _cxq ; for (;;) { assert (w != NULL, &quot;Invariant&quot;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, &amp;_cxq, w) ; if (u == w) break ; w = u ; } assert (w != NULL , &quot;invariant&quot;) ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) { guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; } // Append the RATs to the EntryList // TODO: organize EntryList as a CDLL so we can locate the tail in constant-time. ObjectWaiter * Tail ; for (Tail = _EntryList ; Tail != NULL &amp;&amp; Tail-&gt;_next != NULL ; Tail = Tail-&gt;_next) ; if (Tail == NULL) { _EntryList = w ; } else { Tail-&gt;_next = w ; w-&gt;_prev = Tail ; } // Fall thru into code that tries to wake a successor from EntryList } // Qmode = 4: _cxq队列插入EntryList头部 if (QMode == 4 &amp;&amp; _cxq != NULL) { w = _cxq ; for (;;) { assert (w != NULL, &quot;Invariant&quot;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, &amp;_cxq, w) ; if (u == w) break ; w = u ; } assert (w != NULL , &quot;invariant&quot;) ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) { guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; } // Prepend the RATs to the EntryList if (_EntryList != NULL) { q-&gt;_next = _EntryList ; _EntryList-&gt;_prev = q ; } _EntryList = w ; // Fall thru into code that tries to wake a successor from EntryList } w = _EntryList ; if (w != NULL) { assert (w-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; ExitEpilog (Self, w) ; return ; } // If we find that both _cxq and EntryList are null then just // re-run the exit protocol from the top. w = _cxq ; if (w == NULL) continue ; // Drain _cxq into EntryList - bulk transfer. // First, detach _cxq. // The following loop is tantamount to: w = swap (&amp;cxq, NULL) for (;;) { assert (w != NULL, &quot;Invariant&quot;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, &amp;_cxq, w) ; if (u == w) break ; w = u ; } TEVENT (Inflated exit - drain cxq into EntryList) ; assert (w != NULL , &quot;invariant&quot;) ; assert (_EntryList == NULL , &quot;invariant&quot;) ; // QMode = 1 : 将_cxq中的元素转移到EntryList，并反转顺序 if (QMode == 1) { // QMode == 1 : drain cxq to EntryList, reversing order // We also reverse the order of the list. ObjectWaiter * s = NULL ; ObjectWaiter * t = w ; ObjectWaiter * u = NULL ; while (t != NULL) { guarantee (t-&gt;TState == ObjectWaiter::TS_CXQ, &quot;invariant&quot;) ; t-&gt;TState = ObjectWaiter::TS_ENTER ; u = t-&gt;_next ; t-&gt;_prev = u ; t-&gt;_next = s ; s = t; t = u ; } _EntryList = s ; assert (s != NULL, &quot;invariant&quot;) ; } else { // QMode == 0 or QMode == 2 _EntryList = w ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) { guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; } } // In 1-0 mode we need: ST EntryList; MEMBAR #storestore; ST _owner = NULL // The MEMBAR is satisfied by the release_store() operation in ExitEpilog(). // See if we can abdicate to a spinner instead of waking a thread. // A primary goal of the implementation is to reduce the // context-switch rate. if (_succ != NULL) continue; w = _EntryList ; if (w != NULL) { guarantee (w-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; ExitEpilog (Self, w) ; return ; } }} 退出同步代码块时会让_recursions减1，当_recursions的值减为0时，说明线程释放了锁。 根据不同的策略(由QMode指定)，从cxq或EntryList中获取头节点，通过ObjectMonitor::ExitEpilog 方法唤醒该节点封装的线程，唤醒操作最终由unpark完成，实现如下: void ObjectMonitor::ExitEpilog (Thread * Self, ObjectWaiter * Wakee) { assert (_owner == Self, &quot;invariant&quot;) ; // Exit protocol: // 1. ST _succ = wakee // 2. membar #loadstore|#storestore; // 2. ST _owner = NULL // 3. unpark(wakee) _succ = Knob_SuccEnabled ? Wakee-&gt;_thread : NULL ; ParkEvent * Trigger = Wakee-&gt;_event ; // Hygiene -- once we've set _owner = NULL we can't safely dereference Wakee again. // The thread associated with Wakee may have grabbed the lock and &quot;Wakee&quot; may be // out-of-scope (non-extant). Wakee = NULL ; // Drop the lock OrderAccess::release_store_ptr (&amp;_owner, NULL) ; OrderAccess::fence() ; // ST _owner vs LD in unpark() if (SafepointSynchronize::do_call_back()) { TEVENT (unpark before SAFEPOINT) ; } DTRACE_MONITOR_PROBE(contended__exit, this, object(), Self); // 唤醒之前被pack()挂起的线程 Trigger-&gt;unpark() ; // Maintain stats and report events to JVMTI if (ObjectMonitor::_sync_Parks != NULL) { ObjectMonitor::_sync_Parks-&gt;inc() ; }} 被唤醒的线程，会回到EnterI方法中的继续执行monitor的竞争。 for (;;) { if (TryLock (Self) &gt; 0) break ; assert (_owner != Self, &quot;invariant&quot;) ; if ((SyncFlags &amp; 2) &amp;&amp; _Responsible == NULL) { Atomic::cmpxchg_ptr (Self, &amp;_Responsible, NULL) ; } // park self if (_Responsible == Self || (SyncFlags &amp; 1)) { TEVENT (Inflated enter - park TIMED) ; Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; // Increase the RecheckInterval, but clamp the value. RecheckInterval *= 8 ; if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; } else { TEVENT (Inflated enter - park UNTIMED) ; Self-&gt;_ParkEvent-&gt;park() ; } if (TryLock(Self) &gt; 0) break ; ...} monitor是重量级锁可以看到ObjectMonitor的函数调用中会涉及到Atomic::cmpxchg_ptr，Atomic::inc_ptr等内核函数， 执行同步代码块，没有竞争到锁的对象会park()被挂起，竞争到锁的线程会unpark()唤醒。这个时候就 会存在操作系统用户态和内核态的转换，这种切换会消耗大量的系统资源。所以synchronized是Java语 言中是一个重量级(Heavyweight)的操作。 用户态和和内核态是什么东西呢?要想了解用户态和内核态还需要先了解一下Linux系统的体系架构: 从上图可以看出，Linux操作系统的体系架构分为:用户空间(应用程序的活动空间)和内核。 内核：本质上可以理解为一种软件，控制计算机的硬件资源，并提供上层应用程序运行的环境。 用户空间：上层应用程序活动的空间。应用程序的执行必须依托于内核提供的资源，包括CPU资源、存 储资源、I/O资源等。 系统调用：为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口:即系统调用。 所有进程初始都运行于用户空间，此时即为用户运行状态(简称:用户态);但是当它调用系统调用执行某些操作时，例如 I/O调用，此时需要陷入内核中运行，我们就称进程处于内核运行态(或简称为内 核态)。 系统调用的过程可以简单理解为： 用户态程序将一些数据值放在寄存器中， 或者使用参数创建一个堆栈， 以此表明需要操作系统提 供的服务。 用户态程序执行系统调用。 CPU切换到内核态，并跳到位于内存指定位置的指令。 系统调用处理器(system call handler)会读取程序放入内存的数据参数，并执行程序请求的服务。 系统调用完成后，操作系统会重置CPU为用户态并返回系统调用的结果。由此可见用户态切换至内核态需要传递许多变量，同时内核还需要保护好用户态在切换时的一些寄存器 值、变量等，以备内核态切换回用户态。这种切换就带来了大量的系统资源消耗，这就是在 synchronized未优化之前，效率低的原因。 JVM 对 synchronzied 底层优化高效并发是从JDK 5到JDK 6的一个重要改进，HotSpot虛拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术，包括偏向锁( Biased Locking )、轻量级锁( Lightweight Locking )和如适应性自旋(Adaptive Spinning)、锁消除( Lock Elimination)、锁粗化( Lock Coarsening )等，这些技术都是为 了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。 具体源码分析推荐看这几篇文章：死磕Synchronized底层实现 CASCAS 全称是 compare and swap，是一种用于在多线程环境下实现同步功能的机制。CAS 操作包含三个操作数：内存位置、预期数值和新值。CAS 的实现逻辑是将内存位置处的数值与预期数值想比较，若相等，则将内存位置处的值替换为新值。若不相等，则不做任何操作。 在 Java 中，Java 并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的，Java 代码需通过 JNI 才能调用。 CAS实现并发，我们先看一段代码： public class AtomicTest { private static AtomicInteger atomicInteger = new AtomicInteger(); public static void main(String[] args) throws InterruptedException { Runnable r = () -&gt; { for (int i = 0; i &lt; 1000; i++) { atomicInteger.incrementAndGet(); } }; for (int i = 0; i &lt; 10; i++) { new Thread(r).start(); } Thread.sleep(1000); System.out.println(atomicInteger.get()); // 输出 10000 }} 底层是调用 jdk.internal.misc.Unsafe#getAndAddInt 这个方法 JAVA对象布局当一个线程尝试访问 synchronized 修饰的代码块时，它首先要获得锁，那么 这个锁到底存在哪里呢？ 是存在锁对象的对象头里。 java对象布局 JOL（java object layout）描述对象在堆内存的布局，如图所示： markword： 固定长度8字节，描述对象的 identityhashcode、GC分代年龄、锁的状态标志、线程持有的锁、偏向锁的线程ID和偏向时间戳等等； klasspoint： 固定长度4字节, 指定该对象的class类对象（默认使用-XX:+UseCompressedClassPointers 参数进行压缩，可使用-XX:-UseCompressedClassPointers关闭，则该字段在64位jvm下占用8个字节；可使用java -XX:+PrintCommandLineFlags -version 命令查看默认的或已设置的jvm参数）； 基本变量：用于存放java八种基本类型成员变量，以4字节步长进行补齐，使用内存重排序优化空间； 引用变量：存放对象地址，如String，Object；占用4个字节，64位jvm上默认使用-XX:+UseCompressedOops进行压缩，可使用-XX:-UseCompressedOops进行关闭，则在64位jvm上会占用8个字节； 补齐：对象大小必须是8字节的整数倍，用来补齐字节数。Object o = new Object() 在内存中占用16个字节，其中最后4个是补齐； 数组长度：如果是数组，额外占用固定4字节存放数组长度； jol-core 是 openjdk的一个工具，他可以很方便的让我看到一个对象的布局。 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们查看一下对象和数组 public class HeaderTest { public static void main(String[] args) { Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); System.out.println(&quot;===================&quot;); int[] arr = new int[1]; System.out.println(ClassLayout.parseInstance(arr).toPrintable()); }} 打印结果 java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total===================[I object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 10 0c 00 00 (00010000 00001100 00000000 00000000) (3088) 12 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 16 4 int [I.&lt;elements&gt; N/A 20 4 (loss due to the next object alignment)Instance size: 24 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total HotSpot采用instanceOopDesc和arrayOopDesc来描述对象头，arrayOopDesc对象用来描述数组类 型。instanceOopDesc的定义的在Hotspot源码的 instanceOop.hpp 文件中，另外，arrayOopDesc 的定义对应 arrayOop.hpp 。 class instanceOopDesc : public oopDesc { public: // aligned header size. static int header_size() { return sizeof(instanceOopDesc)/HeapWordSize; } // If compressed, the offset of the fields of the instance may not be aligned. static int base_offset_in_bytes() { return UseCompressedOops ? klass_gap_offset_in_bytes() : sizeof(instanceOopDesc); } static bool contains_field_offset(int offset, int nonstatic_field_size) { int base_in_bytes = base_offset_in_bytes(); return (offset &gt;= base_in_bytes &amp;&amp; (offset-base_in_bytes) &lt; nonstatic_field_size * heapOopSize); }}; 从instanceOopDesc代码中可以看到 instanceOopDesc继承自oopDesc，oopDesc的定义载Hotspot 源码中的 oop.hpp 文件中。 class oopDesc { friend class VMStructs; private: volatile markOop _mark; union _metadata { wideKlassOop _klass; narrowOop _compressed_klass; } _metadata; ... } 在普通实例对象中，oopDesc的定义包含两个成员，分别是 _mark 和 _metadata。 _mark 表示对象标记、属于markOop类型，也就是接下来要讲解的Mark World，它记录了对象和锁有关的信息。 _metadata 表示类元信息，类元信息存储的是对象指向它的类元数据(Klass)的首地址，其中Klass表示普通指针、 _compressed_klass 表示压缩类指针。 对象头由两部分组成，一部分用于存储自身的运行时数据，称之为 Mark Word，另外一部分是类型指针，及对象指向它的类元数据的指针。 我们看一下markOop.hpp 中对的描述： // 64 bits:// --------// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)// size:64 -----------------------------------------------------&gt;| (CMS free block)//// unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block)//// - hash contains the identity hash value: largest value is// 31 bits, see os::random(). Also, 64-bit vm's require// a hash value no bigger than 32 bits because they will not// properly generate a mask larger than that: see library_call.cpp// and c1_CodePatterns_sparc.cpp.//// - the biased lock pattern is used to bias a lock toward a given// thread. When this pattern is set in the low three bits, the lock// is either biased toward a given thread or &quot;anonymously&quot; biased,// indicating that it is possible for it to be biased. When the// lock is biased toward a given thread, locking and unlocking can// be performed by that thread without using atomic operations.// When a lock's bias is revoked, it reverts back to the normal// locking scheme described below.//// Note that we are overloading the meaning of the &quot;unlocked&quot; state// of the header. Because we steal a bit from the age we can// guarantee that the bias pattern will never be seen for a truly// unlocked object.//// Note also that the biased state contains the age bits normally// contained in the object header. Large increases in scavenge// times were seen when these bits were absent and an arbitrary age// assigned to all biased objects, because they tended to consume a// significant fraction of the eden semispaces and were not// promoted promptly, causing an increase in the amount of copying// performed. The runtime system aligns all JavaThread* pointers to// a very large value (currently 128 bytes (32bVM) or 256 bytes (64bVM))// to make room for the age bits &amp; the epoch bits (used in support of// biased locking), and for the CMS &quot;freeness&quot; bit in the 64bVM (+COOPs).//// [JavaThread* | epoch | age | 1 | 01] lock is biased toward given thread// [0 | epoch | age | 1 | 01] lock is anonymously biased//// - the two lock bits are used to describe three states: locked/unlocked and monitor.//// [ptr | 00] locked ptr points to real header on stack// [header | 0 | 01] unlocked regular object header// [ptr | 10] monitor inflated lock (header is wapped out)// [ptr | 11] marked used by markSweep to mark an object// not valid at any other time 根据下面图理解 以及 无锁先打印一下，如果我们不调用 hashCode 在markword上是不会显示 public class HeaderTest { public static void main(String[] args) { Object o = new Object(); System.out.println(Integer.toHexString(o.hashCode())); System.out.println(ClassLayout.parseInstance(o).toPrintable()); }} 打印结果 hashCode: 2d209079OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 79 90 20 (00000001 01111001 10010000 00100000) (546339073) 4 4 (object header) 2d 00 00 00 (00101101 00000000 00000000 00000000) (45) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment) x86都是使用的小端模式，我们转为大端显示更直观一些 我们看最后三位为 001 表示无锁。 其中 hashCode [0 00101101 00100000 10010000 01111001]转换类 16 进制为 0x2d209079。 分代年龄为 4 位，说明 JVM 回收最大存活为 15 代。 小端 00000001 01111001 10010000 00100000 00101101 00000000 00000000 00000000大端 00000000 00000000 00000000 00101101 00100000 10010000 01111001 00000001[00000000 00000000 0000000][0 00101101 00100000 10010000 01111001] [0][0000][0][01] 未使用 hashCode cms_free 分代年龄 偏向锁 锁标志 偏向锁偏向锁是JDK 6中的重要引进，因为HotSpot作者经过研究实践发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低，引进了偏向锁。 偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，会在对象头存储锁偏向的线程ID，以后该线程进入和退出同步块时只需要检查是否为偏向锁、锁标志位以及 ThreadID 即可。 当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操 作把获取到这个锁的线程的ID记录在对象的Mark Word之中 ，如果CAS操作成功，持有偏向锁的线程以后每 次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高。 偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于一个线程反复获得同一锁的情况。偏向锁可以 提高带有同步但无竞争的程序性能。 偏向锁在Java 6之后是默认启用的，但在应用程序启动几秒钟之后才激活（因为刚启动程序内部一般会有多个竞争），当然可以使用-XX:BiasedLockingStartupDelay=0参数关闭延迟，如果确定应用程序中所有锁通常情况下处于竞争状态，可以通过 -XX:UseBiasedLocking=false参数关闭偏向锁。 public class HeaderTest { public static void main(String[] args) throws InterruptedException { // 等待虚拟机开启偏向锁 Thread.sleep(5000); Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }} 打印结果： java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a0 00 a6 (00000101 10100000 00000000 10100110) (-1509908475) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一次打印为匿名偏向，第二次偏向锁指向了main 线程，第一个线程ID为0，第二有线程ID。 匿名偏向：小端 00000101 00000000 00000000 00000000 00000000 00000000 00000000 00000000大端 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000101[00000000 00000000 00000000 00000000 00000000 00000000 000000][00] [00000][1][01] 线程ID 偏向时间戳 cms_free 分代年龄 偏向锁 锁标志偏向main线程：小端 00000101 10100000 00000000 10100110 10111011 01111111 00000000 00000000大端 00000000 00000000 01111111 10111011 10100110 00000000 10100000 00000101[00000000 00000000 01111111 10111011 10100110 00000000 101000][00] [0][0000][1][01] 线程ID 偏向时间戳 cms_free 分代年龄 偏向锁 锁标志 轻量级锁轻量级锁是JDK 6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用monitor的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的。 引入轻量级锁的目的：在多线程交替执行同步块的情况下，尽量避免重量级锁引起的性能消耗，但是如 果多个线程在同一时刻进入临界区，会导致轻量级锁膨胀升级重量级锁，所以轻量级锁的出现并非是要 替代重量级锁。 当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁，其步骤如下: 判断当前对象是否处于无锁状态，如果是，则JVM首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的 Mark Word 的拷贝（官方把这份拷贝加了一个 Displaced 前缀，即 Displaced Mark Word），将对象的 Mark Word 复制到栈帧中的 Lock Record 中，将 Lock Reocrd 中的 owner 指向当前对象。 JVM利用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 的指针，如果成功表示竞争到锁，则将锁标志位变成 00，执行同步操作。 如果失败则判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻 量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态。 轻量级锁CAS操作之前堆栈与对象的状态 轻量级锁CAS操作之后堆栈与对象的状态 public class HeaderTest { public static void main(String[] args) throws InterruptedException { // 等待虚拟机开启偏向锁 Thread.sleep(5000); Object o = new Object(); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } new Thread(() -&gt; { synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }).start(); }} 打印结果： java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 c8 00 2f (00000101 11001000 00000000 00101111) (788580357) 4 4 (object header) d7 7f 00 00 (11010111 01111111 00000000 00000000) (32727) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 00 5a a9 03 (00000000 01011010 10101001 00000011) (61430272) 4 4 (object header) 00 70 00 00 (00000000 01110000 00000000 00000000) (28672) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 发现从偏向锁转为轻量级锁 偏向锁：大端 00000101 11001000 00000000 00101111 11010111 01111111 00000000 00000000小端 00000000 00000000 01111111 11010111 00101111 00000000 11001000 00000101轻量级锁：大端 00000000 01011010 10101001 00000011 00000000 01110000 00000000 00000000小端 00000000 00000000 01110000 00000000 00000011 10101001 01011010 00000000[00000000 00000000 01110000 00000000 00000011 10101001 01011010 000000][00] 指向轻量级锁指针 锁标志 重量级锁public class HeaderTest { public static void main(String[] args) throws InterruptedException { // 等待虚拟机开启偏向锁 Thread.sleep(5000); Object o = new Object(); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } new Thread(() -&gt; { synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }).start(); Thread.sleep(1000); for (int i = 0; i &lt; 2; i++) { new Thread(() -&gt; { synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }).start(); } Thread.sleep(1000); }} 展示了从偏向锁（101）-&gt; 轻量级锁（000）-&gt; 重量级锁（010） java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 90 80 33 (00000101 10010000 10000000 00110011) (864063493) 4 4 (object header) fc 7f 00 00 (11111100 01111111 00000000 00000000) (32764) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 00 3a d6 06 (00000000 00111010 11010110 00000110) (114702848) 4 4 (object header) 00 70 00 00 (00000000 01110000 00000000 00000000) (28672) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 02 3f 21 33 (00000010 00111111 00100001 00110011) (857816834) 4 4 (object header) fc 7f 00 00 (11111100 01111111 00000000 00000000) (32764) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 02 3f 21 33 (00000010 00111111 00100001 00110011) (857816834) 4 4 (object header) fc 7f 00 00 (11111100 01111111 00000000 00000000) (32764) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。 自旋锁：许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得，通过让线程执行循环等待锁的释放，不让出CPU。如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式。但是它也存在缺点：如果锁被其他线程长时间占用，一直不释放CPU，会带来许多的性能开销。 自适应自旋锁：这种相当于是对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定，这就解决了自旋锁带来的缺点。 锁消除锁消除是指虚拟机即时编译器(JIT)在运行时，对一些代码上要求同步，但是被检测到不可能存在共享 数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中， 堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们 是线程私有的，同步加锁自然就无须进行。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确 定，但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下要求同步呢?实际上有 许多同步措施并不是程序员自己加入的，同步的代码在Java程序中的普遍程度也许超过了大部分读者的想象。下面这段非常简单的代码仅仅是输出3个字符串相加的结果，无论是源码字面上还是程序语义上 都没有同步。 public class Demo { public static void main(String[] args) { contactString(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;); } public static String contactString(String s1, String s2, String s3) { return new StringBuffer().append(s1).append(s2).append(s3).toString(); }} StringBuffer的append ( ) 是一个同步方法，锁就是this也就是(new StringBuilder())。虚拟机发现它的 动态作用域被限制在concatString( )方法内部。也就是说, new StringBuilder()对象的引用永远不会“逃 逸”到concatString ( )方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除 掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。 锁粗化原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，只在共享数据的实际作 用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线 程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对 象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操 作也会导致不必要的性能损耗。 public class Demo { public static void main(String[] args) { StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; 100; i++) { sb.append(&quot;aa&quot;); } System.out.println(sb.toString()); }} JVM会探测到一连串细小的操作都使用同一个对象加锁，将同步代码块的范围放大， 放到这串操作的外面，这样只需要加一次锁即可。 写在最后我看很很多视频和文章整理出来的比较，synchronized比较难，涉及到的知识特别多，包括并发、字节码、JVM、汇编以及计算机系统等。在 Java 1.6 以后 JVM 对 synchronized 进行了优化，存在偏向锁、轻量级锁和重量级锁等形式，尤其是锁的锁的升级和降级比较复杂，现在我们回过头再看看这张图，就很容易看懂了。 参考 Java面试热点问题，synchronized原理剖析与优化 死磕Synchronized底层实现 Java对象布局 深入理解 Java 虚拟机之对象的内存布局","link":"/2020/09/09/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20synchronized%20%E5%85%B3%E9%94%AE%E5%AD%97/"}],"tags":[{"name":"二进制","slug":"二进制","link":"/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"},{"name":"计算机基础","slug":"计算机基础","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"位运算","slug":"位运算","link":"/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"Full-Text Search","slug":"Full-Text-Search","link":"/tags/Full-Text-Search/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"英文","slug":"英文","link":"/tags/%E8%8B%B1%E6%96%87/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"OOP","slug":"OOP","link":"/tags/OOP/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"堆排序","slug":"堆排序","link":"/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"name":"lintcode","slug":"lintcode","link":"/tags/lintcode/"},{"name":"浮点数","slug":"浮点数","link":"/tags/%E6%B5%AE%E7%82%B9%E6%95%B0/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"Future","slug":"Future","link":"/tags/Future/"},{"name":"SPI","slug":"SPI","link":"/tags/SPI/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"Reactor","slug":"Reactor","link":"/tags/Reactor/"},{"name":"synchronized","slug":"synchronized","link":"/tags/synchronized/"}],"categories":[{"name":"CSAPP","slug":"CSAPP","link":"/categories/CSAPP/"},{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"源码","slug":"源码","link":"/categories/%E6%BA%90%E7%A0%81/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"JAVA","slug":"JAVA","link":"/categories/JAVA/"},{"name":"Java 基础","slug":"Java-基础","link":"/categories/Java-%E5%9F%BA%E7%A1%80/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"计算机基础","slug":"计算机基础","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Dubbo","slug":"Dubbo","link":"/categories/Dubbo/"}]}